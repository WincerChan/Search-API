[
  {
    "title": "博客折腾小记",
    "date": 1534908718,
    "tags": "主题 博客 字体",
    "category": "博客栈",
    "content": "八个月前，我把建站之初就使用的 NexT 主题换成了 Material 主题，依稀还记得当时告诉自己：以后就好好写文章，绝对不再耗费时间在这没啥价值的事情上（让你立 Flag！后悔了吧？）。时隔半年多，如今发现对我来说好像不折腾比折腾还要难一些，原因嘛，自然是新鲜感与强迫症在作祟，这次折腾的起因就在于新鲜感——我看上了一个主题。优点与缺点这次更换的主题是 inside，该主题相较于其它 hexo 主题的特殊之处就在于它的本质是采用 Angular 编写的 SPA（single page web application，单页应用程序）。优点就在于每次点击不同的链接只产生一个 HTTP 请求，返回的是一个   文件，包含该页面的内容（内容已在   时已经转成 HTML 格式了），而一旦接收到   文件后，就会将文件的内容通过   属性嵌入页面。而缺点在于相较于普通的页面，可能对 SEO 不那么友好。因为阻止页面呈现的 JavaScript 可能会对用户体验造成不好的影响，而我为此在额外方面做了补足：添加了 27 个   标签，用 Google Chrome 测试 SEO 那一项拿了 89 分，应该还算不错了（拿不到满分是因为部分字体小于 16px）。URL 后缀采用 Angular 编写的 SPA 有一个 ~Bug~Feature，即在路由时会自动去掉 URL 结尾的斜线（slash），这就很尴尬了，因为我的博客 URL 是默认在结尾都有一个斜线的，比如： ，我对此的解决办法是：为每一个页面都添加一个   标记，其中标记的链接末尾都加上一个斜线；但这样并不能解决 Google Analytics 的链接地址的问题，因为 Google Analytics 分析发送的 URL 是获取 HTTP 首部信息里的 referrer，为此我修改了发送 Google Analytics 的那部分代码：将每一个 URL 的尾部都加上了斜线；我在 Stack Overflow 上找到了更好的解决方法，原理是根据请求 URL 的每一个路由地址在末尾都加上斜线。但若想完美的解决这个问题，还需同时为每个匹配的路由路径在末尾都补足一个斜线（否则带斜线的 URL 一刷新就会出现路由无法匹配的情况）。 这样一来的话，斜线的问题算是解决了。（这部分也是我折腾耗时最多的部分。）用户体验我针对用户体验方面做了如下改进：字体原主题的默认字体大小是 14px，我将正文修改成了 16px，代码字体修改为了 15px，这应该会比原主题看起来舒服一点。并且我移除了主题额外加载的字体文件，而纯粹改用   来呈现。参考了 fonts.css。我能吞下玻璃而不伤身体。The quick brown fox jumps over the lazy dog.Service Worker原主题不带 Service Worker 功能，但我还是为我的博客注册了 Service Worker 功能。启用盘古之白主要是为了解决中英文混排时的问题。因为研究显示，打字的时候不喜欢在中文和英文之间加空格的人，感情路都走得很辛苦，有七成的比例会在 34 岁的时候跟自己不爱的人结婚，而其余三成的人最后只能把遗产留给自己的猫。毕竟爱情跟书写都需要适时地留白。终于找到了我之前过得如此不得意的原因了，看来从此之后我可以走上人生巅峰了。Disqus原主题对 Disqus 的 identifier 和 url 识别有误，自己新增的页面会在在首部添加   字段，比如我的   页面会变成  ，这并不是我希望的。我针对当前 URL 简单的做了一个判断，根据 URL 的不同来生成指定的 identifier。API我将原主题的 API 请求前缀改了一下，不从源站请求。因为我的网站是使用 Cloudflare 来~减~加速访问，但国内的速度却不佳，而我博客大部分用户还是国内的。将 API 请求源放在了国内的 CDN 后，会更大的提升页面的访问速度——访问页面几乎感觉不到页面的加载时间。个人喜好相较之前的 material 主题，我去除了   功能，因为现在的博客内容需要用 JavaScript 来呈现，而放入   的资源取出的速度是不如直接从 Service Worker 请求的速度来的快。同时我也移除了 lazyload-image 的功能，因为之前朋友告诉我说她从 RSS 阅读器阅读文章的时候图片没有显示，想了想应该是 lazyload 的 JS 没有加载所导致的，于是乎干脆去掉了，等以后有空的时候再试试 Angular 的 lazyload 是否也有这个问题。由于该主题文章的内容是以   呈现的，故   标签里的内容是不会运行的，导致我的音乐插件 Aplayer 无法加载，于是我另写了一个页面专门呈现单独的音乐插件，再以   嵌入当前页面，算是比较完美的一个解决方案了。尾巴这篇文章一发布，预示着我博客栈的目录收录的文章也已到达两位数（10 篇）[^1]，强迫症终于满足了。最后我想说：我真的再也不！想！写！前！端！了！这绝对是我最后一次折腾博客！真香！[^1]: 最近我将写得不是很满意的文章隐藏了起来（原本想删除的，后来想了想实在有些舍不得），有二十余篇，我的博客现在不提供这些文章的入口，你仍然可以通过我的 MyBlog 仓库查看这些文章。",
    "url": "/posts/50658b02/"
  },
  {
    "title": "Python 知多少（二）——继承",
    "date": 1540117100,
    "tags": "Python 继承 super 知多少",
    "category": "分享境",
    "content": "好像又有一段日子没写技术类博文，翻了翻归档，发现最近一篇技术类文章已经是俩月多之前的事了，吓得我赶紧~水~写一篇的技术文章不然怕是要被人当成生活博主了。思来想去写些什么好，还是继续上次开的新坑，来聊聊 Python 中的继承。Python 作为一种具备多种编程范式的语言，面向对象自然也是它所具备的范式之一；而继承，作为面向对象程序设计的三大特性之一，其重要性也是不容忽视的。尤其这一特性在支持面向对象范式的语言里还有着不同的规则，如：C++ 同时支持普通继承和虚继承；Java 则是将其它语言中的 class 细分为 class 和 interface；还有 Python，「无痛地」支持多重继承。 多重继承当一个语言支持多重继承时，至少需要解决这两个问题，以下图为例逐个分析 C++、Java、Python 对多重继承的支持情况： 怎么处理共同的父类（基类、超类）多个父类方法名重复的问题C++首先看看 C++ 是怎么解决第一个问题的：C++ 在遇到这种情况时，最顶层的基类（A）会被创建两次，虽然可以通过将 A 设置为 B、C 的虚基类来解决，但这种虚继承是有副作用的：不只是在获取成员会更慢、占用内存更多，在和虚函数一起出现时会更难以理解：当 A、B、C、D 中都有一个虚函数 f 时，   内部调用了   和  ； 和 内部都调用了 ，于是  就被调用了两次。当然也不是没有办法解决，Template Parameters as Base Classes 就是 C++ 之父专门用于解决这个问题所开发的技术。第二个问题：如果这里的 B 和 C 同时实现了   方法，同时 D 中没有实现   方法，那么在调用  （d 为 D 的 instance） 的时候会调用哪一个？编译器对于这种 Ambiguous base classes 的情况会直接报错，解决方法也简单粗暴，你必须显式指定   来调用 B 中的  。虽然以上两个问题在 C++ 中都解决的并不好，但也总归是解决了。下面来说说 Java。JavaJava 之父觉得 C++ 太难用了，于是他决定创造一门语言来取代 C++，这门语言需要保留 C++ 的优点，但又需要把 C++ 中较为混乱、复杂、危险的部分剔除（其中就包括了多重继承），于是，Java 就在这样的理念里诞生了。在 Java 诞生之初，对多重继承的支持少的可怜：一个 class 仅可继承（实现）多个 interface。本来是挺好的，但是在 Java 8 中为 interface 中的方法引入了 default 关键字，这就让 interface 里定义的方法可以有方法体了。那么 inteface 有了方法体之后，对这解决这两个问题有什么影响呢？将上例中的 A、B、C、D 换成四个 interface：第一个问题：Java 遇到了和 C++ 中的虚函数一样的问题，即 D 中如果想同时调用 B 和 C 中的某方法，且 B、C 中也调用了 A 的方法，那么 A 的该方法会重复运行两次。并且 Java 无法像 C++ 中使用模板技术来解决这个问题。第二个问题：Java 8 之前一个 class 可以实现多个 interface，即使 interface 有同名方法也没关系，毕竟 inteface 里定义的方法没有方法体，所以不会导致二义性。但有了 default method 之后，Java 反而无法处理这个问题了：D 不允许同时继承两个实现了 default 方法的接口（一个实现了，另一个没有实现也不行）。C++ 解决的不好，Java 压根就没解决。所以我认为 Java 在多重继承这一方面比 C++ 处理的更加不好。Python终于到 Python 了，那么先来看看 Python 是如何解决第一个问题的：如果 D 中需要同时调用 B 和 C 中的   方法，且 B、C 中也需要调用 A 的   方法，那么仅需在 B、C、D 的该方法中写下   即可。因为继承图的缘故，Python 中的   会沿着继承图顺序依次找寻 D 的所有超类。第二个问题：还是得益于继承图，当 D 中没有实现   方法时，Python 会依据继承图顺序来寻找 D 的所有超类中是否有该方法，直到找到为止，而这个顺序也就是方法解析顺序。Python 完美的解决了这两个问题，这也是为什么我说 Python「无痛地」支持多重继承。既然这两个问题都是靠方法解析顺序解决的，那么它到底是个什么东西？看官先别急，下面会着重阐述。方法解析顺序方法解析顺序（Method Resolution Order，简写为 MRO），是描述该类自继承顶层超类的一种顺序，它在类中以   属性存放，值是一个元组（  返回的则是一个列表，然而这列表并不可变），上例中的 D 的 MRO 为： 这里的意思是：D 的最顶层超类为  （新式类中所有类都继承自  ），其次是 A、C、B。下面来具体看看 Python 的代码是如何解决上文提到的第一个问题的： 在 D 中遇到的   会沿着 D 的 MRO 依次向上寻找超类中的   方法并执行，即依次执行 D -> B -> C -> A 这个顺序。那么为什么 Java 或 C++ 无法通过这种写法解决呢，原因在于 Java 的   在多重继承中必须指定父类是哪一个，因为编译器是无法获知你想要运行的是哪一个父类的方法。而一旦指定了父类（B），那么与这个父类同时继承的另一个父类（C）你也必须要指定，而这两个父类又具有相同的更高层次的父类（A），所以就导致了最顶层的父类（A）中的方法被调用了两次。下面来具体说说 Python 中的   类。super 的作用在 Python 中某 class 使用了   后，  即会沿着最初调用   的那个 class 的 MRO 向上寻找超类： 也就是说：在 B 中调用的   不会顺着 B 的 MRO 来向上寻找，而是从最初调用的 D 的 MRO 来向上寻找。那么   是怎么知道最初的 class 是哪一个呢？嘿嘿，你可能已经猜到了，没错，就是通过   这个参数来指定的：当我们调用  时 ，实际上调用的是： ，而我们调用的   也只是 Python 3 对   （其实这里的   也可以换成  ）的简写，所以其实 B、C、D 中的   中的   其实都是 d。 当我们以   调用时，这里的 MRO 即为   的 MRO，而   必须为该 MRO 中的某一项，也就是说  。简单来说，  做的事就是：你提供给它一个 class 以及一个 instance，它返回从该 instance 的 MRO 中排在 class 之后的类里，查找方法的对象。说了这么多，那么这个 MRO 到底是怎么产生的？C3 算法在 Python 2.3 之后，MRO 是由 C3 算法来计算得出的，而在 2.3 之前是按照如下规则计算：新式类是广度优先，经典类是深度优先。这里仅讨论 Python 2.3 版本之后的 MRO 计算方法，也就是 C3 算法：为表述方便，先做出如下规定：$$head([C_1,C_2,...,C_N]) = C_1$$$$tail([C_1,C_2,...,C_N]) = [C_2, C_3,...,C_N]$$$$L[C(C_1,...,C_N)]=[C]+merge(L[C_1],...L[C_N],[C_1,...,C_N])$$则用 C3 算法计算这个列表的线性化可以用公式 (4) 表示，其中的 C 是继承自 C1，C2，… CN 的类。对其中的 merge 操作可以解释为：选取等号右边 merge 列表的第一项 L[C1] 为 K；如果 head(K) 没有在 merge 中的任何列表的 tail 中出现（这时称 head(K) 为  ），则把 head(K) 加入 C 的线性化列表中，并将 head(K) 从 merge 的所有列表中删除，重复 2；否则，设置 merge 中的下一项 L[C2] 为 K，如果 head(K) 为  ，重复 2；重复以上操作直到所有的 class 都被移除或者已经找不到   为止；如果找不到   那么就抛出异常，否则创建成功。来看个例子吧： 首先 L[A] = [A]，然后：$$L[B]=[B]+merge(L[A],[A])=[B, A]$$$$L[C]=[C]+merge(L[A],[A])=[C,A]$$这两个等式很简单，没什么好说的，来看个稍微复杂一点的：$$\\begin{aligned}L[D]&=[D]+merge(L[C],L[B],[C,B])\\\\&=[D]+merge([C,A],[B,A],[C, B])\\\\&=[D,C]+merge([A],[B,A],[B])\\\\&=[D,C,B]+merge([A], [A])\\\\&= [D,C,B]\\end{aligned}$$稍微解释一下：第二行，设置 K 为 [C, A]，其中 C，也就是 head(K) 是一个  ，那么就把 C 加入 D 的列表，并把 C 删去；第三行，这时设置 K 为 [A]，A 此时并不是一个  ，因为他在 tail([B, A]) 中出现了，所以要设置下一项 [B, A] 为 K，此时 B 是一个  ，那么就把 B 加入列表，并删除 B；第四行，这时 K 为 [A]，A 此时是一个  ，加入列表，并删除 A，此时所有 class 都已经被移除，算法结束。来个错误的例子：$$\\begin{aligned}L[E]&=E+merge(L[C],L[D],[C,D])\\\\&=E+merge([C,A],[D,C,B,A],[C,D])\\end{aligned}$$这时算法好像没有办法继续往下走了：因为设置 K 为 [C, A]，head(K) 并不是一个  ，那么就把 K 设置为 [D, C, B, A]，这时还是不行，因为 D 也在后面列表中的 tail 出现了。所以是无法选择 (C, D) 为基类来创建 E 的，如果你在解释器中执行一下代码，你就会发现，它报错了： 以上，愿对你有所帮助。参考：The Python 2.3 Method Resolution OrderItem 40：明智地使用多继承Python: super 没那么简单 - Huang Huang 的博客",
    "url": "/posts/58dd3c61/"
  },
  {
    "title": "Web 性能优化（一）——使用 localStorage",
    "date": 1512025774,
    "tags": "优化 localStorage Web",
    "category": "实验室",
    "content": "localStorage 的意义为了针对我的网站提供更好的浏览体验（或者说更接近原生 App 的用户体验），在之前我就已经开启了 Service Worker 技术，针对离线或者网速慢的情况下改善用户体验。但只有少数几个浏览器支持 （Chrome、Firefox、Opera），对目前手机端用户数最多的 QQ 浏览器、UC 浏览器却没有支持，也就是说该方法针对 QQ 浏览器和 UC 浏览器并没有什么实际优化。而且对于 Service Worker，它并不能减少你的 HTTP 连接数量，只是拦截你的请求，减少 Stalled、Request sent 和 TTFB 的时间，见下图：针对以上两个问题，本博客采用另一种 HTML5 新技术 —— localStorage。localStorage 简介localStorage 是在 HTML5 中新引进的一项存储技术，（如果不被清除）存储没有时间限制，但是有大小限制，一般（不同浏览器的限制有所差别）对于每个域名是 5 MB，对于存储一些纯字符串脚本，足够了。且目前大部分主流浏览器均支持此项技术。但是需要注意，Service Worker 是可以将所有的 HTTP 请求全部拦截，无论服务器的 Response Headers 中的 Content-Type 是什么类型都可以拦截从本地加载。而 localStorage 仅能存储静态资源（JavaScript/CSS）。而存储在 localStorage 的中的静态资源所带来的优点就在于再次加载时不需要发起 HTTP 请求（Queueing、Stalled、Request sent、TTFB、Content Download 这些都不需要），这可以大大改善不支持 SW 技术的浏览器在访问我网站时的浏览体验。本博客的实践本博客采用的是 basket.js 方案，将 JavaScript 在 localStorage 中，利用 localStorage 的特性，减少 HTTP 连接的次数，以达到改善页面加载体验的目的。目前（2018/09）得益于新主题的 SPA 特性，我已经移除 localStorage 的功能了：一方面是因为用户每次点击并不用重新请求 JavaScript 和 CSS 和 HTML，存储 JavaScript 有些没必要；另一方面是 localStorage 还存在安全隐患，故暂时去除 localStorage。为了避免每次刷新页面 main.css 加载先后页面出现抖动的问题，默认不将 main.css 放入 localStorage 中存储。另一个问题是 NexT 在设计之初就很依赖于 js（会加载大量的 js 文件），而这些 js 文件的加载顺序是有要求的，jquery 必须优先被加载，否则就会出现奇怪的 bug，好在 basket.js 提供了控制加载先后顺序的方案。危险性在这篇知乎回答中，很详细的列出了 localStorage 的优点和缺点。其中最危险的是网站出现 XSS 漏洞，就会被人利用将恶意代码注入到 localStorage 中，导致即便修复了 XSS 漏洞存储的代码依然是被篡改的。好在 basket.js 可以提供将 localStorage 中的代码重新从网络加载的问题。具体见官方文档。",
    "url": "/posts/a9d193c6/"
  },
  {
    "title": "一台 VPS 的正确打开方式",
    "date": 1519299484,
    "tags": "VPS Nginx API SSH",
    "category": "分享境",
    "content": "其实像 Hexo 这样的静态博客框架本不需要服务器的，GitHub Pages 就提供免费的托管服务、且不限流量，但内心那点不安分因素总是撩拨着我：比如可以自定防护规则、可以搭建私有 Git 服务、可以搭建自己的 API（这个比较重点）、还能自己搭建 SS 服务，于是乎就买了一台 VPS。由于我的博客使用了 Cloudflare 作为 CDN 服务商，而国内的电信和联通用户是默认解析到 Cloudflare 的美西结点，只有移动用户是解析到香港节点，所以为了 API 的快取速度（即：本机 -> Cloudflare -> VPS -> Cloudflare -> 本机），将服务器选在了洛杉矶，每年 20$、1T 流量、10G 固态、512M 内存，搭建一个静态博客和几个 API 足够了。简化 SSH 登录SSH 的安全验证有两种级别：基于密码：知道帐号和密码，就可以登录到远程主机，这种方式无法避免「中间人」攻击基于密钥：创建一对密钥，并把公钥放至服务器，每次通信都会检验密钥，从而可以避免「中间人」攻击这里介绍第二种方法。生成密钥如果在使用 GitHub 的时候已经生成过，那么这一步可以略过 随后就会生成一对密钥，默认为：id_rsa（私钥）、id_rsa.pub（公钥）上传至服务器使用 ssh-copy-id 命令 需要输入远程服务器的登录密码，随后 id_rsa.pub（公钥）会自动上传至服务器的   文件中随后再进行 SSH 连接时，就不需要再输入密码了简化 IP虽不用输入密码，但仍需要输入服务器登录名和 IP 地址，所以需要将配置写入   中： 随后再进行 SSH 连接时，输入   就可以登录了  命令也可以简化成以下： 作为 GitHub Pages目前我的博客仍然在该仓库的 master 分支上保留有静态文件，仅作备份。添加 DNS 记录首先为 DNS 解析添加一条 「A 记录」，记录值为 VPS 所分配的 IP更改 Nginx 配置SSH 登录后，编辑 Nginx 的配置文件  ： 可部署多个子域名，只需将   和   替换成相应的子域名和文件夹就可以了可以先创建一个    测试一下，访问    看看是否成功加密 CI 配置这一步可选，你也可以手动用   命令将每次   生成的静态文件上传至服务器，只不过略微麻烦。Travis CI 的终端并不能支持用户输入密码，而 GitHub 的 Token 又无法在自己的服务器使用，故而只能采取简化 SSH 登录这步中类似的方法，即用私钥（即 id_rsa）去确认登录的身份，而将私钥公开至 GitHub 又是很危险的，所以我们需要将私钥加密： Travis CI 上的 known_hosts 只添加了 GitHub 下的三个域名，在使用 SSH 登录时，会提示是否添加该主机，同样因为终端无法输入，所以需现将服务器的 IP 与端口号添加至 known_hosts： 这里忍不住吐槽一下 Travis CI 的加密：居然无法同时加密两个文件，而官方提供的方法是先把需要加密的文件压缩后加密，再解压。搭建 APIHexo 这类静态博客所需的内存其实是挺少的，只需在后台运行一个 Nginx 进程就可以了，只运行一个 Nginx 进程时用「搬瓦工」的管理面板查看发现一共内存才使用了 40M，才用了不到 10%，所以就想着可以将之前写的「一言」API 放到我的服务器上，毕竟 Heroku 在国内访问还是挺不稳定的。之前是用 Python3 写的，后来发现 VPS 自带的 Python 版本居然是 2.7，深知其中坑的我就没打算再用 Python 了，于是就是用 Node.JS 写了一个，本地调试了一下，就扔到服务器上了。第二天早上起来一看，发现内存占用居然到了 110M，一查看原来都是 Node 的占用，其中每一个 API 请求，平均就会多占用 2M 的内存，而且这个请求所占用的内存并不会释放，这样下去怕是没两天服务器就要爆内存了。后来我也想过解决办法，比如用 PM2 这个工具来限制运行的内存，超过就重启 Node 环境，也想过定时重启服务器，再转念一想，我是大爷诶，凭啥要我去迁就辣鸡 Node.JS 的内存管理，你不行那我换一个具有垃圾回收的语言不就好了，那就 Java？好像也不太行，毕竟服务器就那么点硬盘，JDK 和 JRE 不知道要占用我多少空间，再者说来毕竟我可是 「Java 黑」。那么就归纳一下我的需求：「占用内存小、部署方便、有垃圾回收（不会爆内存）、不要 Java」，然后考虑到编译型程序比解释型程序占用的内存更小，所以也就没考虑 Ruby & Python，满足这些要求的好像也只有 Golang 了。写了那么久的动态类型语言，突然要我写静态类型语言还真是有点不适应。在网上找了个例子，自己捣鼓了一个下午，就写出来了，算是一个勉强遵循「RESTful」风格的 API，开始还有日志功能，后来想想没必要，Nginx 也可以监控端口的访问日志，就删去了。然后在 Nginx 配置端口 而且 Golang 的部署也是很方便，将 *.go 拷贝就行了。跑了几天，内存占用稳定在 10M 上下。该项目已托管至 GitHub。搭建 SS搬瓦工的 SS/SSR 搭建可以说是非常的方便了：先进入 KiwiVM 面板在左侧点击   按钮再点击   按钮大约半分钟后，会提示已经安装完成：再点击   按钮，回到以下界面，再点击  ：SS 服务配置完成了，将以上信息填入 SS 客户端即可使用。不过由于服务器是在美西，所以无论怎么优化（BBR），延迟都会在 160ms 以上，当然这对浏览网页看视频来说也没有什么影响。注意：当你使用 VPS 翻墙时，会同时计算上行、下行流量，也就是说如果翻墙使用 1G 流量，其实等于使用了 VPS 的 2G 流量。搭建私有云笔记我最近有在思考私有云笔记的必要性，毕竟有了博客，那云笔记的作用可能就鸡肋了一点。但我还是选择了搭建。我的想法是：博客用于存放、发布一些较正式的文章，而笔记可以休闲一点（类似作文和日记的区别）。回到正题，目前来说，体验好的云笔记要么需要会员、要么存在诸多功能限制，而我又不想多浪费钱，那么选择一个支持多设备（其实主要是解决手机设备）的同步方案并借助私有的服务器架设自然也就是最好的解决办法了。我选择了 Nextcloud 作为解决方案，并借助他的 WebDAV 功能作为多端同步工具。手机端笔记软件选择的是易码，支持 Markdown 语法和 WebDAV 同步，电脑端可以选择直接用浏览器访问 Nextcloud，可以在线 Markdown 编辑和预览，当然也可以选择用 Nextcloud 同步至本地文件夹，并用其它编辑器打开就可以了。",
    "url": "/posts/b3085a7/"
  },
  {
    "title": "Nextcloud 搭建私人云服务教程",
    "date": 1522479811,
    "tags": "云服务 NextCloud VPS",
    "category": "分享境",
    "content": "我一直很不相信国内的那些云服务提供商（尤其是在李彦宏发表的讲话「中国用户对隐私问题没那么敏感，在个人隐私方面更加开放，一定程度上愿用隐私换方便和效率」后），因为怕隐私得不到保障，故而我的一些隐私数据都是存放在国外的云盘（如 Dropbox、Drive 等）上。可这俩在国内都被墙了，而手机翻墙总是显得有些不够方便，与是我就琢磨着自己搭建一个云服务，随后就发现了 Nextcloud 这一开源云服务。而网上的教程都太过复杂了，对新手太过不友好，于是乎——一篇近乎傻瓜式的 Nextcloud 教程诞生了。安装这里采用 Docker 容器方式来安装 Nextcloud，这样就不用担心各种环境依赖了（Nextcloud 的依赖简直多得吓人，而 Dockerfile 会帮你把依赖都配置好）安装 Docker注：Docker 仅支持 64-bit 的系统Docker 现已被各大发行版的仓库收入，采用正常安装命令即可： 随后，启动 Docker 守护进程： 安装 NextCloud自动安装有了 Docker 后，就可以几行代码安装 Nextcloud 了： 安装完成后先别忙着启动，  查看一下容器的 id，是一串 12 位的字符串，为了便于记忆，重命名一下： 随后就可以采用如下命令启动了： 这样，就完成了 Nextcloud 的安装工作。手动安装方法一只能安装最新版的 Nextcloud，而最新版缺少部分功能，如：无法添加 Drive 和 Dropbox 的外置存储。如果你对外置存储不是很 care 的话，那就按照方法一安装就可以了。 这里采用官方编写的 Dockerfile 手动构建，所以时间会花得比较久。 这时候用   应该可以看到刚刚创建的镜像了，随后创建容器： 稍稍解释一下参数：-v 后面是地址，前半部分是 VPS 的地址，后半部分是容器内的地址-p 后面是端口号name 后面是容器名称最后的 nextcloud 是镜像名称配置Nginx 配置由于 NextCloud 已经占用了 8080 端口，这里采用 Nginx 做反向代理，将域名直接解析至 8080 端口。 重启 Nginx 服务后，就可以通过 cloud.example.com 来访问云服务了。NextCloud 配置 重定向 overwritehost有时候 NextCloud 会自己定向至本地的 8080 端口，所以需要手动重写正确的地址：如果提示不能定位软件包，先执行  。 重启，让配置生效： MySQL 配置由于我 VPS 的内存比较小，所以并没有启用 MySQL/MariaDB 数据库（怕爆内存），而是采用了 SQLite，反正也是我一个人用，问题不大。开启了 MySQL 后发现内存也就多了 20M（但性能的提升可不是一点半点），遂还是改成 MySQL 了：安装 MySQL（这里采用 MariaDB 分支） 开启 daemon 服务   登录 MySQL 初始设置打开 https://cloud.example.com创建管理员帐号和密码数据库就选择 MySQL/MariaDB，其它参考下表：|  名称  |     值      || :: | :: || 用户名  | nextcloud  ||  密码  |  admin123  || 数据库名 | nextcloud  ||  地址  | 172.17.0.1 |注意：这里的地址千万不要填写成了 localhost 或者 172.0.0.1，因为这里的地址需要容器内与外部通信。点击完成后，等待几秒就可以使用了。挂载外部云盘由于我 VPS 的容量只有 10g，故而放不了过多的视频，就考虑采用外部存储的方法，将 Drive、Dropbox 挂载至 Nextcloud 外部存储或者 VPS。注：Nextcloud 13 已经取消对 Drive、Dropbox 外部存储的支持（这时候你也可以选择把 Drive 直接挂载至 VPS 本地目录，再通过外部存储链接至挂载目录来完成）。启用外部存储插件在应用页面，启用   插件：如果提示：「没有安装 “smbclient”无法挂载 “SMB / CIFS”, “SMB / CIFS 使用 OC 登录信息”. 请联系您的系统管理员安装」解决办法：安装 smbclient 这里简单说一下，不管你的 VPS 原本的系统是 CentOS、RedHat、Debian，统一都用 apt-get 安装，因为现在处于的是 docker 容器内的系统，与 VPS 的系统是分离的。接着再安装 smbclient： 同时会提示：「You should add \"extension=smbclient.so\" to php.ini」，这里又被小坑一把，网上大部分教程所说的   并不存在，在 docker 容器内部该文件是在： 随后重启 Nextcloud 服务就应该就 OK 了。随后如果你安装的 Nextcloud 是 13 版本及以上的话，就只有考虑用 box 提供的 WebDAV 来作为外置存储了，不过只有 10G 的容量，且最大文件限制是 250MB。如果是用的 12 版本及以下的话，就可以考虑采取 Drive 作为外置存储了：获取 API访问 Google 开发者平台：点击「启用 API 和服务」点击「Google Drive API」点击「启用」点击左侧的凭据 -> OAuth 同意屏幕：按照以上格式填写，点击保存随后创建凭据：应用类型选择网页应用，其它的参考以下：点击创建后，会弹出悬浮框告诉你 ID 和 Key。配置 Nextcloud登录 Nextcloud，转至管理页面，点击「外部存储」，选择 Google Drive，填入 API 和 Key，点击授权，若授权时出现 400 错误，那么是重定向的 URI 出问题了，再添加如下一条： 如果提示「此应用未经过验证」，点击高级 -> 转至 example.com，忽略掉就行。当出现了绿色按钮，就表示配置成功了。参考：Docker image of Nextcloud用 Docker 和 Nginx 搭建自己的云服务器（Nextcloud）连接 Google Drive 教程FreeNAS 10 NextCloud 開啟外部儲存媒體的 SMB 功能",
    "url": "/posts/bf0413ac/"
  },
  {
    "title": "Hexo，再也不见",
    "date": 1605399506,
    "tags": "Hugo 主题 设计 优化",
    "category": "博客栈",
    "content": "时间倒回到两年前，当时的我刚刚结束实习返校：闲着没事又开始折腾起博客，那时博客才更换成 SPA 没多久，由于 Bug 太多，主题各地方的细节我也不是太满意，体验了一段时间满足了新鲜感之后，心里忽然升起了一种对折腾博客的倦怠感。于是我还是换回了原来的 Material 主题，这一用就用了两年。直到前段时间，Github 提示博客仓库有好几个 CVE 的漏洞，作为一个强迫症，自然是想修复这些漏洞，然而我发现这些漏洞是博客使用的一些 Hexo 插件的依赖造成的，有些插件作者都不再维护了，于是我便想弃用掉这些插件，找寻新的代替品；可又转念一想，就算找到了代替品，这种情况也还是会发生——毕竟我不能指望每一个插件的作者都不弃坑。权衡利弊之后，我决定从根源处解决问题——如果没有 Hexo，自然也就不会有插件依赖的问题了，因此我弃用掉了从建站伊始就使用的 Hexo 框架，转而投向 Hugo 的怀抱。Why Hugo?Hugo 并不像 Hexo 提供各种插件用来增强或修改框架本身的功能，不过好在 Hugo 框架本身的功能已经足够的多了，我只需要在上面做一些修改即可——这也正好符合我的需求，根据我自己的想法定制、维护，也就解决了让我弃用 Hexo 最根本的问题。其实早在两年多前我就有尝试过将博客换成 Hugo，只是当时逛遍了 Hugo 的主题，发现没一个能打的，原因也很简单：Hugo 是基于 Golang 的，主题创作者大多是后端；Hexo 则是基于 Node.js，主题创作者大多数是前端，而主题样式则完全考验的是前端能力，因此 Hugo 主题的整体水平自然落后于 Hexo。如今，既然我已决定使用 Hugo，那么不妨自己写一个主题。主题的设计本次主题我选择使用 Tailwind 作为 CSS 框架，它与其他 CSS 框架的区别在于默认不提供各种元素的样式，而是将各种 CSS 的属性预先定义成 class 的形式，这样如果我想控制某个元素的样式的话，只需要将对应的 class 名称加入元素的 classList 就好，颇有点声明式编程的意思。同时，由于 Hugo 集成了 PostCSS 框架，几乎可以让 Tailwind 开箱即用了。在 JavaScript 方面，由于之前 Hexo 年久失修的插件给我留下的阴影，一开始让我使用它时我是拒绝的，可转念一想有些 JavaScript 的功能的确可以提升博客的体验（Lazyload，Workbox 等），于是开始秉持着「主体功能上不能依赖于 JavaScript」的原则来使用 JavaScript；由于 Hugo 已然内置了模块用于 CSS 的预处理和 HTML 的压缩工作，在发布时我只需要打包 JavaScript 就好，因此在模块打包工具上我选择了 Rollup.js——一个非常轻量的工具，只支持 JavaScript 文件的打包。博客的一些改进评论的加载一般来说，博客评论的加载有以下几种方式（以 Disqus 为例）：最原始的方式：在用户进入文章页面直接加载 Disqus，但这会给页面带来非常多的额外请求从而拖慢加载速度，而且因为中国的局域网环境，会更显著地降低用户体验；优化后的方式：默认不加载 Disqus 的评论，用户需要看评论时，点击按钮以加载评论，这种方式比上一种好很多，但也会给用户带来一次额外的点击操作；将二者结合：用户进入文章页面时，先请求一个 Disqus 的配置文件，如果在给定时间内未超时，则自动加载评论；反之则需要用户手动点击按钮以加载评论，这也是我之前一直使用的方法，可这种方法仍然会拖慢页面的加载速度——如果给定的超时时间比较长的话，仍然会产生和第一种方式类似的问题；博客的实践是在第三种方式的基础上做了一点优化：当用户进入文章页面时，不请求配置文件，只有当页面滚动到文章底部的时候才发送请求配置文件来测试 Disqus 的连通性，这样当用户首次进入文章页面时，页面的加载速度不会有什么影响。文章的加密博客是否需要加密文章，以及需要加密文章的原因不在本文的讨论范围。本文仅讨论实现手法之前 Hexo 博客的加密是通过插件完成的，如今更换成 Hugo 之后，自然要自己造轮子了。其实加密博客的思路很简单，在编译成 HTML 的时候将文章原本内容使用 AES（或者其他的什么算法都行）加密后替换掉，在前端展示时，再让用户输入密码通过 JavaScript 解密就好。这里我踩了两个坑：Go 的加密库与 JavaScript 的解密库的兼容性问题，Padding 函数需要设置成同样的，以及当密钥长度不够时的填充规则也要一样；Hugo 的 shortcode 不支持 Shell 命令的调用，因此我不得不采取一种非常别扭的方式：Hugo 生成 HTML 文件后，手动调用加密程序将指定的 HTML 文件中的内容替换再写入源 HTML 文件。也由于第二个坑的存在，在本地使用 Hugo Server 调试时是没办法测试加密功能的，不过好在每次博客部署都是通过 Github Actions，配置文件写好之后倒也没有特别麻烦，只是心里总是觉得有根刺儿一样不舒服。除此之外还有一些小改进，比如：所有的动画都是使用 CSS 实现的，不依赖于 JavaScript；所有的 JavaScript 都是延迟加载的，等到页面所有资源加载完成才触发执行；所有图片都是 Lazyload 的，考虑到 RSS 订阅的用户，文章内部的插图没有使用 Lazyload；……主题的使用一开始设计博客主题的时候，并没有打算发布，只想自娱自乐，因此将许多个人偏好耦合进了样式中，我也不打算改了，直接把博客开源吧。博客的一些个人配置文件我使用了 Hardcode 的方式嵌入（比如 Google Analytics 的 ID），请注意修改后使用。还有，因为包含加密的文章，所以我将 content 文件夹注册成了一个 Hugo Module（这个 Module 其他人没有访问权限），如果你想直接运行，最简单的方法是删除在配置文件和 go.mod 里的 Module 相关内容，然后将你的 content 文件夹拷贝到根目录，就可以运行了。后记促使我从 Hexo 迁移至 Hugo 的原因或许大多数人的眼里看起来甚至有点扯淡，但我当时的确已经无法忍受了。后来冷静下来想了一想，Hexo 本身并没什么不好的，反而其衍生出来的生态、主题美观度、模板语言、API 自由度比 Hugo 强了不止一点。而我终究还是换成了 Hugo，究其原因应该是我已经对 JavaScript 的编译、打包、构建等前端工具链累觉不爱了吧——咦，那么我为啥迁移到 Hugo 之后还要使用 Rollup.js 打包工具呢，人呐，果然是矛盾的动物。",
    "url": "/posts/migrating-from-hexo-to-hugo/"
  },
  {
    "title": "Hexo 博客备份",
    "date": 1496410620,
    "tags": "Hexo 教程 博客",
    "category": "博客栈",
    "content": "使用 Hexo 在 GitHub Pages 搭建博客时，博客作为一个单独的 GitHub 仓库存在，但是这个仓库只有生成的静态网页文件，并没有 Hexo 的源文件。这样一来换电脑或者重装系统后，再想找回源文件就比较麻烦了，这里推荐一种比较完美的方法解决备份问题。备份创建仓库 WincerChan.github.io，如果同名仓库之前已经创建，请将之前的仓库改名，新建的仓库必须是 Username.github.io（如果你是将 Hexo 博客部署到了自己的服务器，那么仓库名可以随意设置，我这里就是随意设置的仓库）；创建两个分支：master 和 hexo；设置 hexo 为默认分支；将刚刚创建的新仓库   至本地，将之前的 hexo 文件夹中的 _config.yml、themes/、source/、scaffolds/、package.json 和 .gitignore 复制至 WincerChan.github.io 文件夹；将 themes/next/（我用的是 NexT 主题）中的   删除，否则无法将主题文件夹 push（也可以将主题文件夹使用子模块的方式添加到该仓库)；在 WincerChan.github.io 文件夹执行   和  （这里可以看一看分支是不是显示为 hexo）；执行  、 、  来提交 hexo 网站源文件；执行   生成静态网页部署至 Github 上。这样一来，WincerChan.github.io 仓库就有 master 分支和 hexo 分支，分别保存静态网页和源文件。修改在本地对博客修改（包括修改主题样式、发布新文章等）后：依次执行  、  和   来提交 hexo 网站源文件；执行   生成静态网页部署至 Github 上。即重复备份的 7-8 步骤，以上两步没有严格的顺序。恢复重装电脑后，或者在其它电脑上想修改博客：安装 git；安装 Nodejs 和 npm；使用   将仓库拷贝至本地；在文件夹内执行以下命令  、 、 。附录这里稍作说明：添加 ssh-keys在终端下运行： ，一路回车；会在 .ssh 目录生成  、  两个文件，这就是密钥对，id_rsa 是私钥，千万不能泄漏出去；登录 Github，打开「Settings」>「SSH and GPG keys」，然后点击「new SSH key」，填上任意 Title，在 Key 文本框里粘贴公钥   文件的内容，注意不要粘贴成  ，最后点击「Add SSH Key」。hexo 的源文件这里说一下步骤 4 为什么只需要拷贝 6 个，而不需要全部： 站点的配置文件，需要拷贝； 主题文件夹，需要拷贝；  博客文章的 .md 文件，需要拷贝；  文章的模板，需要拷贝；  安装包的名称，需要拷贝；  限定在 push 时哪些文件可以忽略，需要拷贝；  主题和站点都有，标志这是一个 git 项目，不需要拷贝；  是安装包的目录，在执行   的时候会重新生成，不需要拷贝；  是   生成的静态网页，不需要拷贝；  同上，  也会生成，不需要拷贝； 文件，不需要拷贝。其实不需要拷贝的文件正是   中所忽略的。持续部署关于如何使用 CI/CD 持续部署可以参考我这篇文章。",
    "url": "/posts/7efd2818/"
  },
  {
    "title": "关于男乒退赛的一点看法",
    "date": 1498271554,
    "tags": "国乒",
    "category": "碎碎念",
    "content": "6 月 23 日。马龙、樊振东、许昕宣布退出 2017 年国际乒联中国公开赛。本来针对这个事，我想写一篇长文来讲讲最近中国某些「魔幻」的地方，奈何后天就要考网络，只好暂且放下。我一般不在博客上转载文章，不过鉴于这几天实在没有时间写，于是决定转载一下微博的一篇文章，出处已无法考证。憋了一晚上了，大半夜了，看着事情从最初了英勇豪迈，从振奋人心，担忧，到最后深深的无能为力。看它空降热搜，一路爬到第一，半个榜内都是国乒。看它被封，被禁，被删博。截了一路的图。这是国球。国家体育总局关心的是那几块闪闪发亮的金牌。所以呢，给他们空降教练组长，突然之间毫无征兆的给他们的恩师「另谋高就」，他们没法反抗，禁言，被收手机，不能发声，不能上微博。金牌可以再有，但国乒，这个从 2006 到 2016 年，敢在体育总局面前下军令状的梦之队，被瓦崩了，就不能重来。看到了吗，从杜塞世乒赛临阵换走孔令辉，到成都公开赛明升暗降刘国梁，风云诡辩，赛场上闪闪发亮的新老双子星，四个大满贯，转眼间就只剩下了马龙一人。有人说他们，不爱国，退赛，逃避，搞得和国旗上印的是刘国梁的脸一样。那你是没有看过，孔令辉在夺冠后的瞬间扯起衣服亲吻胸口的那个国旗小标。你是没有看过，许昕在赢下赛点后，扯着衣服指给全世界看，他是中国人，然后指着背后的 CHINA 留给世人一个坚不可摧的背影。你是没有见过，一个体育项目，2006 至 2016，在漫长的十年里，一个队伍包揽了世界大赛中，他们在制度约束下所能获得的所有金牌银牌，以及铜牌。是中国乒乓球。爱不爱国，铁骨铮铮，天地可鉴。所以为什么他们会放弃他们热爱的赛场，扣除上百的世界排名积分，在一个不用升国旗奏国歌的比赛中以这种极端的方式伸张正义？他们心寒。孔令辉走了，刘国梁走了。捧起国球一片天，使这个精神漫漫延续的人，都以这样的方式离开了他们所热爱的赛场，不是功满圆退，而是二话不说让你离开。国乒在今年刚刚重新聘选重组完教练组，刘国梁说不想从政只想呆在球场。马琳王皓，曾经世界冠军重新回到了国家队，以另一种方式，教练员的方式。然而，半年未到，体育总局下令国乒取消总教练主教练职位，设立组长分管男女队，让刘国梁去做乒协副主席。连李永波在内，有 20 多位的乒协副主席。毫无征兆。你让他们如何接受。这几天里，从东京到成都，他们到底经历了什么，只有他们自己知道。下午蔡振华蔡局到了成都，对刘国梁的卸任发表了态度。晚上，所有能发生声的运动员，无论是国家一队二队还是省队，退役没退役，还有教练员，都发了一条微博。他们都选择了用这种方式来抗议。后果是什么，禁赛，谩骂，卸甲归田？他们知道吗，同样也不知道。马龙，赌上了他最好的现在，樊振东，赌上了他前途无量的未来，许昕，赌上了奥运后好不容易重拾的好状态。他们怎么可以这么傻。国乒不是没了刘国梁就转不下去，也不是没了许昕马龙张继科樊振东就转不下去，事实上，马龙，刘国梁在里约后都有过退役的念头，但是又是什么让他们选择了依旧留在了赛场上？是那方寸球台，和牵动着万千国人心的白色小球。刘国梁，大满贯。退役后的第一天站在了教练员的位置上，至此，整整十四年。在这十四年，他有了两个可爱的女儿，一个叫赢赢，一个叫一一。赢，是中国队赢。一，使中国队第一。他这半生，都叱咤风云于这赛场，这一生中最重要的人，也与乒乓球挂了勾。发声，这只是见不惯也不能接受一代功臣沦落如此地步。不能反抗，唯有自燃。没有任何一个项目可以做到如此地步。教练员，运动员，把自己串在一起，做同一条绳上的蚂蚱。没有任何一个项目可以做到如此地步。女队教练员不够，男队教练去补，男队教练员不够，那运动员还可以坐镇场外。没有一个项目任何一个项目，和乒乓球一样可以看到四面五星红旗闪闪升旗的模样。拿什么赌？拿自己赌，拿世界第一去赌，拿整个职业生涯去赌。他们是连赛后忘记握手都要大肆报道严重批评的运动员，罢赛简直是想都不敢想的事情，而如今却发生了。为何会做出如此举动，我们都应该明白。这是中国乒乓球队历史上最没有把握的一次比赛。但我希望他们赢。那句话没有变，无论怎样都不会变，国乒长虹，剑指东京。不知道他们在酒店怎么样，有没有手机，看不看得到我们。如果看得到，想告诉他们。整个中国都在支持他们。很奇怪，国乒为什么要改革？改革不是应该改掉不好的吗？日本队今年复制中国管理模式，韩国金泽洙回来重新凝聚团队，各国都在学习认可的管理模式，就因为上层的政治斗争，就随意改革？要建立一个国乒体系花了刘国梁 20 年的心血，而毁掉只需要一个会议。教练组扁平化，这是好听的说法，真实意思是业务和权力分开，由官僚进行垂直管理，中央集权。新建的“管理组”谁来空降？懂不懂乒乓球？会比一群世界冠军的教练还要懂？和教练组有分歧，谁听谁的？外行领导内行？政治斗争，高于金牌利益，高于项目，高于运动员。这就是中国体育界。为什么每一次，都要在巅峰的时候收割别人的心血，提走功勋，然后等低谷了再急巴巴请人来「临危受命」？前有中国女排，后，可能就是乒乓球。不仅是体育总局，其实这就是中国的现实。我很乐意看到中国这样最后会变得怎么样 :D",
    "url": "/posts/2cdb7149/"
  },
  {
    "title": "使用 Service Worker 优化网站",
    "date": 1500959207,
    "tags": "ServiceWorker 博客 优化 sw-toolbox",
    "category": "实验室",
    "content": "静态博客的内容是很适合用缓存来加速访问的，除了采用常见的 CDN 加速和压缩博文等方法，通过客户端也可以实现加速访问，本文介绍的是「服务工作线程—— Service Worker」。关于 Service Worker 的具体介绍见这里。本文主要需要的是它的离线加载的特性。本博客使用 Service Worker 可分为两个阶段，在我最初撰写本文的时候，使用的是 Service Worker 原生的接口。在不久之后，Google 推出了 sw-toolbox 和 sw-precache 用以让用户更全面的掌控 Service Worker 缓存的方式：包括版本控制、文件缓存级别、具体路径等，于是在我经历了漫长的实践后（其实是因为懒），有了本文 Version 2.0。启用 Service Worker添加注册代码以下注册代码需要在网站的根目录添加，这样才能保证接管整个网站的全部资源。 将以上代码加入主题中，至于加在哪需要根据主题的结构决定。你只需要保证生成的静态资源中包含以上代码，那么就算添加成功。以 NexT 为例，你可以把以上代码添加到   下的任一评论配置文件中（前提是你开启了该评论组件）。添加静态资源将以下代码保存为  ，并确保生成静态文件的时候，  在网站根目录下（你可以把它放在   文件夹内）。 首先指定 cacheVersion，在刷新缓存的时候会进行匹配；其次是一个 Cache Storage 名称的有关变量，我这里只是简单划分为静态资源——全部从缓存中加载的资源；关闭 debug 模式，设置 Timeout 时间为 1s。其中 sw-toolbox 的缓存级别共有 5 个（网络优先、缓存优先、速度优先、仅缓存、仅网络）。我这里采用的是  ，即缓存优先加载。可针对具体的资源进行不同的缓存级别分配。其中   表示每一个你需要操作的资源，第一个参数表示匹配的网址，第二个表示缓存级别，第三个是回调函数。具体到以本站为例的话，你可以参考本站的配置文件。加速效果离线可以看到在启用了   仍然可以加载页面缓存刷新页面可以看到许多资源是直接 ( from ServiceWorker ) 加载的，并未发起新的 http 请求。先决条件浏览器is Serviceworker ready 详细列出了所有浏览器支持的情况。HTTPS服务器工作线程只能工作在 HTTPS 加密的网站上，本地的   是默认安全。参考文章：服务工作线程：简介ServiceWorkerRegistration",
    "url": "/posts/a0df572f/"
  },
  {
    "title": "Sorry，会写代码真的能为所欲为",
    "date": 1527388461,
    "tags": "表情包 Javascript",
    "category": "实验室",
    "content": "前一段时间「这个仇我先记下了」的表情包突然火了，导致我也萌生了自己写一个表情包生成工具的想法，毕竟我是重度表情包玩家😌。其实之前我就很喜欢做表情包，不过是用的 PS 等软件，有些麻烦，而且改 GIF 也不太方便。于是乎，我决定也蹭一波热度，也写了一个，最初是只有「记仇」这个静态表情包的，现在加上了王境泽、为所欲为、打工是不可能打工的等等动图，模板后续还会添加，如果有好的素材可以私我。思路当然网上也有一些表情包生成器，比如「sorry」，但界面我不太喜欢，而且我觉得这类较为简单的处理没必要借助服务器端渲染合成，直接在浏览器端渲染就好了，毕竟 JavaScript 算是一门「万能的语言」。核心思路是采用 omggif 对 GIF 进行解码，再用 Canvas 将文字绘制在每一帧上，最后再用 gif.js 将每一帧合成，再渲染后输出成 Blob 文件对象（现在不支持 Blob 的浏览器应该没有了吧？），传递给 IMG 标签进行显示。这是解码过程： 这是绘制过程： 这是编码（渲染）过程： 以上是动图的设计思路，静态图就显得简单多了，采用 dom-to-img 绘制就行了，但是在 Edge 上似乎是无法使用的，作者提到似乎是因为添加了 foreignObject 标签，导致 toDataUrl() 在 Edge 上无法工作，所以 Edge 用户只能使用动图部分了。其实核心思路很简单，gif.js 和 omggif 提供的 API 也不复杂，但我还是花了将近一周的时间，因为这是我首次使用 React 开发应用，所以有大半时间都花在了学习 React 上，然而写出来的结果还是偏「Pure JavaScript」一些。本项目采用 create-react-app 构建，CSS 框架采用了 bulma，部分动图模板来自 sorry。实现刚刚有提到，我在设计该工具的时候大部分时间都没有花在核心思路部分，而是花在了——我称为「薛定谔的 Bug」上，即：你在设计该工具的蓝图的时候，没有设想到会出现这些 Bug，而实际编程中，也不一定会遇到，只有你亲自编写了，才知道这 Bug 是否会出现。我在这次编程中就遇到了四个「薛定谔的 Bug」：Blob 文件对象关于静态图部分，我设计了两个按钮：「戳我预览」和「戳我下载」，其实本应该只需要一个下载按钮就够了，因为我使用 contenteditable 属性以编辑 p 标签。和生成的预览图几乎没什么差别，那么为什么要设计两个呢？就是因为 Blob 对象（后续思考了一下，虽然可以先行判断浏览器是否支持 Blob 下载，但针对动态图还是需要预览修正的，故为了设计上的统一性，还是将预览按钮保留了）。其实大部分人应该是没有听说过这个名词的（包括我），但它还真的不是一个新玩意，甚至都不是 HTML5 新增的 API，相比于 HTML5 在 2014 年才完成标准制定，在 MDN 上查到 Blob 对象在 2010 年就被主流浏览器支持了（Chrome 5、Firefox 4、Opera 11.1），但，如今大部分手机浏览器却仍不支持 Blob 文件下载协议。所以只好提供一个预览按钮来供不支持 Blob 文件下载协议的浏览器长按进行保存。服务器问题由于我的服务器是在国外，而且还套了一层 Cloudflare，故而在某些情况下，加载动图会非常慢，尤其是在晚上（大约花费 1min，而且居然还没断，我真是很佩服 Cloudflare 的稳定性）。当然图片的加载问题还不算大，可以放在支持跨域的图床上，由   调用，问题最大的是 Web Worker（合成 GIF 的时候需要使用），但这个 Web Worker 的地址在 Chrome 下只允许同域名下的脚本，即使是公共 CDN 上允许跨域都不行。这里采用还是借助 Blob 对象，巧妙的规避这一限制： React Router 404 错误在将代码生成「production build」时，遇到了一个 Bug，有时访问二级路由会出现 404，多次复现后，终于确定了：在访问二级路由时，如果是正常从一级页面点击跳转的，则会正常访问；但如果是直接访问二级路由或者是在二级路由刷新页面，则会出现 404；但是这个 Bug 在「development build」中是没有的，原因在于当你点击路由时，并不是直接向服务器发起请求，而是由 react-router 路由库给出路由网址，故而刷新二级路由页面或者直接访问二级路由页面服务器是无法正确响应的。以下是解决办法，在 Nginx 中添加   语句： GIF 渲染当我解决了以上问题的时候，我发给室友首先试用，看到了「戳我预览」这个按钮，他就以「单身十八年」的手速猛戳了四五下，随后标志着渲染进度条就「鬼畜」了起来。因为他猛戳的那几下相当于在后台启动了好几个渲染程序，不仅会让进度条「鬼畜」起来，如果你以更快的手速戳的话（单身八十年？）还会让 CPU 负担加重，甚至会卡死，当然我是没有试过。其实这 Bug 算是无伤大雅的，本不太需要修复，因为不像其它生成器拿服务器做后端，可能会造成服务器宕机，我的纯前端写的。但我本着人道主义情怀、不让我的 Bug 陪我过夜的心理，以及最重要的强迫症，还是决定修复这个 Bug。其实很简单，设置一个全局变量  ，在渲染的过程中，该变量为  ，渲染完毕后设置成  ，再将渲染过程放置在   内就解决了。教程见本项目的 Wiki。结语本工具还有很多需要改进的地方，比如 React 的写法不够规范、没有完全实现静态动态资源分离、用户自定义添加模板等等，这些我在空闲时间里都会一点点的改进。目前在实用的角度来说，该工具已经可以投入使用了，剩下的细节就需要慢慢雕琢了。:)参考：xtyxtyx/sorry纯 JS 实现在前端制作 GIF 表情包的网站Histories",
    "url": "/posts/8575e868/"
  },
  {
    "title": "Linux 与 Windows 10 用 GRUB 引导教程",
    "date": 1508211319,
    "tags": "Linux Windows GRUB 双系统",
    "category": "分享境",
    "content": "前言去年暑假的时候，写了一篇如何装 Linux 和 Windows 10 双系统的文章发在了简书上，我写这篇文章的原因是当初装双系统确实是折腾了许久，网上也找不到一篇详尽的教程。由于去年对于写教程还不是熟练，而这一年多的使用过程也遇到了一些问题，所以就准备「Refactoring」这篇文章。EFI 分区在教程正式开始之前，先花一点时间说明 EFI 分区的组成和作用。首先，在你装了 Windows 之后，Windows 在装机过程中会将硬盘划分出一个约 100m 大小的分区，称为 EFI 分区这个分区就是起引导作用的。在资源管理器中是看不到的这个分区的，可以在磁盘管理中看到，管理则需要借助 DG 工具。便于说明，在装好了 Linux 之后，我将 EFI 挂载至 boot 分区截图：可以看到，该分区包含 3 个文件夹（如果你没有装 Linux 的话，就只有两个），分别是 Boot、Microsoft 和 Manjaro，其中 Boot 文件夹就是 UEFI 引导所必需的文件。我们继续打开   文件夹：这些文件就是启动 Windows 10 所必需的，包含了语言包、字体等，BCD 包含了 Windows 引导开始以后的信息。其中，bootmgfw.efi 是 Windows 默认引导文件。1. EFI/Boot/bootx64.efi2. EFI/Microsoft/Boot/bootmgfw.efi以上是采用 UEFI 启动 Windows 10 的文件结构，也就是说，当你按下开机按钮的时候，首先 UEFI 找到 EFI 分区的 Boot 文件夹，然后加载   文件，读取文件信息，找到  ，按照   的要求，加载所需的启动信息，启动 Windows 10。准备工作在正式装系统之前，我们还需要做一些准备工作：关闭 Windows 的快速启动这个功能的作用是在于关机的时候不完全断电，类似将系统处于「休眠」状态，这样可以让开机更加迅速。但这也就导致了只能使用 Windows 系统。关闭 BIOS 的 Secure Boot 的功能在默认情况下，UEFI 固件只会加载那些被签名的引导程序。在缺少 Secure Boot 功能的传统 PC 机上，恶意的后门程序可以加载自身，进而摇身一变伪装成一个引导程序。这样的话，BIOS 就会在启动的时候加载后门程序，这样它就可以躲过操作系统，把自己隐藏得很深。但是不得不说，这对我们安装 Linux 造成了很大的困扰，也是直接导致我们重启到 Windows 10 后进不去 Linux 的原因。首先我们要关闭这个功能：进入 BIOS 找到 Secure Boot，选择 disabled，这样就关闭了。当然，有些人进入 BIOS 会发现 Secure Boot 这个选项是灰色的（比如我的就是），这时你需要先给你的 BIOS 设一个密码，然后就能关 Secure Boot 了。安装 Linux所有的准备都已经完成，这时就可以准备刻录 U 盘了，不推荐 UltraISO，经亲测，软碟通仅刻录 Ubuntu 能成功，其它绝大多数发行版都会失败。推荐「Rufus」和「USBWriter」，这两个软件都可以。刻录完成后，重启按  ，选择从 USB 设备启动，对于绝大多数发行版来说一路回车就行了，只需要注意一点：在选择挂载 boot 位置的时候，一定要挂载在 efi 分区，别的都不行。重启之后，不出意外的话，你会直接进入 Windows 10，不要担心，这时 Linux 已经安装成功了，我们只需要将引导文件替换一下。替换引导文件先用 DG 打开 EFI 分区，你会看到多了一个文件夹，名称取决于你安装的是哪一个发行版。我安装的是 Manjaro Linux，名称就是 Manjaro，打开之后会发现里面有一个名为 grubx64.efi 的文件，这就是启动 Linux 的引导文件。和 Windows 10 的 bootmgfw.efi 类似，我们想要用 grubx64.efi 引导代替掉 bootmgfw.efi，这样就可以用 GRUB 引导了。步骤：1. 进入管理员命令行。方法：win + x，再按 a2. 输入  。提示操作成功的话，就完成了。注：经人提醒，如果输入以上命令提示「参数错误」的话，将 {bootmgr} 改为 '{bootmgr}'，原因是 PowerShell 和 CMD 语法的差别。至此，如果你安装的是除 Arch 之外绝大多数发行版，那么接下来就和你没有啥关系了，你已经成功了，好好享受吧！开机之后会发现进入 GRUB 的引导了，通常会包含至少三个选项（以 Manjaro 举例）：Manjaro、Manjaro 高级选项和 Windows Manager。这就代表你已经完美的解决了 Windows 和 Linux 双系统引导的问题。修复 Windows 引导这一点是我安装 Arch Llinux 的时候发现的，Arch Linux 安装过程是手动安装的，在编写 GRUB 的时候会扫描不到 Windows Manager 所在的分区（当然可能不是所有人都会遇到），所以在 GRUB 界面可能会看不到 Windows Manager 选项，导致进不去 Windows 10，这里就需要手动编辑 GRUB 信息，我们打开   文件，发现里面确实没有 Windows 10 的启动信息，在后面加上： 注意：这里的  ，代表的是终端执行命令： 后的输出；而   代表的是： 的输出。然后保存。在终端执行命令： ，就 OK 了。到此，Arch Linux 和 Windows 10 双系统也配置完毕了。附加问题在使用这一年多的时间，遇到了以下的几个问题：1. 在 Windows 10 进行了一个大更新后，会发现 GRUB 引导界面没有了，还是直接进入了 Windows 10，这时只需要按照   的方法重新输入一遍命令就行。2. 使用 Linux 某个发行版一段时间之后，难免会想尝试一下另一个发行版。这时请务必将之前的发型版的引导文件删除，否则可能会出现无论怎么设置都无法进入 GRUB 的情况。例如：我之前用的是 Ubuntu，我现在换成了 Manjaro，我就需要用 DG 删除 EFI 分区的 Ubuntu 文件夹。3. 在我使用 Manjaro 更新了一次 Linux 的内核后，进不去 Windows 10 了，这个时候千万不要直接修复 Windows 10 引导，这会格式化 EFI 分区，只需要按上面 修复 Windows 引导 的方法编辑一下 GRUB 就可以了。最后：祝使用愉快。",
    "url": "/posts/ad42f575/"
  },
  {
    "title": "Python 知多少（一）——不常见的数据结构",
    "date": 1533699032,
    "tags": "Python 数据结构 高级 知多少",
    "category": "分享境",
    "content": "近来准备写几篇文章用于介绍 Python 较高级一些的特性，归为一个系列。本文是这个系列的第一篇文章，主要介绍一下内置的一些数据结构。对 Pythoner 而言，元组（tuple）、列表（list）、字典（dict）这三个应该最熟悉的数据结构了，恰当使用这三个数据结构的话的确可以应对大部分的使用场合了，但有时因为其它方面的问题（内存占用、插入效率、删除效率等），我们仍有必要学习其它不那么常见的数据结构。数组初学者可能会认为在 Python 里，列表（list） 就是数组（array），其实不然。数组应当是一系列类型相同的变量的集合，而 Python 中的列表却可以存放任何不同类型的数据。Python 里也是有数组这个概念的，与列表有所不同的是数组里数据的存放方式（类型）并不是 Python 的基础类型（int、float、char）等，而是数字的机器标识（说白了就是和在 C 语言中存储方式一样），也因此，在将数据存入和读取文件时效率会更高一些。  支持的数据类型包括整数、浮点数、字符三种，其中创建每个数组需要一个类型码（Type code），用以标识在 C 语言中存放怎样的数据类型，比如   这样创建的就是存放四个字节大小的整数，范围从 - 2^31 到 2^31 - 1（更多的类型码使用 help(array) 查看）。 数组支持列表的大部分操作（准确地说是支持所有和可变序列的有关的操作），包括  、 、  等。 在排序这里与列表有一点小区别，列表支持   这种就地排序的方法，但数组不支持，所以想对数组进行排序的话，得用   新建一个数组： 队列队列的特性是先进先出，虽然我们可以把列表当作队列来使用：  来模拟进队列，  来模拟出队列： 似乎看上去很完美，但是这种方法的弹出操作是很耗时的，因为删除列表的第一个元素会牵扯到移动列表里的所有元素。这里介绍标准库中两种不同的队列：双向队列  类提供了一个双向队列，也就是说   也完全可以栈来使用。它的  、  和  、  都是原子操作，这也意味这   是线程安全的。  同样实现了所有和可变序列相关的操作。  可以接受一个可选参数（ ）表示队列可容纳元素的数量： 需注意，一旦添加了   属性，这个属性就无法修改了。当对一个已满的队列进行添加操作时（第 5 行），另一头的元素会被挤掉。单向队列（原谅我想不出一个好名字了，只能用单向队列来和刚刚介绍的双向队列做区分了）。  类提供的是一个单向的队列，它与上面双向队列最大不同除了它是单向的之外，还有对于队列已经满了或空了的情况下，还要对队列进行添加或删除操作的结果不同：在满员（为空）时，如果还向   中插入（取出）元素的话，它不会扔掉旧的元素来腾出位置，反而是会锁住——直到另外的线程移除了某个位置，这一特性很适合用做生产者——消费者的模型，尤其是当生产者的生产时间与消费者的消费时间不匹配的情况，比如：生产者的生产时间快于消费者的消费时间，如果采用   的话，就会丢失生产者最早时候生产的数据（反之就会造成消费者从空队列中取出数据的情况）。 消费者线程先等待了片刻是为了给生产线程留部分时间，使其在消费者从队列获取之前先将两个对象放入队列。然而，这里的缓冲区容量为 1，这就意味着生产线程在放入第一个数据后，会卡在第二个   方法那里，必须等待消费线程通过   方法把第一个数据消费之后，才能放入第二个对象。堆堆的性质是父节点（下标为 k）的值，总是小于（大于）等于其左（下标为 2k + 1）右（下标为 2k + 2）两个子节点的值。堆这种数据结构实际中多用于实现优先级队列（在   模块中也有优先级队列的实现：  ）：在队列中，优先级较高的元素总排在前面。  模块可以在标准的列表之中创建堆结构：   和   方法总会保持堆的性质，将数据插入或弹出，  总会将堆中优先级最高的元素弹出。其中   可在线性时间内将列表转化为堆。内存视图内存视图（memoryview）可以在不需要复制内容的前提下，在不同的数据结构之间共享内存。当你需要在内存中处理大量二进制数据时，或者需要反复修改内存中某块数据的内容，内存视图可能会对你有很大帮助：因为在 Python 中，对字符串（str）和字节数组（bytesarray）进行切片都是会造成内存的复制，尤其是当需要对较大的数据进行切片的时候，所耗费的代价将会非常昂贵。 可以看出，对   切片的时间复杂度是 O(n^2)，而对   切片总能在线性时间内完成。当然，由于   本身是不可变（immutable）的字节序列，如果想对   中的数据进行修改的话，就需要用   的方式构造   对象： 由于   使用了缓冲区协议（协议提供的是 C 语言级别的 API），导致   只有在 CPython 中才能发挥它最大的作用。本系列全部文章可访问「知多少」标签查看。参考：Fluent PythonEffective PythonLess copies in Python with the buffer protocol and memoryviews",
    "url": "/posts/dbcdebb/"
  },
  {
    "title": "Python 实现多线程下载器",
    "date": 1500447204,
    "tags": "Python 多线程",
    "category": "实验室",
    "content": "前言我为什么会想到要写一个下载器呢，实在是被百度云给逼的没招了，之前用 Axel 配合直链在百度云下载视频能达到满速，结果最近两天 Axel 忽然不能用了，于是我就想着要不干脆自己写一个吧，就开始四处查询资料，这就有了这篇博客。我假设阅读这篇博客的你已经对以下知识有所了解：Python 的文件操作Python 的多线程Python 的线程池Python 的 requests 库HTTP 报文的首部信息下载获取文件采用的是 requests 库，该已经封装好了许多 http 请求，我们只需要发送 get 请求，然后将请求的内容写入文件即可： 随后看看文件夹，那张名为   的图片就是我们刚刚下载的。但是这个功能太简单了，甚至简陋，我们需要多线程并发执行下载各自的部分，然后再汇总。拆分为了拆分，首先得知道数据块的大小，HTTP 报文首部提供了这样的信息：用 head 方法去获取 http 首部信息，再从获取的信息提取出   字段（上文图片大小为 261258 bytes） 我们得到了图片的前 100001 个字节（Range 的范围是包括起始和终止的），打开   你应该能看到一幅“半残”的图。这样我们里目标更近了一步，继续：确认线程数（比如 8 个），261258//8 = 32657，前 7 个线程都取 32657 个 bytes，第八个取剩余的 每个线程获取到的内容按顺序写入文件（file.seek() 调节文件指针） 嘛，线程多了起来就扔到线程池让它来帮我们调度。封装功能复杂了，用对象来封装整理一下： 至此，核心功能都完成了，剩下的就是实际体验的优化了。完整的代码已托管至 GitHub，地址见这里。结语很可惜，我写的这个下载器还是不能下载百度云直链，不过嘛，好多人都说结果不重要，都说重要的是过程，不是么？写这个下载器我也确实学到了许多，至于一开始我是出于什么样的目的？管他呢",
    "url": "/posts/80689c8d/"
  },
  {
    "title": "我的 2018 轨迹",
    "date": 1545879136,
    "tags": "2018 随笔",
    "category": "碎碎念",
    "content": "{% netease musicid=498134 %}实习回到学校十几天后，便开始思考年终总结怎么写，之所以这么早就开始构思，或许是我笃定在这 2018 最后的半个月内也不会发生什么值得记录的大事。当然我也期待着能发生什么事来冲击一下现有的生活——在校的时光实在是太安逸了，想来是应当正处于心理空窗期了。本次总结将会就学习、生活、工作（实习）三个方面来描绘一下今年的生活轨迹。学习我应该算是「兴趣驱动学习」的典范了：每当我抱着很强的目的性或功利性去学习的时候，总是坚持不了多久。Princeton 的算法课从两年前就开始学，学到现在也才把排序看完。不过今年在学习方面还是有不少收获的：借助 Coursera 这一平台，观看了 Node.js 的开发，Golang 的入门等网课。我在学习一门新语言的时候总会选择看视频，如果从一开始就看书的话，我会觉得有些乏味和枯燥，尤其是动辄上千页的技术类书籍，看厚度就有一种劝退感。而在入门后，想要深入了解一门的语言的底层，我才会选择翻阅一些书籍。除了学习新东西之外，对 Functional Programing（函数式编程，以下简称 FP）也有了更深刻地理解。比如，为什么 FP 中多以递归来代替 Imperative programming（命令式编程）中的循环语句。原因在于数学家和逻辑学家们验证递归的正确性比验证循环的正确性要容易得多。一个很简单的例子，分别用 Java 和 Haskell 实现快速排序：Java： Haskell： 以上两段代码，哪一段的正确性更容易验证？答案不言自明。对于前者，指定了计算的详细过程，而后者，仅指定了计算的规则（原则）。这也是 FP 的特点之一：不关心如何计算，更关心计算的结果（的正确性）。「正确」是 FP 设计的重中之重。究其根本在于 FP 的鼻祖 Lisp 与 λ 演算那密不可分的联系。生活生活方面似乎并没有什么改变，相比去年——好吧，并不是。我的体重告诉我比去年重了 ×× 斤。去杭实习不仅没瘦，反而重了。而且似乎睡得还更晚了，不过似乎「互联网依赖症」减轻了不少，比如本文初稿就是纯手写的。在读书方面，算是有了一些进步，今年在豆瓣读书上为 15 本书贴上了「已读」的标签（不过仍未达到两周一本的目标）。文学类和技术类都有，技术类对我影响最大的毫无疑问就是《流畅的 Python》这本书了，断断续续地看了近三个月，做了万余字的笔记。至于文学类嘛，《哲学家们都干了些什么》是让我眼前一亮：枯燥的哲学似乎在作者笔下都「皮」了起来。但印象最深地却是伊坂幸太郎的《金色梦乡》，等下，《白夜行》好像印象也很深刻，《解忧杂货店》构思也很巧妙（这么说来我果然很喜欢日系推理），钱锺书的《围城》也不错...好吧，文无第一，今年看的文学类书籍都非常不错。接下来就该到电影方面了：今年在豆瓣电影为 72 部电影（包括剧集）贴上了「已看」标签。比较喜欢的剧集似乎都是日剧（非自然死亡，胜者即是正义）；电影的话，《我不是药神》一枝独秀，在电影院里哭得还朝旁边的妹子借纸；动漫也看了不少：来自深渊（新番），怪化猫（旧番）都不错，属于能给灵魂带来冲击的番。谈话类节目仍然强推《圆桌派》，可惜第三季之后窦文涛似乎就跑路了。纪录片这块则必须让陈晓卿的《风味人间》安排上，对于一个吃货来说，本节目的美食引起了强烈不适。不过还是作为吃货，即使吃不着，退而求其次，能过过眼瘾也是一种享受。此外，本节目还会介绍与美食相关的风土，人情，文化，品味等，美食之所以被冠以「美」字，绝不仅仅在于它的味道，更在于人们赋予它的某种意义，或者说是其背后所蕴含着的丰富内涵，这才是其绵延不绝的生命力所在。工作如果说搭建这个博客是去年我做的最有意义的事，那么实习应该就是今年我所做的最有意义的事了。九月份时我并没有走校招，原因有两方面：一方面我并没有发现有什么企业校招 Python 岗（大部分都是前端和 Java）；另一方面是估计实习时间也不会太久，本学期期末学校肯定一大堆事，于是也没怎么考虑公司，面了一家，就进去了。我面的是 Python 岗，本以为进来之后也是写 Python。谁知阴差阳错上了 Node.js 的贼船，当然这有一部分的原因在于我：Leader 问我能不能用 Node.js，我说之前接触过一些，然后他就给了我几天时间让我熟悉一下。不过好在是从零开始写的，不用「接盘」前人的代码，倒是省了不少事。在公司待的两个半月时间内，也帮同事解决了不少 Python 问题，不过多是业务方面的逻辑。除此之外，收获最大的就是 Elasticsearch（以下简称 Elastic）的相关组件（我编写的 API 是直接与 Elastic 交互的）的部署和维护了，因为个人的项目很难直接接触到 Elastic 这一庞大的生态系统。不过我是有些认为面试的时候公司没有把我的水平面出来（颇有些怀才不遇的感觉），简历上写的大部分细节都没问。只是问了问笔试题，感觉有点憋屈。能力未充分得到挖掘带来的问题就是资源的浪费。一方面是职员能力的浪费（能力得不到体现），一方面是公司资源的浪费（项目进度跟不上，业绩无法按时达标），于是就会导致某些人上班只需要花费很少的时间即可完成公司的任务，剩下一堆可自由支配的时间，而另一些人不仅上班时间不够用，还需要加班才能勉强完成。在这个公司时，我应当时属于前者，虽然有些不好意思，但我在公司的空余时间还是会学些自己的东西。同时我也感觉写业务写久了，脑子里也只剩下业务了。对技术反而没什么提升，而对于当下的我来说，技术仍远比业务重要。正在这时候，学校要求我们回去准备毕设的事。于是，我辞职了，开始享受这为数不多的大学时光。如果说之前的我还对未来的道路存疑的话，那么这两个半月的实习生活让我开始明确了未来的道路——Python 开发相关。同时也明白：校园的时光虽然让人十分享受，但也总有毕业的那一天。如果说大学的象牙塔是我最后的天堂，那就让我从天堂里一步一步地走出来。似乎该结尾了，我不想再像去年一样为我的 2019 立什么 Flag 了（去年的 Flag 一大半都没实现），不过我想毕业的年份应当过得比较有趣吧？",
    "url": "/posts/e4e1357d/"
  },
  {
    "title": "豆瓣电影 Top 250 数据分析",
    "date": 1516501469,
    "tags": "豆瓣 电影 数据",
    "category": "分享境",
    "content": "前言前段时间忙于备考，博客有段时间没更新了。其实早就有写这篇博客的想法了，原因嘛——我是比较喜欢看电影的，而且近来也对数据分析颇感兴趣，于是花了一天时间，先是爬取数据，再分析整理，数据可视化。其实豆瓣对爬虫的防范算是比较高级了，即使伪造了 Cookie，还是会封禁 IP（还好我的代理 IP 多😏），甚至还会把你的帐号暂时冻结，其实要不是有一些电影词条必须登录才可见，也不用伪造 Cookie 这么麻烦。爬取之前爬取都是用的正则匹配，这次首次接触了「Beautiful Soup」这个库，相见恨晚啊，不多说，先上代码： 其中片长取得是无删减版的片长，即不同版本中最长的。地区、导演、语言等由于会出现多项内容，采取列表存放。以下统计数据截止至 2018/01/20导演其中由「宫崎骏」和「克里斯托弗·诺兰」贡献最多，均为 7 部，具体为：宫崎骏（日本）：《千与千寻》，上映年份为「2001」，排名为 No.6《龙猫》，上映年份为「1988」，排名为 No.17《天空之城》，上映年份为「1986」，排名为 No.33《哈尔的移动城堡》，上映年份为「2004」，排名为 No.45《幽灵公主》，上映年份为「1997」，排名为 No.80《风之谷》，上映年份为「1984」，排名为 No.106《魔女宅急便》，上映年份为「1989」，排名为 No.189克里斯托弗·诺兰（英国）：《盗梦空间》，上映年份为「2010」，排名为 No.9《星际穿越》，上映年份为「2014」，排名为 No.25《蝙蝠侠：黑暗骑士》，上映年份为「2008」，排名为 No.32《致命魔术》，上映年份为「2006」，排名为 No.61《记忆碎片》，上映年份为「2000」，排名为 No.132《蝙蝠侠：黑暗骑士崛起》，上映年份为「2012」，排名为 No.168《追随》，上映年份为「1998」，排名为 No.170演员其中由「张国荣」贡献最多（前三居然都是香港地区的演员），有 8 部，分别是：《霸王别姬》，导演为「陈凯歌」，上映年份为「1993」，排名为 No.2《春光乍泄》，导演为「王家卫」，上映年份为「1997」，排名为 No.77《射雕英雄传之东成西就》，导演为「刘镇伟」，上映年份为「1993」，排名为 No.88《倩女幽魂》，导演为「程小东」，上映年份为「1987」，排名为 No.113《东邪西毒》，导演为「王家卫」，上映年份为「1994」，排名为 No.131《英雄本色》，导演为「吴宇森」，上映年份为「1986」，排名为 No.140《纵横四海》，导演为「吴宇森」，上映年份为「1991」，排名为 No.149《阿飞正传》，导演为「王家卫」，上映年份为「1990」，排名为 No.183地区其中「美国」地区一枝独秀，超过半数以上电影的制片地区均为「美国」，且远超第二名「英国」。美国：140 部英国：34 部日本：32 部香港：26 部法国：26 部德国：20 部中国大陆：16 部片长| 统计名称 | 数值         ||  |  || 中位数  | 118.0      || 均值   | 124.0      || 众数   | 98.0（10 次） || 标准差  | 34.1       || 极差   | 218.0      |其中片长最长的电影为《指环王3：王者无敌》，导演是「彼得·杰克逊」，片长为 263 mins，排名是 No.30。其中片长最短的电影为《萤火之森》，导演是「大森贵弘」，片长为 45 mins，排名是 No.150。年份| 统计名称 | 数值         ||  |  || 中位数  | 2002.0     || 均值   | 1998.6     || 众数   | 2004（13 次） || 标准差  | 15.6       || 极差   | 85         |其中距今最久远的电影是《城市之光》，导演是「查理·卓别林」，年份为 1931 年，排名是 No.210。其中距今最接近的电影有 5 部，均为 2016 年上映：《疯狂动物城》，导演是「拜伦·霍华德」等，制片国家为「美国」，排名为 No.43《看不见的客人》，导演是「奥里奥尔·保罗」，制片国家为「西班牙」，排名为 No.83《摔跤吧！爸爸》，导演是「涅提·蒂瓦里」，制片国家为「印度」，排名为 No.104《海边的曼彻斯特》，导演是「肯尼思·洛纳根」，制片国家为「美国」，排名为 No.151《你的名字。》，导演是「新海诚」，制片国家为「日本」，排名为 No.245嘿嘿，没想到吧，贡献电影最多的年份并不是「Top 250」前四名中有三部的 1994 年，而是 2004 年。评分| 统计名称 | 数值        ||  | - || 中位数  | 8.70      || 均值   | 8.78      || 众数   | 8.7（44 次） || 标准差  | 0.27      || 极差   | 1.40      |其中最高分为 9.6 分，为两部电影所获得：《肖申克的救赎》，导演为「弗兰克·德拉邦特」，评分人数为 952814 人，排名为 No.1《控方证人》，导演为「比利·怀尔德」，评分人数为 99908 人，排名为 No.41其中评分最低的电影为《疯狂的石头》，分数是 8.2 分，导演为「宁浩」，评分人数为 312083 人，排名为 No.230可以看出豆瓣在进行「Top 250」排名时，并不是仅看评分，其中评分人数也占了很大的一部分比重，且似乎还有一些其它的因素，比如《血战钢锯岭》这部电影，评分 8.7，评分人数为 310624 人，却并没有上榜，同为评分 8.7，评分人数为 314940 的电影《看不见的客人》排名却早已进前百（No.83）。最后，本人并非专业电影人士，无法针对以上数据提出建设性的建议，所做统计也仅仅是出于爱好，也愿自己能在闲暇时间里，多看几部电影。",
    "url": "/posts/7a8186a0/"
  },
  {
    "title": "我的学生时代（高中篇）",
    "date": 1560578024,
    "tags": "感想 学生时代 高中",
    "category": "碎碎念",
    "content": "在临毕业的这段时间，生活似乎短暂地失去了目标，并不是丧，我也没有认为这是一件坏事——至少我可以有更多的时间思考并记录我的想法，当然更多时间我在好好地、不带任何负担地放松自己。直到前几天 WakaTime 发邮件过来说已经两周时间没收到我的 Code Activity 了，问是不是插件出了什么问题：「Please reinstall the plugin to continue using the WakaTime dashboard」。其实并不是插件出了什么问题，而是我真的两周没有编程了（笑。休养够了，也终于意识到应该做或写点什么了：于是我开始了本文的创作。本文决定聊聊我的高中以及大学生活（其实我一直都有些畏惧谈论这个话题，原因之后会提到）。错愕从进初中开始，快班里的我们便只有一个目标——进入省重点高中，为学校赚来更好的名誉（当然也为自己的前途）。中考结束，很遗憾，我离省重点的分数线还有几分的差距，当时班上有几个和我分数差不多的人选择了市重点：学杂费全免，直接去最好的班，还有奖学金。当时的我，对于省重点和市重点没有什么明确的概念，所以还是听从家人的想法：交「择校费」，进入了省重点。我仍然记得从初中班主任（我和他关系很不错，他曾不止一次地鼓励我，甚至在我说因为回家太晚而不想上晚自习时，提出可以每天晚上开车送我回家；在中考前，让我不用做数学卷子，把心用在其它学科上）手里接过录取通知书时，他脸上那种复杂的表情——惋惜与错愕。前者在于我最终还是没能过省重点的分数线，后者在于我居然还是上了这所学校。堕落高一上学期，还未分班，想学文的和想学理的混在一起上课，我所在的班级不巧在以后会成为文科班，一想到反正以后也会转班，那就转班后再好好学习吧！恰巧在朋友的安利下，又接触了网络小说（玄幻啊，都市啊~，言情啊~），于是一发不可收拾彻底沉迷于小说，而「转班后再好好学习」也成为了我心安理得的借口。当时的化学老师非常照顾我（因为我第一次摸底考试化学考了并列第一名，当然是吃初中的老本），他也是最早发现我堕落的老师，因此找我谈过几次话，虽然我并没有因谈话而上进，但我仍然感激他在我陷入黑暗的时候愿意拉我一把。在未分班时，考试排名差我也有理由搪塞：文科我不会。可到了高一下学期，便进行了预分班，我被分到了一个新的班级，预想中的「重新做人」并没有出现在我身上，反而是更加的堕落——因为我同桌也看小说。与此同时，「文科我不会」的谎言也不攻自破（虽然是预分班，但学校会针对文理科的学生单独出一份文理科目的排名）。家人以为是我沉迷手机（说实话当时也确实沉迷手机，毕竟是智能机刚兴起的时代，但不是沉迷于网络，而是沉迷于折腾手机 ROOT 之类的），于是把我的手机没收。仅留下一个 MP4，但 MP4 仍然可以看小说，于是我仍沉迷于小说。最终，堕落的高一以我期末考试 1062 的名次（年级不到一千两百人）结尾，而我也没有和家人扯什么「其它人中考分比我高，我学不过他们」这种诛心的理由。高二上学期，上课看小说的情况似乎并没有得到改观，反而是我在与老师斗志斗勇的过程中成长了——「发明」了一种能上课看小说而不被抓到的方法：用书在课桌的前面和右侧各摆一摞，形成一个角落，一有风吹草动就把「作案工具」塞到书下面专门预留的缝隙里。得益此「发明」，我上课看小说没有被老师抓到过一次。可惜之后效仿的同学越来越多，班主任就禁止桌面上的书摆放成这种形状了（话说我这也算是迫使别人改变规则的人了 233333）。奋起似乎很难想起当初选择从堕落的深渊里爬出来的理由（或许不是想不起，而是我自己也不知道），但终究还是选择往上爬了——我开始严格控制看小说的频率，并开始学习了。没过多久，正巧班主任把我调换了座位，我的同桌变成了班长，前桌坐的是班上第一名，我们三人「一见如故」：感兴趣的课（数理化）会一起认真听讲，一起听数学老师讲人生道理；在另外的某些课上则会小范围地互相逗乐、互相扯淡，那段时间不仅是我高二过得最快乐的时光，也是进步最大的时候，我很感谢他俩，也开始明白为什么家人一定要送我来这所学校了。除了他们，我还想说说老师们，尤其是数学老师。在他的课上，我学会了数学这种严禁的思考方式，以及他那近乎到自恋的自信（名言：答案和我不一样就是答案错了），兴趣来了，成绩也就水到渠成了。高二下，我数学考了全班第一——145 分，数学老师似乎开始注意到我这个默默无闻的学生了，从那之后，我像是想证明什么似的，每次数学都很尽力地考，可却再也没考上过 130，可也没低于过 110。语文课，永远都是睡觉的课——语文老师是学佛的，也非常佛系：发现你睡觉时，便会很温柔地抚摸你的背让你不要睡觉，大部分人在被叫醒后仍然继续倒头就睡，他也不恼，继续上他的课。英语老师也非常有趣：经常在课上和我们这些成绩不太好的学生「互动」，还经常放电影给我们看，得益于她，我拾起了对英语的兴趣。好景不长，高二下学期过了才两个月，我们三人组的欢乐时光被班主任强行结束（原因是某人告密说我们三人上课讲话影响课堂纪律），也因此，高二的我对班主任怨念颇深。荒诞上了高三，学校开始要求学生要上两节晚自习（七点到八点半以及八点四十到十点），我们的班主任又要求早上六点五十就要到校，而且我还要搭公交往返，这样一来的话一天根本无法保证八个小时睡眠，于是我就让父亲和老师说我不上第二节晚自习，好在当时我的成绩稳定下来了，也有了底气提出这个要求。虽然每天晚上比同学早一个多小时回家，但我早上仍旧无法那么早起床（尤其是冬天），迟到成为了我的家常便饭，基本高三大部分的早自习我都是被罚站在教室后面背书，最多的一次罚站了近二十人，这也算我们班独特的风景线了。在临近高考的几个月里，我过得比之前更放松了：会在老师要求我们自习时和坐最后一排的朋友一起靠在墙上看《奔跑吧兄弟》，却又不敢笑出声；会在早自习下课的五分钟时间内和同学跑去食堂吃碗面条，然后理所应当地迟到十几分钟才进教室，并打赌班主任不会守在门口……多么美好的时光啊，美好而短暂。高考前夕，我玩得特别好的一朋友（他成绩比我好，高三的摸底考试基本都比预估的一本分数线高四十分，而我一般高十分左右）问我：「你要是没过一本线，会不会复读？」「不会」，我不假思索地回答到。「我也不会」，他透过黑框眼镜，深沉地看着我说：「除非我二本都没考上」。那是我们第一次比较正经地谈论我们的未来。那年是湖北省高考自主命题的最后一年，出卷老师似乎拼了命想让这届高考的学生记住他一样，数学卷异常地难。导致湖北当年的一本分数线是十几年来最低，而我，也倒在了我最擅长的数学上（没考到 80 分，我现在还觉得有些对不起数学老师）。去学校领分数条的那天，阴霾天空，我遇到了那朋友：「考多少分啊？」，他问我。「不好意思说」，我摇了摇头，眼睛望向地面。「我不信你还能有我低，我四百五都没到」，我猛地抬起了头望向他，却只看到他嘴角的苦涩。那是我们第二次，无比正经地谈论我们的未来。高中啊，以「我没过一本线，他没过二本线」这样荒诞地结束了。高中部分已完，由于大学部分需要写的东西比较多，我会另起一篇文章，敬请期待。",
    "url": "/posts/5fdce618/"
  },
  {
    "title": "高校生使用教育网的一点姿势",
    "date": 1556329984,
    "tags": "IPv6 教育网 破解校园网",
    "category": "实验室",
    "content": "最近一直忙于毕业的相关事项，所以也没有新文章产出——并非是找不到写作素材，实在是没写作时间。虽然这几天依旧很忙，但总算也抽出了一点时间完成了本文，希望能给广大高校生在办理宽带时带来一些帮助。前言目前大部分高校的校园宽带应该都对使用者作出了诸多限制，比如：一号一机，禁止使用路由器（破解后才可以共享）；与校方合作垄断，导致价钱比家用宽带贵一大截等。在校生也只能被迫接受——毕竟，你总不能真的不用电脑上网吧？好在目前越来越多的高校里校园网已经开始支持 IPv6 了，而一般校园网只针对 IPv4 的流量计费，对 IPv6 产生的流量是不计费的，至于原因，我猜测有两方面原因：一是 IPv6 相关技术还不是特别完善，IPv4 计费系统可能需要修改；二是目前国内 99% 的网站都不支持 IPv6，而纯 IPv6 环境下是无法访问 IPv4 网站的，所以干脆就没做这一限制。连接上校园网后，不要认证，戳这里来测试是否支持 IPv6，当然也可以直接打开 Google，目前 Google 可以通过 IPv6 直连。但，谁让我是学计算机的呢，这并不能难倒我。既然无法通过 IPv6 直接连接 IPv4 的网站，那利用一个同时支持 IPv4 和 IPv6 的 VPS 做一层代理不就可以绕过这一限制了吗？原理见下拓扑图：这就意味着，只要你具备 IPv6 网络，便可以通过此方法绕过诸多限制，从而免费上网。获取 IPv6目前比较出名的 VPS 服务商除搬瓦工外，大部分都原生支持 IPv6 连接，包括：Vultr、Linode、DigitalOcean。而搬瓦工的 VPS 中 OpenVZ 架构自带 IPv6，KVM 架构则需要利用 Tunnel Broker 技术来提供 IPv6 隧道给只支持 IPv4 的用户（我的搬瓦工 CN2 主机便是通过 Tunnel Broker 来获取 IPv6 支持的，这也是搬瓦工的客服推荐的方案），它定义在 RFC 3053。如果你的 VPS 原生支持 IPv6 连接的话，便可以跳过这一步。获取 Tunnel目前 Hurricane Electric 免费提供 Tunnel Broker 服务（我 TM 吹爆！），该公司运营了世界上以对等数目计算的最大 IPv6 网络，所以服务方面是不用担心的。戳这里注册。随后点击左侧的  ，再在框内输入 VPS 的 IP 地址，再选择一个地区服务器来作为隧道的一端，这里建议根据服务器的地区来就近选择，我这里选择的是 Los Angeles。配置 IPv6创建成功后，在以下页面选择你的系统，如果是 Debian 系就选择 Debian/Ubuntu，其余就选择 Linux-net-tools。框中会出现几行命令，登陆 VPS，依次运行这几行命令就行了。第四行被我抹去的地址便是公网 IPv6 的地址。如果对  Tunnel 的速度需要更换的话，可以删除该 Tunnel 后在 VPS 运行    命令或者直接重启，再重新创建一个 Tunnel。测试不出意外，这时 VPS 已经可以使用 IPv6 连接了：需要注意的是，如果选择非北美地区的服务器，会绕道美国，所以这里的 PING 值会略高。配置代理代理可以选择 Shadowsocks，但本次要介绍的不是它，而是另一款代理软件：V2Ray。该代理软件比 Shadowsocks 多了许多种伪装流量的方法，且占用内存更低（毕竟是 Go 写的），这对于小内存的 VPS 来说，非常重要。只不过其配置文件比 Shadowsocks 要劝退小白一些。服务端安装输入以下一行代码进行安装，系统需支持 Systemd： 有关更详细的安装教程见官方文档。服务端配置如果是通过以上命令安装的话，配置文件在   目录，以下是我的配置文件，没有流量伪装等进阶配置：  ：入站配置，是一个数组。注意协议这里填的是：  ，由 V2Ray 原创的一份加密传输协议。  是一个 Object 数组，每一个元素里的 id 必须满足 UUID 格式，且服务端客户端需保持一直，作用类似于 Shaowsocks 中的密码。 ：出站配置，也是一个数组。客户端安装Linux 客户端的安装与服务端一致。Windows 建议使用 V2RayN，带有图形化界面，下载   解压，下载   解压出的 .exe 文件放入刚刚的目录下。目录应该与以下类似： 客户端配置Linux格式与服务端一致，你需要修改的仅有 address 和 id 部分：address 填写服务端的 IPv6 地址；id 需与服务端一致。  这时，打开网络代理，填入：注意，这里一定要选择手动代理模式，不能使用 PAC/自动模式，因为我们的目的是要本地的所有流量都走代理。而 PAC 仅会当遇到被墙的 IP 时才会走代理。Windows双击 V2RayN.exe 后，点击右上角的 ：填入地址，端口，id 即可：再将右下角的系统代理模式改为全局模式，道理同 Linux 类似：这样，不出意外的话，就已经成功了，你的仅支持 IPv6 的电脑已经该可以通过代理来访问非 IPv6 的网站了。连接测试网速测试正好手头最近入了一个原生支持 IPv6 的 VPS，贴一下与搬瓦工的对比，以下均在同一时段做的测试：原生支持 IPv6 的机器可以直接观看 2K 视频并且不会出现卡顿现象（可以看到已经缓冲了一分钟了），而使用 Tunnel Broker 的就没这么好了，不仅连接速度只有三分之一，而且无法较为流畅的观看 2K 视频，时不时会出现卡顿。考虑到 YouTube 的线路优化已经很强了，国内的视频或者直播应当只能观看 720p（码率最好不要超过 3000）甚至更低了，而前者直播时蓝光 8M 无压力。延迟与丢包测试首先是搬瓦工的，经过了 15 个节点，教育网的入口和出口丢包率很高：这是原生 IPv6 的，经过了 19 个节点，同样教育网的入口和出口丢包率较高（但还不是最高的）：可以看到其原生自带 IPv6 的主机其实也用的是 HE 的 IPv6 网络（前 13 个节点都一样），那么看来是返程的时候出问题了：果然，问题出在返程上面，原生的 IPv6 并没有走 HE 的线路，丢包率为 0。而相比于浏览网页，在看视频时返程的网络状况会直接影响观看体验，这一点也确实在之前的网速测试中体现了。所以，购买建议是：如果你还没有购买 VPS 的话，建议购买原生自带 IPv6 连接的 VPS，使用体验会好很多，不过由于电脑是全局的代理，所以要注意 VPS 流量的使用哦~最后附赠一个国内的 IPv6 电视网站：清华大学 IPTV。参考：给搬瓦工 KVM 版 VPS 配置 IPv6 支持（基于 Linux CentOS 7）Project V 官方网站",
    "url": "/posts/36b4c1ab/"
  },
  {
    "title": "奇安信（原 360 企业安全）服务端开发面经",
    "date": 1558154044,
    "tags": "面经 奇安信 服务端",
    "category": "分享境",
    "content": "现在说起来我自己都不信，之前我居然一直以为秋招是为当年毕业的学生准备的，直到我们班有人签了百度，我才知道秋招原来是为次年的应届生准备的😅，不过当时已经十月，秋招已经基本结束，于是只好准备来年的春招了。话说回来，本次春招我准备的也不算特别充分，很大一部分原因是毕业设计选题选了一个自己陌生的领域，并且还准备评优秀毕业论文，所以年后一直在准备毕设，空闲时间才会找公司投递。我对公司还是挺挑的（钱多事少离家近，起码要满足两点吧），而且还要招 Python 岗，可供选择的公司就更少了，找来找去也只投递了一家公司——奇安信（原 360 企业安全），所幸最后也拿到了 Offer。本文是对这次招聘流程的一个总结。笔试我是三月底投递的简历，四月中旬发来的笔试通知。有两道编程题，一道非递减数列（AC 67%，这题 Python3 的输入格式有问题），一道实现哈希表（AC 91%，同上，Python3 输入仍然有问题），这两题难度均介于 Leetcode 的 Easy 和 Medium 之间。由于两道编程题都没 100% AC，我以为凉了，结果在 4 月 23 日晚上十一点发来面试通知，通知我 25 号下午面试，当时就有点慌，面试时间太近，只有一天时间准备（24 号上午还要去看复联 4 首映，本来想不去了，后来想想首映一辈子就这一次😅），于是看完电影赶紧把数据库和操作系统还有计算机网络复习了一下。一面（30 分钟）等了小半个钟，面试官才姗姗来迟（可能是因为面试的太多了），面试官是一个中年微胖的大叔：先做个自我介绍吧元组和字典的区别（我当时以为我听错了，心想这俩完全没一点相似的啊）Node.js 的特性，与 Python 的区别（这一点应该是看我简历上有写）Python2 和 Python3 的区别Python2 和 Python3 在多线程有什么区别（我当时想了一下，觉得好像没区别，就说 Python2 多线程不太了解）说说多线程的锁多进程有什么用说说函数式编程的特性框架了解吗，说说 Django 和 FlaskDjango 的一次请求流程Django 里用了哪些标准库（好奇怪的问题😳）写一个 Python 的注解（我以为他问的是 Type Hints，后来意识到可能说的是装饰器，就把装饰器的概念说了一遍，问他具体是哪一个，结果他也说不清楚，说自己好久没接触 Python 了，于是这个问题就过了）Numpy 了解吗？Numpy 里新增了什么类型？为什么 Numpy 效率高？Elasticsearch 用过吗，说说分片（我当时已经很久没用 ES 了，有些基础概念忘掉了，就说我只知道分桶，不清楚分片）算法了解吗？说说堆排序和快排（不知道堆排序，就说了一下快排）手撕代码——单链表赋值（还比较简单）Python 和 C 的区别有什么想问我的（这里我作了一个小死，问了一下面试官觉得我怎么样？回答是思维比较发散、活跃，也比较喜欢钻研新东西，但对某些东西背后的原理挖掘不够深入，总体来说算挺不错了😉）与我想象中的面试还是有很大的区别，计算机网络一点没问，操作系统一点没问，数据库一点没问（让我一天的复习付诸流水😅），总体来说都是按照简历来发问，很 Nice 的体验。几分钟后收到二面的短信。二面（18 分钟）也等了小半个钟，二面面试官应该是小组或者部门的 Leader 了，特别温和，居然用了「您」来称呼我：自我介绍说说你印象最深的一个项目（我说去年的实习可以吗？他说可以），我说了七八分钟，他偶尔会打断并针对我的叙述提问你觉得这段实习你在其中学到了什么，阐述了三个方面，又说了五分钟听说你想去武汉啊？（对，离家比较近）来北京吧，武汉可能没有这个岗位了，北京钱多，又是核心部门，我目前的组就是服务端开发的 blabla...然后就没问我问题了，说会在技术方面给我评分，一会 HR 会有三面，问一些其它的事情原本我以为一面没问数据库、网络，二面怎么也该问了吧，可是还是没有（看来是真的不按套路出牌啊😅），面试官超级 Nice。几分钟后收到三面的短信。三面（28 分钟）这一面 HR 问的问题实在是太多，跟查户口一样，又没有录音，只能回忆起一部分了：你是哪人Docker 为什么最近火了起来Docker 和虚拟机有啥区别实习的时候具体做什么，大概多久适应团队为什么读计算机专业（开始讲故事）高考失常了吗（开始讲故事 × 2）为什么不复读（开始讲故事 × 3）想过考研吗，为什么不考研？有其它公司的面试吗（惭愧，没有）你觉得前两位面试官怎么样你觉得笔试题难度怎么样你对自己的评价怎么样对自己的职业规划是怎么样公司如果要求转岗你怎么办工作地点想选择哪个城市对我们公司了解吗有什么想问我的有调休吗😅（HR 还有点蒙，转头问了一下其它人）薪资待遇怎么样（HR 说最近在集中面试，等面试结束后会逐一评定薪资）我这俩提问都是比较迫切的，问的并不算好，不过和 HR 聊天还是比较愉快的。后记等待 Offer 的过程不可谓不煎熬，5 月 16 号在群里看到有人说接到 Offer Call 了，当时心里就凉了半截，17 号晚上九点看到有人已经收到 Offer 了，一看我的邮箱，心另半截也凉了。结果十点一看发现我也收到了😅，当天激动得一晚上没睡好。祝各位都能拿到心仪的 Offer~",
    "url": "/posts/d42e79bb/"
  },
  {
    "title": "构建一言 API 踩坑记录",
    "date": 1509331481,
    "tags": "Hitokoto Flask API",
    "category": "实验室",
    "content": "前言最初是在手机上一个叫「一言」的 App 接触到 Hitokoto，一见倾心啊。之前我看书时遇到写的不错的句子就喜欢摘录下来，在有自己的博客之后，本想是单独写一篇博文来存放，后来分析了 NexT 的布局后，就想到在侧栏底部可以加上一个单独的模块。最开始，是使用别人的 API，后来觉得不太好，有诸多限制，而我又没有主机，于是就自己用 Javascript 写了一个本地的脚本。后来发现这样也不太好，因为本地的脚本每次加载势必要加载存放 Hitokoto 的 JSON 文件一次，当记录越来越多时，会消耗不必要的资源。毕竟每次只需要加载一条。   获取一言最开始准备构建的时候，就遇到了一个问题：一言的数据库去哪里找。我翻便了 Google，基本都是提供 API 的，并不会将完整的数据库给你。这想想也正常，都把数据库给你了，那谁还用你的 API 呢。我就花了一下午，写了一个爬虫，对准了几个提供 API 的网站，开始爬去数据。但是由于 API 产生的数据是随机的，难免会有重复。所以爬取之后又要查重，着实花费了我不少时间。整个过程大概花了一天多，做成了一个 JSON 格式的文件，然后用 JS 导入成为数组，再随机访问数组的某一项，这便是最初“本地版”的「一言」了。转化数据库先前已经说过，一旦数据多了起来。那么数组的访问和加载都是问题，而访问慢的问题可以用数据库来解决。而这学期正好在学数据库这门课，于是便花了点时间将 JSON 格式的数据转化成 sqlite 数据库。JSON 格式的数据有需要的只有 3 项，分别是 ID（用以标识每个 Hitokoto）、HITOKOTO（每个 Hitokoto 的内容）、SOURCE（每个 Hitokoto 的出处）。知道了这些，转化的代码就呼之欲出了： 截至至本文发布，该「一言」数据库共收录了 880 条记录，以后我还会陆续添加。生成 API有了数据库，自然要构建一个 API，这里选用的是 Flask 框架提供的接口。首先你需要安装 Flask，而 Python 是自带 sqlite3 模块的。直接上代码： 保存为  。然后运行，打开   如果没有意外的话，应当是成功了。接下来就是部署了。部署至 Heroku环境准备一开始担心是没有主机，后来才知道有「Heroku」这个造福大众的云平台服务。首先你需要安装 Heroku 客户端工具，安装完成后，输入以下命令来验证安装是否成功： 安装成功后，在本地命令行登录 Heroku： 然后输入你的帐号和密码即可创建应用可以在网页端创建，也可以在命令行创建： 这里或许会提示你名字已经被使用了，换一个就好。接下来要初始化本地和远程代码库。 部署应用除了代码和数据库外，两个必要的文件：  部署应用时，远程环境会自动安装   文件中列出的依赖。我们   文件内容如下： 接下来，我们如何告诉服务器如何运行这个文件呢？就要通过   文件了。 以上就是   的内容。另根据习惯，可自行添加对该项目的描述。接下来就是激动人心的提交了： 打开 https://wincer-hito.herokuapp.com/api/ 看看效果吧！升级应用升级程序的时候，在所有的改动提交后，建议按照如下步骤升级： 使用 API数据获取：请求地址：https://wincer-hito.herokuapp.com/api/请求方式：GET返回函数名 hitokoto 的 js 脚本，本质为 document.write 函数的脚本如果需要 json 格式的数据：https://wincer-hito.herokuapp.com/api/json/如果仅需要 hitokoto 主体：https://wincer-hito.herokuapp.com/api/main/在你想使用「一言」的地方插入以下代码： 演示效果看侧栏。注：由于是 Heroku 的主机是在美国，所以该 API 延迟可能会有一点高。",
    "url": "/posts/f6e1eb2a/"
  },
  {
    "title": "Hitokoto（一言）API 2.0 正式上线",
    "date": 1531712895,
    "tags": "一言 API Hitokoto",
    "category": "分享境",
    "content": "去年夏天的时候，用 Flask 开发了一个简易版的一言，算是最初的 beta 版，部署在了 Heroku 上面（那时我还没购买服务器），由于 Heroku 免费版有时间池的限制，在我购置了服务器后就重新用 Go 重写了一下部署在自己的服务器上，算是 1.0 版，这两天又重新拾坑，开发出了 2.0 版本。前言在 1.0 版本使用了较长的时间后，基于以下考量，我还是重构了部分代码：收录一言数太少：我没事的时候就喜欢刷新玩，经常发现眼熟的，毕竟也就不到一千条；性能：由于使用的是 SQLite，在每秒请求数在 1000 的时候就 GG 了；查询参数：返回不超过查询长度参数的一言，但翻了一大堆 API，都并没有提供这个功能；于是乎，本着「生命不死，折腾不止」的态度，2.0 版本诞生了。本 API 的源码已开源至 GitHub，如有需要的可自行搭建。以下是 2.0 版本的更新日志：数量问题爬取数据时采用了异步爬虫，解决了 1.0 版本爬取时效率低下的问题，同时选取了 xxhash 作为散列函数，将一言主体 hash 后，得到的 64bit 的无符号整数作为主键，这样如果爬取到了重复的一言也不会插入数据库中。得益于异步爬虫的高效率，在很短的时间内，爬取到了足够的一言数。目前，数据库内共有   条一言。以后数量还会不断地增加。爬虫程序已托管至 GitHub。性能问题数据库更换成了 MySQL，以承受高并发访问，以下为建表语句： 参数问题2.0 版本共包含以下请求参数：编码格式格式为  ，包含以下四个参数值：js：JavaScript 脚本，将一言插入 HTML 中第一次出现   的标签中json：JSON 格式的字符串，包含主体（hitokoto），出处（source）text：一言句子的主体默认为： ，即主体 + 出处字符集格式为  ，包含以下两个参数值：utf-8：在 Header 中的   字段添加  gbk：同上长度格式为  ，会随机返回一条不超过这个查询长度的语句。回调格式为  ，会根据回调参数的值返回对应的函数调用，其中函数的参数为一个字典，key 分别为   和  。注意：callback 参数会覆盖掉 encode 参数使用示例调用地址： 例如，我想请求一个长度不超过 10 的一言，并以 JSON 格式返回： 如果想在自己的网页使用的话，可以采取以下两种方法：JS 方法只需要在想要展示的标签加上   属性，随后在任何地方加上： 插入页面的显示结果是：××××××× ——「×××」形式。展示结果见侧栏。回调方法如果对   返回的格式不满意，可自行定义页面展示的格式：比如以下代码仅展示一言的主体部分：定义标签和函数： 随后将请求地址加上参数  ： 以上示例将会在 HTML 标签首个包含   的标签内部插入仅包含一言主体的部分。尾巴你看到某句熟悉的一言从屏幕上显示的时候，勾起了之前第一次看到这句话时或感动、或开心、或难过的回忆，而某个陌生人也会因此和你一样陷入属于他的短暂回忆——想到这些不是很快乐吗？而我想那个陌生人一定也正想着同样的事情。我一直这样觉得。而这，应当就是文字赋予一言的最大作用了。",
    "url": "/posts/a5c39267/"
  },
  {
    "title": "书推：雪中悍刀行",
    "date": 1494049554,
    "tags": "书推 文摘",
    "category": "文字阁",
    "content": "简介有个白狐儿脸，佩双刀绣冬春雷，要做那天下第一；湖底有白发老魁爱吃荤；缺门牙老仆背剑匣；山上有个骑青牛的年轻师叔祖，不敢下山；有个骑熊猫扛向日葵不太冷的少女杀手；这个江湖，高人出行要注重出尘装扮，女侠行走江湖要注意培养人气，宗派要跟庙堂打好关系；而主角，则潇洒带刀，把江湖捅了一个通透；江湖是一张珠帘。大人物小人物，是珠子，大故事小故事，是串线。情义二字，则是那些珠子的精气神。{% netease musicid=33544132 %}简评（转）年少时，看武侠电视剧里的侠踪剑影，总是莫名憧憬，甚至意犹未尽处，还会忍不住幻想自己是位飞流倜傥、快意恩仇的大侠，剑收于鞘时渊渟岳峙、剑起时又能挥出一片水银泻地云卷云舒。日思夜想久了，于是便在心中有了一片江湖，有了一场江湖梦。我想不止我是如此。有句老话说，一千个读者的心中，就有一千个哈姆雷特。同样的，一千个被现实社会的条条框框桎梏住的俗人们心间，便也有一千座不同的江湖。求名者得名、求利者得利、求快意者得快意、求安稳者得安稳——这些在现实中并不存在的江湖就像是我们圆梦的地方，我们被称之为“规矩”“方圆”“社会准则”的枷锁束缚得越紧，就越是想要在内心最深处那片江湖里翻江倒海自在逍遥。说白了，我们心中江湖上的那个状若侠客的自己，才是我们真正想成为的自己。但人生有太多弯路，太多不可回头的路，一步踏错便再无转圜的余地，南辕北撤说的便是这个道理——有时候回头看，我们一路行来的方向，竟是和最初的梦想背道而驰，可我们被所谓社会的进步、所谓年轻人的成熟、所谓命运的安排这一类的东西追迫着、驱赶着，又着实没有时间停下来感伤，于是渐行渐远、梦想和现实也被拉扯得越来越沧海桑田。到最后，我们的梦想，只剩下一副骨架、一副残骸，即是那座每每热血沸腾时便在心间浮起的海市蜃楼般的偌大一个江湖。在那个江湖里，我们是最自在最洒脱不羁的那位侠客。文摘李淳罡：大雨依旧磅礴。她不起身，徐凤年便一直撑着伞。老剑神李淳罡望向这一幕，瞪大眼睛。随即眼中黯然落寞缅怀追忆皆有。那一年背负那女子上斩魔台，一样是大雨天气，一样是撑伞。世人不知这位剑神当年被齐玄帧所误，木马牛被折并不算什么，只剩独臂也不算什么，这都不是李淳罡境界大跌的根由，哪怕在听潮亭下被困二十年，李淳罡也不曾走出那个自己的画地为牢。原本与世已是无敌，与己又当如何？李淳罡想起她临终时的容颜，当时她已说不出一个字，可今曰想来，不就是那不悔两字吗？李淳罡走到大雪坪崖畔，身后是一如他与绿袍女子场景的撑伞男女。她被一剑洞穿心胸时，曾惨白笑言：“天不生你李淳罡，很无趣呢。”李淳罡大声道：“剑来！”徽山所有剑士的数百佩剑一齐出鞘，向大雪坪飞来。龙虎山道士各式千柄桃木剑一概出鞘，浩浩荡荡飞向牯牛大岗。两拨飞剑。遮天蔽日。这一日，剑神李淳罡再入陆地剑仙境界。​​洪洗象：正在经楼找寻一部典籍的陈繇踉跄跑到窗口，颤颤巍巍推开窗户，老泪纵横，嘴唇颤抖道：“王师兄，小师弟成了！”山中炼丹的宋知命顾不得一鼎炉被凡人视作仙物的丹药，扑通一声跪下去，磕头道：“武当三十六弟子宋知命，恭迎祖师爷！”在东海寻觅到一名骨骼清奇闭关弟子的俞兴瑞，正坐蒲台上传授那名弟子内功心法，抚掌大笑，笑出了眼泪，激动万分道：“李玉釜，你掌教师叔终于要下山了！”七十二峰朝大顶，二十四涧水长流。其中最长一条飞流直下的瀑布犹如神助，低端被掀起拉直，通向毗邻那座唯有一名年轻道人修习天道的小莲花峰，瀑布如一条白练横贯长空，数万香客见到此景，仿佛置身仙境，更加寂静无声，偌大一座武当山，几乎落针可闻。水起作桥为谁横？齐仙侠亲眼见到古剑连鞘飞出太虚宫，尾随其后，沿着悬挂两峰峰顶水桥奔掠向小莲花峰，看到骑牛的怔怔靠着龟驼碑，喃喃自语：“今曰解签，宜下江南。”一身朴素道袍的洪洗象拍了拍尘土，骑上一只体型巨大的黄鹤，望向江南。江南好，最好是红衣。徐脂虎缓缓转头，问道：“你到底是谁？”  一直被寄予厚望去肩扛天道的年轻道士羞赧嚅喏道：“洪洗象啊。”徐脂虎重复问道：“你来做什么？”年轻道士壮着胆子说道：“那年在莲花峰，你说你想骑鹤。”她转过身，背对着这个胆小鬼。这个放言要斩断赵氏王朝气运的道人，深呼吸一口，笑道：“徐脂虎，我喜欢你。” “不管你信不信，我已经喜欢你七百年。” “所以这世上再没有人比我喜欢你更久了。” “下辈子，我还喜欢你。”丫鬟二乔眨巴眨巴水灵眸子，小脑袋一团浆糊，只看到小姐捂着嘴哭哭笑笑的，就更不懂了，唉，看来小姐说自己年纪小不懂事是真的呀。年轻道士伸出手，轻声道：“你想去哪里，我陪你。”这一曰，武当年轻掌教骑鹤至江南，与徐脂虎骑鹤远离江湖。仙人骑鹤下江南，才入江湖，便出江湖。年轻道士深呼吸一口，等女子依偎在他怀中，那柄横放在龟驼碑边缘的所谓吕祖佩剑出鞘，冲天而起，朝天穹激射而去，仿佛要直达天庭才罢休。九天之云滚滚下垂。整座武当山紫气浩荡。他朗声道：“贫道五百年前散人吕洞玄，五十年前龙虎山齐玄帧，如今武当洪洗象，已修得七百年功德。”“贫道立誓，愿为天地正道再修三百年！”“只求天地开一线，让徐脂虎飞升！”年轻道士声如洪钟，响彻天地间。“求徐脂虎乘鹤飞升！”黄鹤齐鸣。吕祖转世的年轻道士盘膝坐下，望着注定要兵解自己的那下坠一剑，笑着合上眼睛。陈繇等人不忍再看，老泪纵横。有一虹在剑落后，在年轻道士头顶生出，横跨大小莲花峰，绚烂无双。千年修行，只求再见。轩辕敬城：修身在正其心。莫道书生无胆气，敢叫天地沉入海。成事者，不惟有超世之才，亦必有坚韧不拔之志。轩辕青锋脑海中走马观灯，那些诗词文章一一浮现。“我入陆地神仙了。”轩辕敬城闭上眼睛，只见他七窍流血，却神情自若地双手摊开，似乎想要包容那整座天地。以他为圆心，大雪坪积水层层向外炸起。那一瞬间，有九道雷电由天庭而来。辕敬城每年酿当归酒三坛，两坛都让人送来庭院，自己只余一坛。所以他从来都是喝不够酒，而这里却是从来不喝，任由年年两坛酒搁着闲置，年复一年，酒坛子越多，酒香也愈发醇厚。她终于启封一坛酒，搬来一套尘封多年的酒具，酒具是那男人自制而成。   反正除了习武，那人仿佛没有不擅长的事情。独坐的她盛了一杯酒，放在桌上，好似对于喝不喝酒，犹豫不决，她没来由开始恼恨自己，伸手猛地拍掉酒杯。半响后她起身去拿回酒杯，才发现杯底刻有两行小字，字迹清逸出尘。人生当苦无妨，良人当归即好。许涌关：一刹那。瞎子老许头脑一片空白。他既然能活着走下累累白骨破百万的沙场，能是一个蠢蛋？在北凉，谁敢说这一句徐骁不过是驼背老卒？除了大柱国，还有谁？瞎子老许那一架需要拐杖才能行走的干枯身体剧烈颤颤巍巍起来。最后这位北凉赖活着的老卒竟是泪流满面，转过头，嘴唇颤抖，哽咽道：“大柱国？”那人并未承认也未否认，只是喊了一声瞎子老许：“许老弟。”只见瞎子老许如同癫狂，挣扎着起身，不顾大柱国的阻止，丢掉拐杖，跪于地上，用尽全身所有力气，用光了三十年转战六国的豪气，用光了十年苟延残喘的精神，死死压抑着一位老卒的激情哭腔，磕头道：“锦州十八-老字营之一，鱼鼓营末等骑卒，许涌关，参见徐将军！”锦州十八营，今曰已悉数无存，如那威名曰渐逝去的六百铁甲一样，年轻一些的北凉骑兵，最多只是听说一些热血翻涌的事迹。鱼鼓营。号称徐字旗下死战第一。最后一战便是那西垒壁，王妃缟素白衣如雪，双手敲鱼鼓营等人高的鱼龙鼓，一鼓作气拿下了离阳王朝的问鼎之战。近千人鱼鼓营死战不退，最终只活下来十六人，骑卒许涌关，便是在那场战役中失去一目，连箭带目一同拔去，拔而再战，直至昏死在死人堆中。其实，在老卒心中，大柱国也好，北凉王也罢，那都是外人才称呼的，心底还是愿意喊一声徐将军！被徐骁搀扶着重新坐在木墩上的瞎子老许，满脸泪水，却是笑着说道：“这辈子，活够了。徐将军，小卒斗胆问一句，那徐小子莫不是？”老卒脸贴着被大柱国亲手拿回的拐杖，重复呢喃道：“活够了，活够了……”鱼鼓营最后一人，老卒许涌关缓缓闭目。徐将军，王妃，有一个好儿子啊。我老许得下去找老兄弟们喝酒去了，与他们说一声，三十万北凉铁骑的马蹄声只会越来越让敌人胆寒，小不去，弱不了。徐字王旗下，鱼龙鼓响。老卒许涌关，死于安详。温华：一个时辰后黄龙士缓缓走下马车，马车渐渐远去，消失于风雪中。黄龙士没有急于入院，而是在巷弄来回走了两趟，这才推开门扉。短短一炷香后，一名年轻男子断一臂，瘸一腿，自断全身筋脉，只存一条性命，只拎上那柄原本就属于自己的木剑，离开了院子。巷中雪上长长一条血。“在老子家乡那边，借人钱财，借你十两就还得还十二三两，我温华的剑，是你教的，我废去全身武功，再还你一条手臂一条腿！”他在院中，就对那个黄老头说了这么一句话。然后这个雪中血人在拐角处颓然蹲下，手边只剩下一柄带血木剑。年轻游侠儿泪眼模糊，凄然一笑，站起身，拿木剑对准墙壁，狠狠折断。此后江湖再无温华的消息，这名才出江湖便已名动天下的木剑游侠儿，一夜之间，以最决然的苍凉姿态，离开了江湖。刺骨大雪中，他最后对自己说了一句。“不练剑了。”徐凤年：徐凤年闭上眼睛，双手搭在春雷上，有些明白一些事情了，为何徐骁如今还像个老农那般喜欢缝鞋？轩辕敬城本该像张巨鹿那般经略天下，最不济也可以去跟荀平靠拢，却被自己堵在了一家三口的家门以外，堵在了轩辕一姓的徽山之上，即使一举成为儒圣，仍是不曾跨出半步。骑牛的最终还是下了山，但这种下山与在山上，又有什么两样？羊皮裘李老头儿十六岁金刚十九岁指玄二十四岁达天象，为何断臂以后仍是在江上鬼门关为他当年的绿袍儿，几笑一飞剑？说到底，都是一个字。徐凤年想着她的酒窝，摇晃站起身。他就算不承认，也知道自己喜欢她。不喜欢，如何能看了那么多年，却也总是看不厌？只是不知道，原来是如此的喜欢。既然喜欢了，却没能说出口，那就别死在这里！徐凤年睁眼以后，拿袖口抹了抹血污，笑着喊道：“姜泥！老子喜欢你！”拓跋春隼冷笑不止，只不过再一次笑不出来。一名年轻女子御剑而来，身后有青衫儒士凌波微步，逍遥踏空。女子站在一柄长剑之上，在身陷必死之地的家伙身前悬空。她瞪眼怒道：“喊我做什么？不要脸！”李当心：唉，闺女，等你大些，就会明白只要在一个男人心中好看，你就是天下最好看的姑娘了。”“啊？可徐凤年说我长得一般呐，完了！”“闺女真是长大了，娘很欣慰呐。闺女，娘真不好看？不行，再下山一趟，还得买些胭脂水粉，多扑一些在脸上就好看了。”“娘你又乱花钱，爹肯定要跟笨南北蹲墙角唠叨去了，他们一起叨叨叨，可烦了。”“让他们叨叨去。哪天不叨了才不好。”这娘俩，似乎挺俗气。亏得各自身后爱慕着她们两个的光头，是那般佛气。小和尚将洗好的袈裟晾好，望向房内自语到，“又是一个天晴的好日子。李子，师父说我没悟性，你也说我笨，咱们寺里两个禅，我都不修。你便是我的禅，秀色可参。”千山以外是千山，这就是江山；六宫粉黛独看你，这就是美人。白衣僧人笑道：“去吧，睡觉去。” 小和尚嗯了一声，道：“东西怕打雷，我去门外给她念经去。” 白衣僧人摸了摸自己光头，这徒弟。站在千佛殿门口，看到在泥泞中奔跑顾不得雨水的笨南北，白衣僧人呢喃道：“笨南北啊，你有一禅，不负如来不负卿。少妇才喊完，嗖一下，一名白衣僧人就以屁滚尿流的姿态窜出那栋巍峨阁楼，来到少妇面前，笑呵呵道：“媳妇，走累了没，给敲敲腿？”若是外人在场，定要认为以这女子一路行来表现出的蛮横，肯定要好生拾掇一番白衣僧人才会罢休，但真见着了自己男人，她却是轻柔说道：“不累呢，只是好几天没见着你，有点想你啦。”本名原来是李当心的白衣僧人笑容醉人，也不说话。既然有她，天下无禅。",
    "url": "/posts/9a260fa1/"
  },
  {
    "title": "使用持续集成（CI）开发项目",
    "date": 1528510954,
    "tags": "CI 持续集成",
    "category": "分享境",
    "content": "我的博客在建站后不久就使用了 Travis CI 自动部署服务，即我只需要将修改的源码推送至 GitHub，Travis CI 会自动将我提交的代码拉取，在 Travis CI 端生成静态文件后，同步至我的服务器，这样可以减少一些麻烦的步骤：可以直接在 GitHub 端修改代码；不用等待生成静态文件、压缩静态文件的时间。Circle CI虽然使用 Travis CI 是能简化部分开发流程，但这货和 GitHub 是一对一的，只支持在 GitHub 托管的项目，并不支持 Bitbucket 和 GitLab，而 GitHub 免费版在私人仓库这一方面是比不上 Bitbucket 和 GitLab 的（虽然我是学生，可以使用 GitHub 私人仓库，可我也不一直是学生呀），同时支持 Bitbucket 的和 GitHub 私人仓库的 CI 工具（自建的除外）好像真的也就 CircleCI 了，这里之所以没有考虑 GitLab 是因为 GitLab 自带有 CI/CD，而且这家公司给我的印象实在不太好（包括之前的删库事件，以及莫名奇妙的 Bug）。在了解 CircleCI 后发现比 Travis CI 真是强不少（CircleCI 是基于 Docker 和 Workflows 设定模式的），不过在网上并没有很完善的中文教程~（虽然官方英文文档已经很完善了）~。所以如果你懒得翻官方文档的话，继续往下看我这篇文章就好了🤓。选择仓库CircleCI 支持 GitHub 和 Bitbucket 帐号的登录，授权登录完成后，就可以添加 Projects 了，支持 GitHub 和 Bitbucket 的公有及私有仓库。这里以我的 Meme-generator 仓库为例。选完仓库后，就可以开始配置 CircleCI 了。准备工作添加 SSH 密钥Meme-generator 仓库用到 SSH 密钥的地方有两处：从 GitHub 克隆仓库将编译后的静态文件推送至我的服务器如果你是用来推送至 GitHub 的话，可以直接用 GitHub 提供为该仓库提供的 Token 密钥，第一点也可以使用 HTTPS 方式克隆，就可以省去添加 SSH 密钥这个步骤。点击 CircleCI 个人主页的 JOBS 菜单项，随后点击仓库名称右边的齿轮按钮 -> 点击   -> 点击蓝色的   按钮，将私钥（看清楚了，是私钥）粘贴进去（超级良心有木有啊，比 Travis CI 将私钥加密上传这种土办法不知道高到哪里去了）。添加 IP 至 known_hosts添加 SSH 密钥后，还需要将服务器的 IP 添加至 known_hosts 列表，否则每次部署的时候都会让你确认以下消息： 同 Travis CI 类似，CircleCI 在运行的过程中也是不接受命令行输入的（当然运行完成后就更不行了），所以我们需要提前将 IP 写入 known_hosts（在 CircleCI 中如何做？继续往后看）： 在该仓库的管理页面中的   选项卡中添加 SSH_IP 的环境变量。配置文件简单的例子由于我的配置文件太过长了，先以一个简化版为例： 首先指明 CircleCI 的版本号——2.0（1.0 在 18 年 9 月之后就停止支持了）。其次，为 Docker 指定 image（这是官方已经构建完成的镜像列表），可以指定多个 image。先前提到过，CircleCI 并不默认像 Travis CI 那样提供 Linux 虚拟机镜像，推荐使用的是 Docker（当然你也可以指定工作方式为 Machine），这是官方针对 Docker 和 Machine 的对比报告。随后在   里面是需要运行的指令：  是一个用于检查配置路径的源代码的特殊步骤，并可以通过 SSH 来 clone 远程仓库的代码（如果你已经添加了 SSH 私钥的话，不然就只好手动 clone 了），详解见官方文档  后面接的是 bash 命令，  该任务的名称，  为具体 bash 的指令安装额外命令需要注意的是，如果你需要将生成的静态文件同步至服务器所用的   命令是没有被安装的，只有这些命令是被安装在所有镜像中的。docker 镜像预装的系统是 Ubuntu，可采取   命令来安装需要的软件包： 设置缓存CircleCI 建议的 Workflows 中建议将整个工作流分割成不同的子作业，比如说以 Yarn 项目为例，可以分成   和   两个流程。其中   用以安装依赖和生成待部署的静态文件；  用以将生成的静态文件部署至服务器。可以看出，静态文件是横跨两个作业的，所以我们需要将包含静态文件的文件夹缓存下来（当然你也可以选择不使用 Workflows，这样就只需创建一个工作就好了），在   工作中缓存采取如下命令： 以上命令是将   文件夹以   形式缓存，其中   选择的是   的哈希值。这里的文件名最好选择仓库自带的文件。更多   的形式可以参考这里。在   工作中恢复缓存采取以下命令： 注意在   之前一定要有   命令。完整的示例直接放 Meme-generator 项目的配置代码了：点我。每次构建完成后，commits 列表的画风就变成这样了：点击 Details 就会显示每次构建的详细过程。后记虽然本文名为「使用持续集成（CI）开发项目」，但实际却好像只介绍了 CircleCI，当然我的意思不是钦定 CircleCI 作为最好的持续集成系统，我没有说 CircleCI 是最好的持续集成系统，没有任何这个意思。但你一定要问我为什么选 CircleCI，它现在对 Bitbucket 和 GitHub 的私人仓库支持最完善，我怎么能不支持它呢？参考：2.0 Docs",
    "url": "/posts/f011ea9c/"
  },
  {
    "title": "导出 QQ 聊天记录",
    "date": 1498895853,
    "tags": "QQ Python",
    "category": "实验室",
    "content": "前言从 2013 年开始，手机 QQ 就已经不支持私人聊天记录的导出功能了（群聊的记录还是可以导出），目的当然是为了推广超级会员，毕竟超级会员的聊天记录有 2 年漫游时间，而不想给腾讯送钱的我，就只好另辟蹊径了。配合视频教程食用更加哦~：https://youtu.be/Y4y-UWg5vco准备我并不算是那种埋头造轮子的人，所以遇到问题总是先问谷歌，确实也寻找到了一些工具，可惜有的不能用能用的还要收费。看来还是需要自己动手（当然，不动手也就没有这篇文章了）。数据库位置安卓手机 QQ 的数据库文件保存在   下，所以需要 Root（更改 AndroidManifest.xml 的 debuggable 属性之后可以使用 adb 工具导出），这里并非本文的重点，就不展开说了。数据库里面不仅有聊天记录，基本上包括了 QQ 号的所有信息。不幸的是，里面的重要数据被加密了。加密方式另外很幸运的是，加密方式采用的是「异或加密」，而用于加密的字符串就是你手机的 IMEI，所有手机的 IMEI 都是不同的，这样也可以确保加密后的数据是唯一的，既然知道了加密方式和密钥，那么解密自然也就不是难事了。开始先想一下，我们聊天记录想导出成什么格式：我的想法是：  这样的格式。打开数据库文件：如下图，mr_friend_* *_New 就是你与每一个好友聊天的信息，包括昵称、备注、qq 号码、聊天记录等，直接查看就会发现是被加密过的。这一串 32 位的字符串就是 QQ 号码的 md5 值。由于 QQ 在手机端使用的数据库是 sqlite，Python 有很方便的 sqlite 的工具，而且 Python 针对字符串处理很方便，这里就采用 Python 来解密。用浏览工具打开数据库，以我的数据库为例：  保存的就是聊天记录，  就是聊天对象的 QQ 号码， 就是发送消息的时间，既然知道了这三个就是我们想要的，那么接下来的就好办多了，解密这三个就好了。解密既然牵扯到解密，自然也就逃不掉编码和解码。尤其是   项，确实是花费了我好久才解决（哼，我才不会说这是因为我对 Python 的编码不熟悉呢）。代码已托管至 Gist，见这里。参考：用 Python 解密手机 QQ 聊天记录",
    "url": "/posts/1060d444/"
  },
  {
    "title": "Linux 与 Android 同步剪贴板的通用方案",
    "date": 1547265683,
    "tags": "Clipboard 剪贴板",
    "category": "实验室",
    "content": "按照惯例，还是在每篇文章的开头扯几句不相关的：元旦前就从学校回家了，在家的十几天过得很是舒坦：闲的时候，上午玩两小时游戏或者看看直播，下午就看会 Coursera，晚上有时间就看部电影，没整段的空余时间就找朋友聊聊天、刷刷 V2EX；当然在不闲的时候也是做了一些事的，就比如本文将要说到的——让移动平台和桌面平台同步剪贴板的方案。我为什么想到做这个呢：两周前，我把用了一年半的 Manjaro 格式化了（忍受不了 KDE 巨多的 Bug，还有硬盘都被我用完了），装上了 Ubuntu，桌面环境选择了 Budgie——一个新出的 DE。比 GNOME 漂亮，比 KDE 稳定，稍加配置即可满足我这个强迫症的审美需求：从 KDE 转成 Budgie 之后，最让我不习惯的就是手机和电脑再也不能愉快地共享剪贴板和文件了，当然我也在网上找了一些现成的解决方案，但体验都不佳，于是我便考虑自己造一个轮子。设计思路由于移动端（客户端）、桌面端（服务端）二者需要进行数据的双向传输，HTTP 协议肯定是无法做到了：于是选用了 WebSocket 作为底层的传输协议。同时，为了让适用性更广，桌面端开发选择了 Golang；移动端则使用 React Native 开发。但这两门高级的语言（Golang、JavaScript）都无法为剪贴板添加监听事件，于是我只好自己用轮询的方式对比当前剪贴板的内容与上一次内容的差异，再考虑是否发送数据。桌面端桌面端的开发语言选择 Golang 其实我是有些不情愿的：太过高级：无法提供系统底层的 API（比如监控剪贴板）；语法太过丑陋：我想把 log 信息封装一下，结果用 struct 封装了半天，代码反而看起来更「💩」了，还不如用 Switch，可 Switch 导致暴露出的接口又不够简洁 . . .其它语言我也找了个遍：Python 虽可监听剪贴板的变化（通过 gi 这个库），但这个库并没有办法跨平台，且我 Windows 没有安装编程环境，我也不想安装。总之，能监听剪贴板的无法跨平台，能跨平台的无法监听剪贴板。So . . . 哪怕 Go 有万般不是，但在跨平台这一点的易用性上也足以让我抛弃其它的所有（纯静态链接库 + 交叉编译）。于是乎，「真香」。移动端其实我本想用 Flutter 来开发的，但遇到了一些问题：在我电脑上无法热加载，这在修改样式的时候可太难受了；Dart 似乎无法在已有的 WebSocket 连接上绑定一个新的连接，即使原来的连接已经失效了（不知是 Bug 还是咋样）。于是我选择了 React Native。有了 React 的基础，上手确实很快，并且 JavaScript 写起来感觉还是挺爽的。之所以会有刚刚提到的（重新绑定 WebSocket 的）需求，是因为在不同的网络环境中，电脑的 IP 可能有所改变，而我暂时想不到一个方法让手机自动识别同一网络的哪一台电脑使用了共享剪贴板的工具（逐一扫描 IP？那也太丑陋了）。所以在初始化连接时需要手动输入一次电脑的 IP 地址，随后地址信息会被保存，之后就不用再输入了。使用只需保持这两个软件在后台，会自动监控剪贴板的内容并发送。下载由于代码写的有点不满意，功能也不太完善，等以后有空重构之后加上文件共享功能，会开源的。这里先放出各平台的可执行程序：戳我👈。愿能有所帮助。",
    "url": "/posts/d691e748/"
  },
  {
    "title": "我的学生时代（大学篇）",
    "date": 1581327003,
    "tags": "感想 大学 学生时代",
    "category": "碎碎念",
    "content": "最近忽然有些念旧，想着距离写完我的学生时代（高中篇）也有大半年时间了，趁着前几天的创作欲还未散去，本文就好好聊聊我的大学时光吧（再不聊我都怕忘记了）。温馨提示：本文会有些长，会尽量按照发生时间的先后叙述，不过我无法保证本文的叙述具有 100% 的准确性，毕竟人的的记忆本来就不甚可靠。专业现在回想起来，应该是从高二开始吧，便对计算机（的某一分支）有兴趣了，当时沉迷于安卓系统的优化，比如：刷各种 XDA 的魔改内核、ROM 等，不过受限于条件，只是停留在使用别人修改好的软件包层次，并没有机会自己手动修改。应该还是在高二吧，上微机课的时候，老师会控制全班同学的电脑，不让我们自己玩，但唯独只有一个同学不会被控制。有一堂课（好像是在讲顺序分支循环那些，记不太清了），老师向我们解释到为什么不控制那个同学：「因为我上课讲的内容他都懂了，所以我让他自己玩」。当时就觉得这个同学好厉害啊，可能这时开始，一颗种子便埋在心底了。填志愿时，这颗种子经过了一年多的萌芽，已经慢慢开始生长了。于是乎，即使所有的亲戚朋友都反对，我仍是选择了计算机专业。大一九月入学，校园各大社团（包括学生会）都开启了招新活动，不过我一个都没参加，大概是因为性格散漫惯了吧，不想受到什么约束。大一上学期学了第一门与计算机相关的课：HTML 与 CSS3 基础，由于刚入学，课听得都很认真，在期末时交的静态网页作业拿到了全班最高分（直到之后很长一段时间，我都在因为这个事纠结我是从事前端还是后端），高等数学也考了满分，一时间有些膨胀了。这人嘛，膨胀了之后，会有一段时间觉得自己很牛逼，我在这段时间里（大概从大一下学期开始吧），开始上课不听讲了，甚至还伙同两三个同学逃了高数课跑去看校园十佳歌手，晚自习也不怎么去上了，学习态度的散漫，导致我这学期的成绩比上学期退步了许多（当然这是后话了）。也是在这段时间里，学院开设了第二门与计算机有关的课——C 语言，同时学院的  ACS 协会（别问我全称，我也不记得了～是一个与 ACM 竞赛相关的组织）开始招新了，招新的学长在台上说了一大堆加入协会的好处：找工作时各种大公司的内推、参加 ACM 竞赛可以获得加分（保研时有用）等等，虽然这些好处没怎么打动我，不过仍是稀里糊涂的就加入了协会（可能看着身边的人都加入了吧），开始了短暂的刷题生涯。在杭电上刷了五六十道题之后，我发现我对算法没什么兴趣，期间也曾尝试转到安卓组，发现还是没什么兴趣，于是便退了协会。在五月份，某大牛同学（初中开始编程）组了个队参加「互联网 +」创业创新大赛，我也加入了。目标是做一个考研的交友平台，可以根据个人信息推荐相似的研友，他负责推荐算法，我负责用爬虫采集数据，并清洗。当时第一次接触网络爬虫，也没有经验，只能在网上随便找个爬虫改改凑活着用，虽然最后这个项目只拿了校级的奖项，但是在这个过程中我发现我喜欢上爬虫了，于是我开始觉得要自学编程了。所谓「工欲善其事，必先利其器」，在学习之前，首先得要把环境搭好，上网看了一圈之后，决定装一个 Linux 系统（与 Windows 共存）专门用于编程，当时我对操作系统完全是一窍不通，导致在装完 Linux 系统之后重启直接回到了 Windows，百度后尝试了许多方法（比如：把 UEFI 模式改成 Legacy啊、用什么 Boot 编辑器啊），但都没什么卵用，逼得我甚至冒出了将 Windows 整个格式化掉的想法。最后还是在暑假期间解决了，还在简书写了一篇教程（一年之后居然有两万多浏览量），成功安装好双系统之后，我又开始像高中折腾安卓一样开始折腾 Linux 发行版的各种美化（真是死性不改😅）：Terminal 的美化，状态栏、主题图标的美化等等，原定好的学习编程计划也搁置了。如果时光可以倒流的话我一定会告诉当时的自己：「不要再花时间在这些没卵用的美化上了！快点学习吧！」，不过当时的我也肯定听不进去，毕竟颜值才是第一生产力～大二对大二上学期这段时间的记忆比较模糊，应该也并没有发生什么值得记录的大事吧：唯独对数据结构这门课印象很深，老师是我们院的副院长，可以看出他很懂数据结构，但是讲课不是特别好，不是很能吸引人，这门课我们全班的战绩都挺惨的，好像没有人超过 80 分。在大二的寒假期间，似乎终于想起了自己半年前好像就说要学习编程了，于是开始比较系统地学习 Python 了（大概是因为之前接触过爬虫，我对 Python 印象很好），在知乎上听说 MIT 6.0001 这门课用于入门 Python 不错，于是便开始看跟着视频一起学习，授课老师（MIT 计算机学院院长）讲得非常好，而我遇到理解不了的就用谷歌查，花了一个多月时间才差不多把这门课的内容学完。不过这一切都是值得的：本课程在我对计算机的理解还是一张白纸的时候并没有急着在上面写写画画，而是耐心地教了我怎么才画才算是正确的，换句话来说，本课会花很多的时间来培养你的计算思维，而一旦养成了计算思维，编程便不再是什么难事了。即使是现在，我依然会向所有想学习计算机的人推荐此课入门。到了大二下，印象比较深的课就是操作系统了，先前提到过，我在大一暑假时便开始接触 Linux，老师在得知了这个消息之后，某堂课上走到我身边悄悄对我说：给你两周时间，两周后的这节课，有半节课时间给你表演👿，题材不限，风格不限，和 Linux 相关就行。我花了两天时间好好准备了一下，还抄了一个 PPT，至于结果嘛，emmmm 反正挺尴尬了，因为下面的学生似乎都没在听，从这一点看，当老师还是考验人的～四月份（也有可能是五月份），学院组织了一个院级的算法比赛，闲着没事就参加了一下，看看许久没写算法是不是退化了许多（题目我是一道都不记得了），最后拿了一个二等奖，奖品是一个 32G 的 U 盘，感觉还不错～（只是我也并没有因此对算法提起多大兴趣。。五月初，一朋友说她（好吧，其实是当时的女朋友）正在尝试用 Hexo 搭博客，我搜了一下，之后，便有了这个博客～提问：搭好博客后最重要的一件事是什么呢？回答：当然还是美化啊～当时基本上把所有好看的 Hexo 主题都尝试了一遍（NexT、Yilia），最终还是决定了使用 NexT，选定好博客主题后的那两个月内非常高产地写了差不多十篇文章，应该是新鲜感作祟吧，很多文章都没什么营养，没多久便把大部分都删掉了。得益于博客的搭建，我的知识面被扩充了不少，也了解到了 SICP（Structure and Interpretation of Computer Programs）这本神作，在暑假前，我在图书馆借阅了这本书，花了一整个暑假的时间，却仍只读完了半本（读完了前两章，做完了习题），该怎么形容我那两个月的感受呢，感觉自己的编程世界观受到了冲击（也是在阅读第一章后，我彻底明白了递归与迭代的区别），感觉自己的脑回路好像都被重构了一样。一般来说，当我们在编写软件的时候（尤其是大型的软件），核心便是控制复杂度，而本书的核心——抽象，便是控制复杂度重要的手段。我在工作后接手了祖传的项目代码，才理解控制复杂度的重要性（当然这也是后话了）。在看完了 MIT 6.0001 后，如果你想成为一名更好的程序员，并打算继续深入，那么看看 SICP 这本书吧，不会错的。大三大三时，逃课开始变成了家常便饭（尤其是离散数学，但是我一学期没怎么去上过，期末反而还考了满分），不过数据库这门课我倒是每次都去上了（只是差不多每堂课都会迟到😅），因为授课老师就是上学期的操作系统的老师，对她印象还蛮好的（不过我现在还很奇怪的一点是为什么老师要教 SQL Server 而不是 MySQL 或者 PostgreSQL）。数据库课程分为理论课和上机课，由于上机课和理论课不在同一所教学楼，于是在理论课下课时便会和几个同学绕一大圈，逛逛校园，再慢慢地抵达上机课的教室，好在老师也不会说些什么。当时还有一门课是软件工程，遗憾的是软件工程的重要性是我在工作之后才明白，因此当时这门课我并没有去几次，而且老师一开始就说了这门课的考核标准：交一个系统上来就行了。于是断断续续花了两个月时间，读完了狗书（Flask Web开发：基于 Python 的 Web 应用开发实战），照着书上面的代码自己敲了一遍，也算清楚了 Python 的开发流程。除了了解 Python 开发之外，当时还针对 NexT 主题做了很多定制化操作，也借此学习了一下 JavaScript 中是如何使用 Template 的。大三的寒假正巧碰到搬瓦工上架了 19.9 刀的 CN2 套餐，于是毫不犹豫就下手了，从此我拥有了人生第一台服务器～有了服务器之后，最先做的事就是把博客挪到了服务器上，顺便折腾了一下 CI/CD；其次 Flask + SQLite 写的一言 API 也总是崩溃，于是就花了两天时间用 Golang 重写了一遍，数据库也换成了 MySQL，也部署到了服务器上（虽然服务器只有区区 512M 的内存，但是Go 这货还是真的省内存，满载时也不过 10M 的占用。到了大三下学期，更加的放飞自我了，专业课程只剩下编译原理了，不过真的好难啊（而且我当时还是已经通过 Lisp 了解了 AST），为了学好编译原理我还兴冲冲的去图书馆借了虎书准备好好研究一下，结果拿回寝室就吃灰了。。四月份，和高中那个微机课不被监控的同学交流时，得知他拿到了腾讯的暑期实习 Offer，给我羡慕得不要不要的。谈到职业生涯时，我也挺慌的，因为我甚至还没有想好是从事前端开发还是后端开发（因为当时正在学习 React，写了个项目练手，反响还挺好），更别说是具体的岗位了。大一的暑假是玩过去的，没必要担心，毕竟才第一年；大二的暑假是学过去的，一直在学 Lisp，感受着 Lisp 给我脑子带来的冲击。而大三暑假，则是最迷茫的一个暑假，一方面是在纠结自己的职业规划：前端还是后端？后端的话，我比较熟悉的语言只有 Python，但 Python 的岗位实在太少（且我不想转 Java）；前端的话我又没什么能拿得出手的项目。另一方面则是有些陷入了自我怀疑中：两年来，我将学习的重心放在自己感兴趣的方面这一决定是否正确，又或者我是不是应该好好完成学校的课程。大四大四上发生了一件特别有意思的事，一同学也在找工作，他说他暑假学了两个月 Spring，但现在对 Spring 基本还是一无所知，于是乎我和另一朋友「苦口婆心」劝了他一个晚上，终于劝他转 PHP 了，然后过了两个星期，他就找到了 PHP 的工作（没有任何黑 PHP 的意思😆）。随后，便是去杭州实习了，去杭的两个月可以看看杭州见闻这篇文章，这里不赘述了。从杭州回来之后，在学校呆了一个月，那一个月是我大学四年过得最放松的一个月：逃课也不用战战兢兢地担心被老师发现（当时还有一门 Python 的选修课，因为学分还没修满）、实习证明也顺利弄到手，更重要的是，这几个月的实习，驱散了我几个月前的自我怀疑，也明确了自己未来的职业规划。还有一个小插曲就是这门 Python 课了，由于我提前和老师打过招呼说我要去杭州实习，所以平时课去不了，老师说没关系，最后用 Python 写个东西交上来就行了。于是在最后一堂课，我把大三暑假复习计算机网络时写的一个静态 HTTP 服务器交了上去，并阐述了分别使用 Asyncio 和 Thread 实现的并发，结果老师说这个程序太复杂了，不相信这个程序是我写的（大概是觉得他一个教 Python 的都写不出来吧），费了好大力气甚至把 Github 页面都亮了出来他才相信。。大四寒假，主要是搞论文的事，选题时恰巧写业务写得有点烦（现在的工作对比来看，能安稳写业务真的很难得了），于是选了个文本情感分类方面的课题，当时还在 Coursera 上学习机器学习的课程，上到第五周的时候，往后翻了翻课表，发现并没有介绍文本分类之类的算法😒。于是便弃了这门课，改为自己找论文看着谷歌学，顺便学习了一下 Latex～顺便说一句，Latex 太适合我这种强迫症了～毕业前夕还发生了一件事：我发现学校的校园网络不登录居然也是有 IPv6 的地址的，且具有互联网的访问权限。嘿嘿，略加思考，便想到了一个可以薅学校羊毛的方法，原理很简单：需要保证有一台支持 IPv6 和 IPv4 的服务器就可以了，用这台服务器在本机和互联网之间中转一下，那么即使即使只有 IPv6 的互联网权限，也可访问 IPv4 的网站了。结尾毕业时，我罕见地有些不舍：不知是不舍这所学校、还是不舍同过窗的同学、抑或是不舍可能是最后一段学生时光。但应该还是不后悔的吧，虽然投入开源项目我付出了很多时间，但的确也扩充了我的知识和眼界，不过也不是说程序员就都要做开源，只是我个人确实通过做开源获得了很多提升：如果你能坚持在两年内，每天平均编程四个小时，我想你也会获得很多提升，而开源只是我坚持的动力罢了。大学四年里，我放弃了一些欲望，只想活得轻松一点。这欲望是指对保研的渴望（努力上课，好好听讲，参加各种竞赛）、对组织能力的锻炼（加入各种学生会、班委）等等，转而将精力投向了我所感兴趣的方面。当然我意思也不是说我现在多么成功，只是想说明，当你决定要跟从内心做自己喜欢的事时，接下来只需要坚持下去就好了。本系列正式完结（不排除有续作的可能，嘿嘿）～",
    "url": "/posts/71f1f91c/"
  },
  {
    "title": "Spacemacs 生存指北",
    "date": 1506402093,
    "tags": "Spacemacs 编辑器",
    "category": "分享境",
    "content": "简介Spacemacs 是一份 Emacs 的配置文件，将 Vim 的快捷键移植到了 Emacs 上，可以提供 Vimer 至 Emacs 的无缝衔接。有了 Spacemacs，你不需要花那么多时间去学习 Emacs 就可以真正用 Spacemacs 开始做一些事情。安装 Clone 至本地后，第一次使用 Spacemacs 时要加载一些 Package，以及根据你的喜好所生成的配置，建议一路回车。此时会加载很多的 Package，如果没有挂代理的话，就会很慢很慢，可以采用 emacs-china 的配置源。快捷键Spacemacs 基本使用的是原生 Vim 的快捷键，此前请先熟悉 Vim 的操作。我这里只贴出个人认为比较常用的快捷键。配置文件  快速打开配置文件  同步配置文件  退出 Emacs  重启 Emacs文件管理  打开文件  neotree 方式显示文件路径  搜索当前文件（需安装 ivy layer）  另一种搜索文件的姿势（需将光标置于需搜索的单词处）   下一个匹配  前一个匹配  改变范围：当前屏幕，当前函数，当前 buffer  编辑所有匹配（类似于替换）  在当前 project 搜索  清除搜索高亮  重命名当前文件  使用 sudo 来编辑文件（当某些文件的权限是只读的时候）  删除当前文件  打开最近文件列表（需安装 ivy layer）  复制当前文件的绝对路径  复制文件buffer 管理  显示已经打开的 buffer  关闭当前 buffer  进入 Spacemacs 初始界面  新建一个 buffer  从自动备份的文件中恢复  复制整个 buffer 的内容  将剪贴板的内容粘贴到整个 buffer  切换至上一个 buffer窗口管理  跳转至第 n 号窗口  跳转至 neotree 侧边栏  当前窗口最大化  或   水平分割窗口  或   竖直分割窗口  平衡窗口  删除当前窗口  切换至其他窗口  将当前窗口与其他窗口 黄金分割project 管理  在当前 project 中查找文件  切换项目  在该项目中搜索字符串  在项目中替换字符串，先输入「匹配」的，再输入「替换」的字符串（我一般不使用这种方式，我用 来替换）缩进代码  自动对齐  美化代码（不适用于所有语言）shell 操作  打开/关闭 Eshell（需安装 shell layer）  打开其它种类的 Shell中断操作  输错命令时，可取消该次输入显示动态行号将    的值改为 'relativeMagitSpacemacs 中集成了 Git 管理工具，需先安装 git layer。常用的快捷键：| git                    | magit               ||  | - ||               |             ||             |             ||                |   弹出然后按   ||   |               ||             |           ||               |             ||                |           ||       |            ||    |   弹出然后按   ||   |   弹出然后按   |守护模式终端使用   以守护模式开启 emacs：  打开 Emacs GUI  打开 命令行 Emacs当开启守护进程时，点击关闭按钮后进程还是会保留在后台，如果想要彻底关闭 Emacs 可以：  或者 以下是我针对我常用的一些语言做的一些特殊的设置：C/C++我没有采用 Spacemacs 提供的 c/c++ layer，而是采用的 Irony-Mode，因为原生的 c/c++ layer 自动补全需要 ycmd，而 ycmd 安装配置起来实在太麻烦了。快捷键  启用 gdb 调试  编译程序默认是用   编译，可以替换成   （这些参数会被记住）PythonPython 用的 Spacemacs 自带的 python layer，添加了一些参数： 快捷键  运行当前文件  美化代码  打开 IPython repl  跳转至定义处：  在当前窗口跳转至定义处  在另一窗口跳转至定义处  回到原处  将当前文件发送至 repl:  将当前 buffer 发送至 repl  将当前 defun 发送至 repl  将当前选中内容发送至 replJavaScript我将 JavaScript layer 自带的 repl 换成了 nodejs，自带的不太好用。 设置了一些快捷键：(o 开始的默认为用户自定义的)  启动 nodejs repl  将当前 buffer 发送至 repl  将选中内容发送至 repl  将当前行发送至 replScheme我是在学 sicp 时才用到 Scheme，所以采用的 Scheme 实现是 MIT-Scheme，并将其设置为默认 repl：快捷键  切换至 repl  评估算式：  计算当前 buffer  计算最后一个表达式  计算当前定义的函数  计算当前选中的内容结语我的 Spacemacs 配置放在了 GitHub 上，这是地址。",
    "url": "/posts/2aa541e6/"
  },
  {
    "title": "Python 并发之痛：线程，协程？",
    "date": 1601383409,
    "tags": "Python asyncio 并发",
    "category": "分享境",
    "content": "算算日子，我又有两个多月没有写新文章了，是时候给博客除除草了——拖更的原因是（ 懒 ）换了一份新的工作，在适应新的工作与生活环境。在入职奇安信（上一份工作）的时候，有半年的时间没有更新博客，当时的我把原因归咎于公司 push 员工太厉害，导致员工没有属于自己的空间；可现在的工作明明给予了我足够的空间，我却还是两个多月没有新文章产出，看来个人方面也有一定的原因。废话好像有点太多了，本篇文章准备分享一下最近工作上遇到的问题以及解决办法。起因起因是部门产品的图相关部分的 API 查询（使用 GraphQL 自己实现的）太慢，一次普通的查询往往在后端会解析成十几个不同的子查询，子查询的内容上没有相关性；涉及的数据源也大相径庭，包括：MongoDB、ClickHouse，以及其他产品的 Web API，因此也无法通过关联查询减少查询次数。由于子查询太多，即使每一条子查询耗时都能控制在 300 毫秒内，那一条完整的查询也会耗费将近 5 秒的时间（来自十几个子查询耗时的叠加），这显然不正常。如果能将十几个子查询的方式从「顺序」改成「并发」就好了。因此我很自然的想到了使用 asyncio 来实现并发的查询，而 GraphQL 也提供了 AsyncioExecutor 的方式来异步执行查询语句，但是正当我沾沾自喜以为这个问题就这么从理论上解决了的时候——开发负责人告知只有图相关的 API 需要改成异步方式，其他的 API 保持不变，并说出了基于两个方面的考量：大部分其他 API 只是针对一个数据源查询，不会像图一样有十几条子查询，换成异步并不能提升单次查询的性能；将其他的 API 都换成异步工作量太大，且需要测试各种兼容性，再结合上一条原因，得不偿失。但直觉上，我认为如果只是将图相关的 API 改成异步，在后续可能会出问题，但具体为什么会出问题、以及出什么问题我还不知道，因此就先着手试试。迁移的过程比我想象中要轻松很多——motor、aiochclient、aiohttp 等库已经很成熟了，在这些异步库上封装一层与现使用的同步库的兼容层就行了。问题花费了一周时间，在本地测试没什么问题之后就放到了线上先让系统运行着测试。头几天没出什么问题，在我以为这个问题就这么完美的解决了并准备做其他事的时候，前端突然找到我说查询请求会报一个很奇怪的错误，复现的概率不高，但有时候就会出现，我心里咯噔一下，感觉是之前异步改造不完全造成的问题。在前端发给我看具体报错之后，我确认了的确是和异步相关的问题。错误信息相信大多数接触过 asyncio 的都看过，这差不多是 asyncio 里最常见的错误之一了： 。和前端沟通后，在我本地的开发环境上却没有复现此 bug，因此我认为应该是生产环境上部署的工具与 asyncio 冲突了。部署的方式与其他 Python Web 端程序并没有什么区别，WSGI 服务器使用的是 Gunicorn，worker_class 设置为 sync（一共开启 6 个），每个 worker 开启了 20 个 threads，一开始我怀疑是 worker_class 的问题，可将其设置为 gevent 之后，仍然会出现这个错误，我开始觉得有点棘手了。吐槽在出现这个问题的时候，我就和朋友吐槽过，Python 这门语言真的是太割裂了（Python 2 和 3 版本间的割裂就不用说了），公司产品和开源社区完全就是两个极端：开源社区一个新 Feature 接一个发布，可大多数公司仍然守着 Python 2 不肯升级，原因也很简单：Python 3 对比 2 最大的更新就是 asyncio，可这玩意所解决的痛点相比 Python 2 升级 3 耗费的精力实在太微不足道了——Python 2 使用 monkey patch 一下再使用 gevent，也比用 asyncio 慢不了多少吧，既然如此，那我还费心思升级干啥？往远了说，我认为这仍然是 Python 的历史包袱仍然没有完全甩掉（即使 Python 3 在发布的时候宣称想甩掉一些历史包袱从而决定不兼容 Python 2），也是我认为 Python 最大的痛点——并发的问题。既然 Python 之禅宣称做「最好是只有一种方法来做一件事」，此话也被社区奉为圭臬，那为什么 thread，process，greenlet，asyncio 都可以用来实现并发这件事呢？要我说就应该在 Python 3 问世的时候甩包袱甩得更彻底一些，干脆就像 Node.JS、Go 一样，想用并发？可以，只提供一种方式，想直接调用系统原生的线程？不好意思，没这种操作。让用户只用一种方法做一件事的最好办法就是不提供其他的方法。在 Linux kernel 2.6 版本正式引入 IO 多路复用的时候，Python 2.4 已经发布，各种功能已经很完善了，不太可能抛弃掉现有的多线程模型转而投向异步 IO 模型。如果将此时作为分水岭的话，在这之前就诞生的语言（Python，Java，C/C++）大多都是使用内核提供的多线程实现的并发模型，而在这之后诞生的语言（Node.JS、Go 等）大多是自己实现的并发模型。而 Python 则因为 GIL（Global Interpreter Lock）的存在，即使提供的是系统内核级的多线程也无法像 Java 一样实现并行处理，所以 Python 的并发一直都为人诟病。而同为解释型语言的 Node.JS，人家压根就没多线程这玩意，所有 IO 事件都放在一个事件循环里跑，和 GIL 河水不犯井水。这也是为什么我说 Python 仍然具有一定的历史包袱的原因。定位在确定了是 Gunicorn 与 asyncio 的冲突之后，我开启了 asyncio 的 debug 模式，希望能从中获取一些有用的信息，果然，一个新的错误出现了： ，报错文件是：  中的  ，此方法是一个非线程安全的方法，因此在开启了 debug 的情况下，会  。报错原因则是   函数会检测当前线程是否是 event loop（事件循环）运行中的线程。那么，event loop（事件循环）可能会在其他的线程调用吗？——一般情况是不会的，对于大多数程序而言，有异步 IO 处理并发就够了，不需要再使用线程了。但是，基于上面的两点考虑，我们不得不选择在使用 asyncio 的情况下再额外使用线程。这里的线程其实是广义的概念，并非指的是系统级别的线程，gevent patch 之后的 gthread 也算在内。在我们的项目里，event loop 是作为 module 级别的变量声明的，按照 Python 的内存管理，是存放在私有堆上的，因此从同一个 Gunicorn worker 里衍生的线程自然会共享这个变量。也就是说出现这个错误的原因在于当前的线程操作了由另一个线程（通常是主线程）创建的 event loop。可以更具体的解释为：  调用了   方法，此方法会对 loop 进行  和   检测。而最先开始的   报错就是   时抛出的。解决问题定位到之后，解决就很简单了。既然多线程一定要使用，那么将 call_soon 换成线程安全的   就好了。  里的   也需要换成  ，该函数可以向指定的事件循环提交 coroutine。这两处需要修改 GraphQL 相关库的源代码的地方可以使用 monkey patch 的方式修改。除此之外，event loop 的创建也需要改一下，不能直接通过   来获取了，需要把它专门放在一个线程里  （因为   会使用   检测 loop 的状态，所以需要保证 loop 一直处于 running 状态，而   这个操作是阻塞的，所以需要另起一个线程），然后由其他的线程向它提交： 结语从接触 Python 到现在，已经有近四年的时间了。最初觉得它语法简洁、标准库功能齐全，工作了一段时候后又觉得动态类型的有些不便以及写法过于开放难以维护，再到最近感受到协程与线程的并发之痛，不知是否是因为我的水平逐渐变高，越来越能发现 Python 的不足。对于把编程语言当做是一种工具的人来说，发现工具的不足或者不好的地方之后，只需要换一种工具就好了，只是我始终没有把编程语只当做是工具，更喜欢把它当成一门「手艺」，所以我自然希望这门「手艺」使用起来越顺心越好。吐完槽冷静下来后，我也尝试站在 Python 开发者的角度想，如果真的完全不顾历史包袱，不管和老版本的兼容性，那似乎就相当于创建了一门新的语言了。而假如未来真的有某一版本的 Python 完全没有历史包袱，又拿什么去吸引用户做迁移呢？我想这也是最初 Python 3 发布的新特性也会向 2.6 和 2.7 版本添加的原因吧。所以如果要问我为什么喜欢 Python 反而还大力的吐槽，我想是因为我真的希望它变得更好吧。",
    "url": "/posts/c12de45e/"
  },
  {
    "title": "使用 OpenCore 引导黑苹果踩坑记录",
    "date": 1587560539,
    "tags": "黑苹果 OpenCore Hackintosh Bootcamp",
    "category": "实验室",
    "content": "从大一暑假开始，我便一直使用 Linux 作为日常所用的系统，这三年要说我用 Linux 如何顺心，那绝对是鬼话；可要说我使用得特别难受，那也不至于。因为它的确提升了我的开发体验和编程技能。它的优点我很喜欢、它的缺点我一开始就知道并能接受——这便是我能坚持使用 Linux 三年的原因。虽然坚持使用了这么久，可我还是要说一句 Linux 作为日常使用的系统真的很不方便，而不方便就会想要去折腾，折腾来折腾去发现时间都浪费了，它还是老样子；可使用 Windows 吧，看着丑哭的字体渲染和残废的命令行工具，感觉自己写代码都没什么动力了，所以当我第一次见到 macOS 时，我在心里就默默地种草了。种草容易拔草难啊，这一拔就拔了三年。说起来是有些奇怪，明明我这么想用 macOS，为什么不直接买一台 Mac 呢，其实是因为我对 Windows 还有需要：闲暇时我也会打打游戏，而购置一台用于打游戏顺畅的 Mac，恐怕就只能从 (i)Mac Pro 起步了——我肯定是不会买的。于是，我选择了黑苹果。配置单按照 Tonymacx86 的说法，黑苹果最好选用八代或九代的 Intel CPU ➕ AMD 的显卡配合 Z390 芯片的主板。本节的撰写时间是 2019 年 9 月，以下是当时的价格，仅供参考：| 配件 | 型号                       | 价格（¥） ||  |  | - || CPU  | Intel 9700KF               | 2499      || 显卡 | AMD Vega 56                | 1600      || 固态 | 西部数据黑盘 512G          | 614       || 散热 | ID-COOLING CHROMAFLOW 240  | 359       || 电源 | 全汗 MS600                 | 599       || 主板 | 技嘉 Z390 I AORUS PRO WIFI | 1319      || 内存 | 海盗船 DDR4 3000           | 718       || 机箱 | Sunmilo T03（定制）        | 939       || 合计 |                            | 8647      |在本文发布时候，我已经使用基于 Clover 引导的黑苹果半年时间了，最近突然手贱升级了 Catalina 导致系统挂了，所以才想干脆放弃 Clover，转向 OpenCore，于是便有了这篇文章。 ⚠️：如果你是 OpenCore 纯新手，强烈建议先读读我文末的几篇文章。否则可能会看不懂这篇文章在说什么。ACPI 相关ACPI 的补丁会被 patched 到 OpenCore 引导的所有系统，因此某些非必须的补丁（比如 SSDT-USBX.aml）不建议在 ACPI 中加入，不然可能会造成其他系统无法启动等情况。DSDT 提取目前比较推崇的提取 DSDT 的方式是采用 Clover 来提取，因为这种方法能提取出原生的未曾被 patched 过的 ACPI，但这对从未安装过 Clover 引导的人有些麻烦：需要在 U 盘上创建一个 Clover 的 EFI 分区。由于 ACPI 的补丁范围并非针对单一的操作系统，因此在使用 OpenCore 引导的系统中提取到的 DSDT 可能并非原生的，不过如果你未曾修补过你的 ACPI，也没使用过黑苹果，可以考虑使用 SSDTTime 工具来提取 DSDT（支持 Windows 和 Linux，不支持 macOS）：双击 SSDTTime.bat（需要 Python 3 环境），选 4 来提取 DSDT： DSDT.aml 会被提取到脚本目录的 Results 目录下。### 注入原生电源管理SSDT-PLUG.aml（名字并无限制） 补丁是用于支持原生的 CPU 电源管理。使用 SSDTTime 进行生成：运行 ./SSDTTime.command（SSDTTime.bat） 输入 「3」后，将 DSDT.aml 拖入当前终端窗口，并 Enter : SSDT-PLUG.aml 会自动生成在 Results 文件夹： 开启原生 NVRAMSSDT-PMC.aml（名字并无限制）补丁是用于开启主板原生的 NVRAM 支持。使用方法见 xjn 这篇文章的 3.12 节。如果你的主板和我的一样，可以直接使用我的 SSDT-PMC.aml 文件。加载了 SSDT-PMC.aml 之后，「系统偏好设置-节能」里面能看到五个选项——未加载 PMC.aml 之前只有 4 项；未加载 PLUG.aml 之前只有两项。如果没有开启（模拟或者原生）的 NVRAM，系统可能会出现以下问题：关机或者重启非常慢且功能错位：明明点了关机，却触发了重启；睡眠唤醒之后屏幕在鼠标键盘失灵，屏幕冻住（freezing），然后重启。定制 USB 端口由于 OpenCore 的配置比较追求轻量化，因此一些人在将 Clover 换成 OpenCore 的时候可能会出现一些 USB 设备失灵的问题：鼠标和键盘的指示灯都没有亮，显示没有通电。这里可以使用 SSDT-USBX.aml 来解决这个问题，但是并不推荐，原因之前也说过了，ACPI 的补丁对 Windows 也是适用的，而 Windows 压根不需要这个 USBX 的补丁，并且这个补丁有一个 bug（feature？）：它会将所有的 USB 设备识别成内置的接口，即使你插入的是 U 盘。一旦系统将 U 盘识别成内置的硬盘，就无法使用 Mac 自带的「启动转换助理」来刻录 Windwos 系统盘了（这一点下一节会详细讲）。除了使用 ACPI 补丁之外，还可以使用 macOS 内核扩展（kext）来解决这个问题：首先使用 USBInjectAll.kext 来设置所有 USB 接口为外置 USB，确保系统能正常使用；然后打开 Hackintool 的 USB 选项卡，随后将主板的所有 USB 逐个插一遍，将非活动端口删掉，并使用连接器定制每个端口的类型。随后点击导出图标，会导出 USBPorts.kext 和几个 ACPI 补丁到桌面，在 config.plist 里面加载 USBPorts.kext，并停掉 USBInjectAll.kext 就可以了。双系统引导戳这里观看双系统使用 Bootcamp 引导的视频。在使用 Clover 引导的时候，需要将 CLOVERX64.efi 设置为默认的引导，在使用 OpenCore 的时候稍稍有点不一样，不需要且不能在 Windows 直接使用 bcdedit 命令更改 Path 为 OpenCore 自带 BOOTx64.efi 的值。安装 Windows如果你电脑目前已经安装了 Windows，直接看下一节。下载 Windows 10 ISO 镜像，插入 U 盘，打开「启动转换助理」，将三个勾全部选上，点击继续。如果启动转换助理没有报错的话，会让你选择分给 Windows 的硬盘空间。选择完了之后会重启。如果在下载 Windows 支持软件的时候，提示无法连接到服务器的话，依次选择左上角的 操作菜单 -> 下载 Windows 支持软件，路径选择 U 盘。此时也需手动使用磁盘工具分区出一块 Windows 所用的硬盘。重启后，一定要继续使用 OpenCore 引导，而不要按 F12 直接进入 U 盘的引导。在 OpenCore 引导选择界面应该会看到名为「 U 盘的名称（external）」的引导项。选择它，就会进入系统安装的界面了。安装完 Windows 之后，系统会自动重启，重新进入引导选择界面的时候，会看到多了一个名为 Windows 的引导项（排名应该只在 U 盘名称的后面一位），选择它。Windows 修复引导如果在选择 Windows 启动时提示「ocb-startimage-failed-already-started」，别慌，这是因为 OpenCore 不知道从哪引导 Windows，你需要手动指定一下：进入 macOS，在 config.plist 的 Misc -> BlessOverride 添加一项：「\\EFI\\Microsoft\\Boot\\bootmgfw.efi」。这时再重启，应该就可以正常进入 Windows 了。正常进入系统之后，将 U 盘里刚刚下载的 Windows 支持软件安装（文件夹名称应该是 WindowsSupport，文件是 setup.exe，双击安装），安装后会要求重启。重启时在 OpenCore 引导菜单时选择进入 Windows，进入系统后，右下角应该会显示 Bootcamp 的运行图标，选择重启到 macOS，应该就能正常重启到 macOS 了。需要注意的是：如果没有开启 NVRAM，是没办法做到这一点的：Windows 使用 Bootcamp 重启到 Mac，Mac 使用启动磁盘重启到 Windows，因为无法使用 NVRAM 来指定开机时的启动项。参考：iShengP 的 Z370F + i7–8700K + RX570 Hackintosh Build 黑蘋果建置 (Catalina ver. with OpenCore)使用 OpenCore 引导黑苹果精解OpenCore",
    "url": "/posts/7a2a84c6/"
  },
  {
    "title": "端午记",
    "date": 1495901360,
    "tags": "随感 日记",
    "category": "碎碎念",
    "content": "5 月马上就要过去似乎还没开始的这个学期，怎么就快结束了时间怎么这么快？长眠于 4 月之前的海子，对于时间，有一个生动的说法叫「打马而过」有时觉得，这种匀速流淌不可改变的东西，才是真 TMD 残忍。雨滴的出生到结束，就是从天空落向大地似乎它的宿命就是滴落大地回到家中，躺在沙发上空气中弥漫着「熟悉的味道」想必那就是家的味道吧？临近期末似乎应该很担心成绩挂科我理想中的大学不是这样的我讨厌把自己的能力和思考，都锁在一个 for 循环里循环的条件是：你是一个大学生那样该多无趣啊我想 break，就像现在躺在沙发上可以暂时跳出这个循环突兀的断网调试了许久之后终于意识到可能没有网了这是 break 出循环的代价？在家里总可以敞开去吃喝啤酒到胃涨还能强迫去吃饭吃的饱了总算能真切感受到自己不在循环里明媚而灿烂的五月啊要是心情烦躁的时候，写写博客吧这也是断网唯一能做的开心事了",
    "url": "/posts/859c63e4/"
  },
  {
    "title": "离职的两个月之后",
    "date": 1590129612,
    "tags": "离职 工作 计划 思考",
    "category": "碎碎念",
    "content": "三月下旬的离职，已经是两个月前的事了。在那之后我没有立刻开始寻求一份新工作，客观原因是考虑到我正处于疫情的中心地带——湖北；主观原因则是在调整自己的状态：想让自己完全从上一份工作状态里抽离出来——时隔两月，我总算可以比较客观、冷静地谈论起离职这件事了。在前公司的状况我的 leader 并非是技术出身，对因产品迭代而产生的技术问题往往视而不见，因此划定上线（提测）的日期往往非常紧迫，加班加点也只能堪堪完成功能上的开发，也就让员工不得不忽略代码质量的好坏与软件设计的正确与否。当然，由于我们组的外包人员非常多（占 80%），就算给他们更多的时间，他们也不一定有能力写出更好质量的代码或做出正确的设计，不过这并不是可以破罐子破摔的理由。目前产品使用的 Web 框架是部门 VP 在五年前根据 Flask 定制的，把开发流程全部封装得严严实实：只需要继承一个 class 并将 URL 参数放在重写的 get、post 等方法的参数列表里，然后将 URL 加入某 YAML 文件里面，就可以开始编写业务逻辑了。你不用明白框架是如何将 class 注册为对应 URL 的视图函数，也不用明白如何从 URL 参数里取出和函数参数对应的名称的值并校验值的范围、类型，只需要写业务代码就行了，像极了流水线上的工人。代码质量的低下以及框架本身偏向业务的定制加速了架构问题的产生：目前的系统甚至无法支撑十个用户的同时访问。原因在于框架一开始就没有考虑到并发，部署时也是使用的 FastCGI（单线程） + Nginx，Python 2.7 又无法使用 asyncio。同时，代码的规模越来越大、历史包袱愈堆愈多，而架构却无甚改进，导致目前的系统已经完全不能在本地运行起来了，这给调试带来了非常大的困难——只能把代码替换到服务器上运行（还不能打包替换，因为环境并不是你一个人在用），然后看日志。离职的原因离职的最主要原因是 leader 的管理理念与我个人的职业发展理念不符：他过分强调业务（KPI）的重要性，只在乎可量化的指标，例如：何时提测、功能是否完备；而对：架构的改进、代码的质量、用户的体验等非量化指标完全不在乎。具体总结后的原因如下：公司不重视技术，招了很多很水的外包，导致产品的代码质量很差；领导对开发时间错误估计，以及人员良莠不齐导致加班很多（经历过两个多月的 996）；框架无改进、开发流程不规范，导致历史包袱愈堆愈多，开发、Debug、部署的负担也越来越重；只在乎 KPI，不在乎产品的具体实现和体验，如：某页面请求加载十几秒都不在乎。这些原因既是我离职的原因，也是我认为目前产品的症结所在。我曾向 leader 指出这些弊端，并给出了解决方案，但 leader 想都没想就以当前项目太紧为由驳回了。看，领导根本不在乎这些，只要保证提测时产品本身是差不多可用的就行了，代码质量？那是什么，KPI 里有写吗？但我仍然相信，这些弊病迟早会拖垮这个产品，只是我没有必要等着这一天的来临罢了。这样的管理理念磨灭了我钻研技术的热情，也违背了我做技术的初衷（从入职后的四五个月里 Github 的 contributiosn 基本为 0 可以看出），因此我选择离开。两个月我做了什么在下定决心辞职之前，我也想过在论坛发一个帖子，询问我这样的状态是否应该辞职，后来想明白了：为什么我的人生需要其它素不相识的人来决定，或者难道大部分人劝我忍一忍我就真的能安心干下去了吗？答案是否定的。想明白了这一点，我便直接裸辞了。离职之后我在技术方面做了这些事：阅读了《Kubernetes in Action》这本书，学习了 K8S，并在我的项目 DIEM-API 上实践了；在 Coursera 上完成了《Algorithm, Part I》课程的所有内容，完成了《Algorithm, Part II》课程的前两周内容；完成了 MIT 6.824《Distributed Systems》第一个 Lab MapReduce 的内容；重构了 Github 上的几个项目的代码，这段期间的 contributions 基本保持全绿。这些内容对我的提升比我在公司八个月所获得的更多，因此我也并没有因为辞职而后悔。总结 & 打算离职就算不是一件光明正大的事，至少也并不需要讳莫如深：我对公司并没有什么怨念，同事之间也相处得很愉快，只是这些并不在本文的讨论范畴。毕竟离职的原因肯定不是因为公司对你太好了，而是因为公司有些毛病你无法忍受却又无力改变，因此只能选择离开。毕业前因为想离家近，所以我选择了武汉；而接下来，我想的下一份工作能让我的价值得到比较好的展现。更进一步的讲，我想做一些更贴近用户的产品、一些用户真正需要的产品，能让用户的生活更加舒心，也可以满足我个人的成就感。",
    "url": "/posts/ee6b678/"
  },
  {
    "title": "基于 Socket 编写 HTTP 服务器",
    "date": 1533269173,
    "tags": "Socket 异步 HTTP 服务器",
    "category": "实验室",
    "content": "在大二上《计算机网络》这门课的时候，由于并不是很喜欢这门课的老师，导致我在上课的大部分时间都在摸鱼~（啊喂，学校教的哪门课你没在摸鱼啊？）~。最近看了《图解HTTP》这本书，借这本书正好也复习了一下应用层和传输层协议，毕竟现在的 Web 应用几乎都是在应用层的 HTTP 协议运行的，而 HTTP 又是基于传输层的 TCP 协议来实现的。我一直认为检验学习新知识是否牢靠最好的方法就是写一个小的实例，于是乎，借助于 Socket 模块（仅对 BSD Sockets API 进行封装），我也实现了一个静态的 HTTP 服务器，当然，比标准库提供的 SimpleHTTP 要强一点，因为我编写的支持并发。源码见这里。Socket 服务器SocketHTTP 协议是基于 TCP 协议来实现的，也就是说要实现 HTTP 服务器首先就需要先创建一个 TCP 连接，而一个完整的 TCP 连接是同时需要客户端和服务端的，而客户端和服务端的创建，就需要借助 Socket（套接字）了。通常创建一个 Socket 需要为其指定地址族（包括本机、IPV4、IPV6）、套接字类型（流式、数据报式，分别对应 TCP 和 UDP） 随后需要为该   绑定一个 IP 地址和端口，并开始监听该地址（listen 可传入参数，表示排队连接的数量）： 随后，就可以等待客户端发起连接请求了： 随后该连接会阻塞，直到 accept 到客户端的连接之后（客户端可使用   来连接），随后程序就会继续运行，这时就可以通过 socket 连接来传输数据了，在 telnet 输入任何字符，随后在客户端接收，再响应请求： 封装我们后续编写 HTTP 服务器仍是基于这一套流程，只是在客户端请求和服务端应答的内容不一样，故而封装成一个类，方便继承，以下为一个回显服务端，从客户端接收到的任何消息都会将其返回： 测试用例 HTTP 服务器HTTP 报文那么有了 TCP 连接，该怎么实现 HTTP 协议呢，其实很简单，HTTP 协议只是在传输的内容上做了规定：满足「报文首部」、「空行」、「报文主体」，这样通过服务器发出去就算是一个 HTTP 报文了，不信？试试就知道了。将上面的 EchoServer 中的   方法修改一下，让其返回以下数据： 咳咳，准备好了吗，打开浏览器，输入  ，如无意外，你就可以在屏幕上看见   了。这就算最「小」的 HTTP 服务器了，不管向它发送什么请求，不管请求的是什么，它都会返回  ： 这是因为我们还没有对请求报文首部进行分析，从而根据请求路径的不同或者请求方式的不同来返回相应的数据。响应请求既然要做一个静态的服务器，最少也应该分析   请求，根据请求的 URL 作出响应，那么就需要增加额外的函数了： 我这里（在   中）增加了两个函数：  和  。作用分别是根据客户端的请求报文的首部来生成相应的服务端响应报文首部和根据客户端的请求 URL 发送响应的报文主体内容，比如，请求首部： 响应首部（可将请求的资源以   模式打开，并读入内存，再作为响应报文主体发送）： 有关这两个函数的具体实现，可以参考我这部分的源码。并发请求优化我们的服务器现在已经可以根据 GET 请求的 URL 来返回相应的报文了，很好，但现在的服务器不支持并发请求，也就是说必须先对前一个请求作出完整的响应，并将响应发送出去之后，才能处理下一个请求，造成这种后果最重要的一点原因就是：  和   都是阻塞型 I/O 函数，也就是说，CPU 会一直等待这两个函数执行完成才继续执行后面的代码。虽然在本地局域网内，作出大部分响应的时间都很快（毫秒级别），但我们仍有必要对阻塞型 I/O 函数进行优化，优化方法有两种：在单独的线程中运行该阻塞型操作把该阻塞调用转化为非阻塞的异步调用使用其中第一个方法很简单，借助   模块即可实现，重写一下   方法： 而第二个方法就需要借助 Asyncio 这个库了（由于借助了 Asyncio 这个库，要求 Python 版本为 3.5+），该库重写了标准库 socket 中的阻塞 I/O 函数，将其改为了非阻塞形式的异步调用，由于该方法改动的地方太大，就不贴完整的代码了，可移步至这部分的源码。薛定谔的 BUG同我在之前一篇博文提到的类似，这次同样遇上了一些薛定谔的 BUG：大文件传输当以   函数打开某一个文件时，会把这个文件的内容读入到内存中，如果只是普通的文本或者图片倒是不会出现什么问题，但是一旦读入的文件过大（比如我就喜欢在电脑开启静态 HTTP 服务，然后在局域网内其它的设备打开共享的视频来播放），就会出现两个情况：占用的内存空间过大，程序 gg；成功读入内存，但花了很多时间读入内存，服务端又花了很多时间发送，客户端又花了很多时间接收；于是乎，大名鼎鼎的「generator（生成器）」终于派上了用场。将   函数（请求的文件内容）中的   函数作为一个生成器，每读取一行（ ）就 yield 一次，在   函数中不断对   返回的数据进行迭代发送，这样既不会一次性全部读入内存，造成内存空间不足、又不会花费过多的时间在 I/O 上，一举两得，当然，为此你需要加上一个   的首部，用以告诉客户端什么时候接收完毕。目录与文件当请求的是目录时，URL 最尾端应当为  ，这时返回的应该是该目录下的   文件，如没有的话就返回该目录下的文件列表（同样的，列表中的目录应当以   在末尾标识），如果点击了该目录下的子目录，则应递归的显示子目录。但当以   列出文件列表时，并不会显式的将目录以   标识，而仍需我们手动判断，当请求同名目录但末尾没有   时，应当将状态码设置为 301，并在响应头部加上   用以显式的指向目录。结语其实这个服务器在结构上并不复杂，甚至可以说简单，就是依据 Socket 建立 TCP 连接，再分析请求首部得到的 URL，用   模式加载并作为响应主体返回，但也确实让我学习到了不少：比如说「面向对象」范式的好处，即在构建以   这样自顶向下的结构时，继承（  继承于  ，而   又继承于  ）可以大大的减少代码量和提高可重用性；再比如说生成器，即惰性求值的好处（节省内存），这好像还是我第一次正式在代码中用到生成器。而这两点，想来只有自己在生产代码中遇到过，才能切实体会到好处。",
    "url": "/posts/89381f22/"
  },
  {
    "title": "写给 20 岁的自己",
    "date": 1503936000,
    "tags": "成长 感想",
    "category": "碎碎念",
    "content": "凡心所向，素履所往，生如逆旅，一苇以航。一直很喜欢海子对于时间的说法——“打马而过”。就像我还没来得及细数，20 个年头匆匆已逝。没有那么多时间细想，这一天就这么来临了，来不及回忆过去，也来不及憧憬未来，一眨眼，就发现自己已经 20 岁了。在许久之前，我便对自己的 20 岁有过憧憬，想着，20 岁的我会在哪里，做着什么事情。是有了一项划时代的发明，成为震惊世界的奇才；还是偏居一隅，发出「天地与我并生 万物与我为一」的感慨。是的，我希望自己能真实的活着，不像那些忙忙碌碌一辈子不知道为谁而活的人那样。不在意别人的眼光，不为了生存而活。但是，现在的我，也就只是在大学里，做着大多数人应该做的事情，过着大多数人应该过的生活。看来在这二十年的生命中，我还是不够坚韧。我想我是不甘于于平凡的，很小的时候，我就会告诉自己，不要去重复别人做过的事情，因为我是独一无二的（后来才知道原来小孩都会有这样的想法），我有自己的事情去做。现在回想起来，还真的觉得挺可爱的。《搏击俱乐部》里泰勒抢了一个便利店员（雷蒙）的钱包并拿枪指着他的后脑勺，雷蒙跪在地上颤抖着，泰勒问他想做什么，同时扳下击锤，雷蒙颤抖得更厉害了。“兽医”，雷蒙颤几乎是带着哭腔说了出来。“我知道了，我要拿走你的驾照。我随时会去看你，我知道你住在哪”，泰勒说。“要是在六星期内你没当上兽医，你就死定了”，泰勒把钱包还给他了，并让他跑回了家。同行的杰克表示不理解：“拜托 那有什么好玩的？那样做有什么意义？”泰勒背对着他，“明天会是他一生中最美的一天，他的早餐会比我们吃过的都甜美。”蒋勋在《孤独六讲》中写到，好像只有孤独，生命可以变得丰富而华丽。无人理解的泰勒，他的人生想必是华丽到了极点。他内心所真正向往的地方是只有自己知晓的一方天地，他会去做自己想做的事，并因此让自己的生命变得有意义起来。这一切都是因为做自己喜欢的事情，无关别人，只是为了自己的热爱。从小到大，父母乃至老师灌输的思想就是：用心念书，从市重点初中，到省重点高中，再到一本大学，过更好的生活。是的，过去二十年我仿佛就是按照这个既定的轨迹，一步一步活成了别人眼中的自己。等到我现在可以反思我的生活时，才发现我想做的事情和我应该做的事情那条清楚的界限早已模糊不清，长期的压力仿佛让自己对一切都失去了兴趣。我抗争过吗？当然抗争过，不过一个人的力量终究是难以改变什么，泰勒也深知这一点，才会成立“搏击俱乐部”。这样的生活很可怕。《三傻大闹宝莱坞》兰彻对法汗说：知道我为什么第一名吗？因为我热爱机械，工程学就是我的兴趣所在，知道你的兴趣吗？这就是你的兴趣……跟工程学说拜拜，跟摄影业结婚，发挥你的才能，想想迈克尔杰克逊的爸爸硬逼他成为拳击手，拳王阿里的爸爸非要他去唱歌，想想后果多可怕？是的，被别人强迫去做自己不喜欢的事情，是很可怕的。更可怕的是，被强迫的多了，就会麻木。从小学到高中，我的生活一直像父母要求的那样，努力，不轻言放弃。被强迫穿着这许多外衣的我，沿着既定的轨迹一点一点的行进。如果说，之前的我，不是为自己而活，那么从此时此刻，我就要像小时候自己想的那样，不为别人而活，为自己真实地活着。去寻找自己喜欢且甘之如饴的事情。作家吴晓波在《把生命浪费在美好的事情上》中写到：喜欢，是一切付出的前提。只有真心的喜欢了，你才会去投入，才不会抱怨这些投入，无论是时间、精力还是感情。在这个世界上，不是每个国家每个时代每个家庭的年轻人，都有权利去追求自己所喜欢的未来，所以，如果你侥幸可以请千万不要错过。我还年轻，以后的路还很长，我可以做得更好。不要害怕前路，我会迈着缓慢而坚定的步伐走下去。我不要自己做到最好、最优秀，只希望能在接下来的时光里，变得柔软而坚韧。最后，二十岁快乐，送给自己。",
    "url": "/posts/11ab0263/"
  },
  {
    "title": "这盛世可如你所愿？",
    "date": 1511503804,
    "tags": "政治 国情 严肃向",
    "category": "碎碎念",
    "content": "我曾听说住在罗生门的恶鬼，因为害怕人性的残忍而逃走。——《罗生门》——谨以此文献给十九大之后的「太平盛世」。  豆瓣敏感电影词条被迫雪藏广电总局禁播同性恋有关内容B 站泰剧美剧视频被进行审查北电侯亮平事件不了了之刘国梁被罢职、国乒集体退赛诺贝尔和平奖获得者刘晓波被捕唐山收费站穆斯林打人事件江歌事件迟迟没有结论《铿锵三人行》被封禁豫章书院虐待学生事件被曝光红黄蓝幼儿园~性侵~虐待儿童. . . . . .这些事件只是今年发生的一部分，却迟迟没有令人满意的答复，如果说之前的事件还有人抱着「事不关己，高高挂起」的态度，那么我想近日被爆出的红黄蓝幼儿园事件应该是与我们每个人息息相关了。这也是我最讨厌中国人的所在，大部分人只关心自己，无论自己有没有能力，只在乎自己能不能正常生活，只要火一天没烧到自己身上就永远不会关心其他人。每当出现这类事件，政府首先考虑的不是解决这类事件，而是首先禁止讨论，这想必是「防民之口，甚于防川」最好的诠释了。因为这些事件总会无疾而终，最先开始你绝望、怒吼、攥紧拳头，以为这些事件迟早会给我们公众一个交代，可最终你得到的只有封口的胶带。你会说，嘿，至少我努力过，我的挣扎会留下痕迹，世人不会忘记。可惜，他们会的，你所有的挣扎，所有的努力都会被淹没在某个明星宣布恋爱、某个模特摔倒的新闻里。在整齐划一的阅兵式上，在十九大的演讲中，他们仍然会热泪盈眶，欢呼这太平盛世，欢呼这中华人民的伟大复兴总算要来了。是的，在网络审查下，中国在大多数不会思考的人面前，展现出在新闻里呈现的那样——富强、民主、文明、和谐、自由、平等、公正、法治。在新闻里你不会看到不幸，五毛们笃定这是一个无比美好的环境。一讨论过激就撤热搜，一涉及敏感字眼就删除帖子，毕竟这是一个连小熊维尼都能影射国家领导人的国度。实名举报学校补课而差点被开除、吐槽奥运会排练而被行政拘留，言论的口就像安全区一样，越收越紧。中国的网络审查已经愈发显得为理直气壮。言论的度可以任由其界定，而现在的你我稍不注意随时都可能成为破坏社会安定的罪人。再说到最近大火的红黄蓝幼儿园（该幼儿园的所属机构已在美国上市）事件，在半年前，该幼儿园在半年前就已经被爆出了虐待儿童事件，到如今再次被爆出~性侵~虐待儿童的时间段内为何敢更加放肆？是幼儿园的老师可恶，还是在幼儿园的背后撑腰的人更可恶？而现在网络讨论都不敢放开。国家在害怕什么？我们需要的是一个公民社会，一个由我们全民去自救的社会，一个勇于暴露自己的不足、一个敢于接受公民不满的社会。而不是像现在这样的社会，遮盖一层光鲜的外衣，而不管这层外衣里面的鲜血淋漓。",
    "url": "/posts/d67271d8/"
  },
  {
    "title": "2019 · 终焉",
    "date": 1577869826,
    "tags": "2019 感想",
    "category": "碎碎念",
    "content": "翻了翻存档，我这个之前平均一月发一篇博客的人居然有半年没有新文章产出了，在这里给挂念着这个博客的各位小伙伴说声抱歉（前几天逛 V2 的时候还被催更了）。工作以后确实经历了许多事，也成长了不少，本文作为 2019 的告别文，就稍微记录这一年发生的事吧。WARNING：本文负面情绪有些重，有些流水账，有些吐槽向。毕业在毕业论文选题时，我特地挑了一个完全陌生的领域——机器学习，本想着能跟着导师学点新东西，结果导师太不靠谱——压根不管事（啥资料什么的都不给，开题报告的要求都是研究生代写），只好自己摸索着学了。花了差不多俩月时间（中间包含着春节），捣鼓了一篇万余字的论文出来（论文是用 Latex 写的 ，为了让排版符合学校规定，调整了好久，如果不是因为这点，应该一个月就差不多了），满心欢喜地发给老师，结果老师压根就没看：「明天打印一份出来我再看，电子版与打印版的格式会不一样」，我盯着屏幕上的 PDF 文件陷入了沉思，难道 PDF 电子版打印出来会不一样嘛？第二天把论文带去了教室，老师把其他人的论文都看完了才看我的，所幸给出了比较正面的评价：「从论文看，你这两个月确实是做了点研究的」，心里顿时长舒了一口气。随后两周，果然比较顺利地通过了答辩，老师也把我的论文推上了优秀毕业论文。回首这一年看来，捣鼓机器学习的那两个月应该是我这一年最快乐的时光了（我对学习新知识还是有挺大的渴望）。培训七月份，我正式入职了某家公司（公司名就不透露了，因为接下来要说它坏话 :）一开始听说公司要求去北京培训两个星期（我 Base 在武汉），我就不太乐意，把 Base 在全国各地的人都拉去北京培训，培训的目的肯定不会是培训工作技能，极大可能是「洗脑」——利用从众心理，当周围的人都认同一件事的时候，你很大可能也会被同化。培训第一天，给全体人员了十二个组，每个组大约十来人，选定了组长、组长秘书，从此之后的每天早上都会进行组内分享，分享自己认为昨天成长了什么（无非是围绕着奋斗、客户、产品的扯淡），虚伪到了极点。每人都分享完毕后，组内投票选出成长达人，在全体人的面前分享「获奖感言」。我并非不喜分享，只是这种明明言之无物、却又不得不说的分享，我很反感。工作两周后，漫长培训如期结束。到岗的第一天，直属 Leader 就把我和另一个也是校招进来的人叫到办公室，客套了几句，随后说：「你们是校招生，前三个月对公司的产出肯定是比较少的，所以我要求你们前三个月每天都不得早于九点半下班」。看着另一个校招生没有任何犹豫就点了头，无奈之下，我也只好妥协，答应的同时，心理仍然侥幸地想着，没关系，三个月嘛，很快就过去了。只是我没想到，妥协一旦有了第一次，便会成了无数次。九月初，我开始正式开发一个新的定制项目，没有需求、没有产品、没有原型、没有测试，只有一个 PPT，让我们对着 PPT 把产品做出来。九月下旬，要求我们出差上海，驻场开发，为期一个月。去上海的一个月里深刻体会到了什么叫「朝令夕改」，每隔两天客户开会都会提出新的需求，没有产品，所以只能让开发去和客户对接需求，呵，我真想骂人。‘在上海的最后一个星期，我们组有一个北京的校招生离职了，对外的理由是家里出了一些事。另一个在武汉的校招生说 Leader 已经宣布正式进入 996 了（还从其他组抽调了人），目的是为了完成部门产品的一年一次的迭代开发。操他妈的」，告诉我消息的那个校招生在和我通电话的时候骂了出来，「我 es 压根就没学过，就直接让我着手开发」、「你能在上海多呆一会就呆一会，回来就苦逼多了」……我心里想着，没关系啊，已经妥协两次了，再妥协一次又有什么关系呢？996毕业前，我一直在思索寻求一份什么样的工作（自然是计算机行业，这里是指更加具体的方面），恰逢 996.icu 项目最火的时候，我告诉自己，既然不知道想找一份什么样的工作，那就反其道而行之——不找一份 996 的工作。大约是造化弄人吧，公司并没有履行约定好的 1075 工作制（没记错的话，入职半年只有两次准点下班），996 还是降临到了我的身上。从上海出差回来的第三天，那天我八点半下的班，八点四十 Leader 打了个电话给我，问我为什么这么早下班，事做完了没有，我说做完了。「这么早就做完了？看来是工作量不饱和啊，明天给你多加一点」。「操他妈的」，我也爆粗口了，只不过是在心里骂的。第二天一去公司，询问了一下提前走的三个人（其中有两个人都是其他组调来的），都同样被打电话询问了。有趣的是，Leader 昨天并不在武汉，而是在北京出差。两天之后，被打电话的一个人直接提了离职（他是其他组借来的，已经在公司呆了一年半了），裸辞，只不过部门大领导没有同意。经历了两个月的 996，我深深明白了 996 真正摧残人的地方不是身体，而是心灵。它会慢慢磨损掉一个人心气，当你知道即使在规定时间做完了事之后，你也无法到点下班时，效率对于你来说便无所谓了。跟着领导混吧，他喜欢看着我加班，那就加吧，只要听领导的，技术什么的反正领导也不在乎，能做出来就行，管他用什么方式呢。我不想，真的不想自己变成这样的人。辞职周一的上午，来到公司后，给自己冲了一杯奶茶，慢慢地饮下去，享受着胃里因为温暖传来的舒适感，惬意极了。慢慢走到了 Leader 的附近，「XX，有个事我还是决定应该提前告诉你一下，我准备离职了」，说这句话的时候我一直在仔细观察他的面部表情。可惜似乎没看到什么变化，「你稍等一会，我一会去找你」。两分钟后，他把我叫到了一个会议室。「坐」，他指了指椅子，「啥情况啊，为啥突然想到要离职」。「感觉刚毕业还是应该学点技术，业务写多了实在没什么意思」，我说得很委婉，毕竟我不知道该怎么和他说和我合作的一个同事连 URI 是什么都不知道，没准说出来之后发现他也不知道 URI 是什么（还是有这个可能性的，毕竟他认为把函数调用的结果赋值给一个变量之后在内存中的占用会多一倍）。「那你找好下家了吗？」，他随口问到。「没有，裸辞」，我没打算说谎。「那如果可以给你换组，你可以留下来吗？」，他问道。我愣住了，我没想到他会这么说。「你想做什么方面的呢，安全？机器学习？渗透？这些我都可以帮你安排」，谈话的天平似乎慢慢向他的方向倾斜了。……一场非常「诡异」的谈话开始了。谈话的双方分别是一个刚入社会不久的本科毕业生、另一方是整个部门最赚钱的组的 Leader。他给出了留我的条件：我本周为当前的项目的内存稳定性进行优化，今后的工作他会把我平时工作的业务量控制在 30%  以内；并且下周开始，我负责另一个即将产品化的项目进行架构调整，我对该项目的架构、技术选型有着完全的控制权。那是一个与  Hadoop、Hive、HBase、Spark 有关的大数据项目，仔细想了想，似乎我的技能树里就差了大数据这一块了。最终，我选择留了下来。不是因为别的，而是因为一月份上三周班能拿一个月的工资～生活996 的人，还有生活吗？这是我一直在思考的问题，每天下班之后随便看看视频就已经十一点多，洗个澡之后躺在床上就十二点了，甚至每天八小时睡眠都无法保证。这便是我工作之后博客便停更的最根本原因，也是我今年一年观影量锐减的主要原因。好在上半年还有不少存货，还是简单总结一下吧。读书方面，今年一共读了 11 本书，推荐两本书：《乌合之众：大众心理研究》和《蜘蛛男孩》，前者讲的是心理学，有些观点有些偏激，不可全信；后者是一部奇幻小说，很温暖、很跳跃、很好看。电影方面，今年共看了 62 部电影，似乎没有明显高出其他电影一筹的（像去年的我不是药神），觉得还不错的有：寄生兽、哪吒、升级（Upgrade）、海王、调音师。剧集方面，今年看过的都不错，长剧强烈推荐：六龙飞天，是一部讲高丽如何被推翻的剧，虽然有 50 集，每集 1 个小时，但真的非常吸引人，一看就上瘾的那种；短剧推荐：致命女人、半泽直树、花甲男孩转大人。以及高中非常喜欢的一本小说——《庆余年》，终于改编成电视剧了，一开始担心会毁原著，但是却出奇精彩！动漫方面，似乎今年只看过五部，最好看的定然是灵能百分百 II：温情、热血、打斗、治愈，太完美了。写本文时，总觉得心中有股气，不写出来觉得委屈得难受，写完之后静下心思考了一下，我应当是把对 Leader 的厌恶都加在了公司的身上了，是有些不妥；可又一想，一个敢把公共会议室当个人办公室的人在这个公司居然混的这么好，这大概能说明公司本身管理就出了问题吧。Anyway，2019，总归是结束了。至于 2020 嘛，简单一些，开心就好~",
    "url": "/posts/a9aef93a/"
  },
  {
    "title": "《代码整洁之道》读书笔记",
    "date": 1524132672,
    "tags": "笔记 代码",
    "category": "文字阁",
    "content": "相对于任何宏伟愿景，对细节的关注甚至是更为关键的专业性基础。首先，开发者通过小型实践获得可用于大型实践的技能和信用度。其次，宏大建筑中最细小的部分，比如关不紧的门、有点儿没铺平的地板，甚至是凌乱的桌面，都会将整个大局的魅力毁灭殆尽。这就是整洁代码之所系。本书「序」中的这段话完美的诠释了作者写本书的意义。（简评在最后）序神在细节之中。5S 哲学包括以下概念：整理（Seiri）整顿（Seiton）清楚（Seiso）清洁（Seiketsu）身美（Shitsuke）整洁代码有人也许以为，关于代码的书有点落后于时代——代码不再是问题：我们应当关注模型和需求。……扯淡！我们永远抛不掉代码，因为代码呈现了需求的细节。在某些层面上，这些细节无法被忽略或抽象，必须明确之。将需求明确到机器可以执行的细节程度，就是编程要做的事。而这种规约正是代码。勒布朗（LeBlanc）法则：稍后等于永不（Later equals never）。多数人都知道一幅画是好还是坏。但能分辨优劣并不表示懂得绘画。能分辨整洁代码和肮脏代码，也不意味着会写整洁代码！Bjarne Stroustrup（C++ 语言发明者）：我喜欢优雅和高效的代码。代码逻辑应当直截了当，叫缺陷难以隐藏；尽量减少依赖关系，使之便于维护；依据某种分层战略完善错误处理代码；性能调至最优，省得引诱别人做没规矩的优化，高处一堆混乱来，整洁的代码只做好一件事。Grady Booch（《面向对象分析与设计》作者）：整洁的代码简单直接。整洁的代码如同优美的散文。整洁的代码从不隐藏设计者的意图，充满了干净利落的抽象和直截了当的控制语句。Ron Jeffries（《极限编程实施》作者）：简单代码，依其重要顺序：能通过所有测试；没有重复代码；体现系统中的全部设计理念；包括尽量少的实体，比如类、方法、函数等。Ward Cunningham（Wiki 发明者）：如果每个例程都让你感到深合己意，那就是整洁代码。如果代码让编程语言看起来像是专为解决那个问题而存在，就可以称之为漂亮的代码。光把代码写好可不够。必须时时保持代码整洁。有意义的命名名副其实：变量、函数或类的名称应该已经答复了所有的大问题。它该告诉你，它为什么会存在，它做什么事，应该怎么用。避免误导：应当避免使用与本意相悖的词。别用 accountList 来指称一组账号，除非它真的是 List 类型。用 accountGroup 或 bunchOfAccounts，甚至 accounts 都会好一些。做有意义的区分：以数字系列命名（a1、a2，……aN）是依义命名的对立面。这样的名称纯属误导——完全没有提供正确信息；没有提供导向作者意图的线索。 如果参数名改为 source 和 destination，这个函数就会像样许多。使用读得出来的名称： 使用可搜索的名称：窃以为单字母名称仅用于短方法中的本地变量。名称长短应于其作用域大小相对应。避免思维映射：不应当让读者在脑中把你的名称翻译为他们熟知的名称。类名：类名和对象名应该是名词或名词短语，如 Customer、WikiPage。避免使用 Manager、Data 这样的类名。方法名：方法名应当是动词或动词短语，如 postPayment、deletePage 或 save。每个概念对应一个词：给每个抽象概念选一个词，并且一以贯之。别用双关语：避免将同一单词用于不同目的。函数函数的第一规则是要短小。第二条规则是还要更短小。函数应该做一件事。做好这件事。只做这一件事。别害怕长名称。长而具有描述性的名称，要比短而令人费解的名称好。长而具有描述性的名称，要比描述性的长注释好。最理想的参数数量是零（零参数函数），其次是一（单参数函数），再次是二（双参数函数），应尽量避免三（三参数函数）。如果函数看来需要两个、三个或三个以上参数，就说明其中一些参数应该封装为类了。函数要么做什么事，要么回答什么事，但二者不可兼得。函数应该修改某对象的状态，或是返回该对象的有关信息。重复可能是软件中一切邪恶的根源。许多原则与实践规则都是为控制与消除重复而创建。我写函数时，一开始都冗长而复杂。有太多缩进和嵌套循环。然后我打磨这些代码，分解函数、修改名称、消除重复。我缩短和重新安置方法。有时我还拆散类。大师级程序员把系统当作故事来讲，而不是当作程序来写。他们使用选定编程语言提供的工具构建一种更为丰富且更具表达力的语言，用来讲那个故事。注释Brian W. Kernighan 与 P. J. Plaugher：别给糟糕的代码加注释——重新写吧。注释的恰当用法是弥补我们在用代码表达意图时遭遇的失败。注意，我用了「失败」一词。我是说真的。注释总是一种失败。我为什么要极力遍地注释？因为注释会撒谎。好注释：法律信息提供信息的注释对意图的解释阐释警示TODO格式你今天编写的功能，极有可能在下一版本中被修改，但代码的可读性却会对以后可能发生的修改行为产生深远影响。垂直格式：关系密切的概念应该相互靠近。变量声明应尽可能靠近其使用位置。实体变量应该在类的顶部声明。若某个函数调用了另外一个，就应该把它们放到一起，而且调用者应该尽肯能放在被调用者上面。横向格式：应该尽量保持代码行短小。死守 80 个字符上限有点僵化，至多在 100 或 120 个字符。赋值操作符周围加上空格字符，以此加上强调目的。不在函数名和左圆括号之间加空格。源文件是一种继承结构，而不是一种大纲结构。类中的方法相对该类缩进一个层级。方法的实现相对方法声明缩进一个层级。对象和数据结构过程式代码便于在不该动既有数据结构的前提下添加新函数。面向对象代码便于在不改动既有函数的前提下添加新类。得墨忒耳率认为，类 C 的方法 f 只应该调用以下对象的方法：C由 f 创建的对象；作为参数传递给 f 的对象；由 C 的实体变量持有的对象。方法不应调用由任何函数返回的对象的方法。换言之，只跟朋友谈话，不与陌生人谈话。对象曝露行为，隐藏数据。便于添加新对象类型而无需修改既有行为，同时也难以在既有对象中添加新行为。数据结构曝露数据，没有明显的行为。便于向既有数据结构添加新行为，同时也难以向既有函数添加新数据结构。错误处理错误处理很重要，但如果它搞乱了代码逻辑，就是错误的做法。在某种意义上，try 代码块就像是事务。catch 代码块将程序维持在一种状态，无论 try 代码块中发生了什么均如此，所以，在编写可能抛出异常的代码时，最好先写出 try-catch-finally 语句。你抛出的每个异常，都应当提供足够的环境说明，以便判断错误的来源和处所。对异常可以依据其来源分类：是来自组件还是其他地方？或依其类型分类：是设备错误、网络错误还是编程错误？不过，当我们在应用程序中定义异常类时，最重要的考虑应该是它们如何被捕获。返回 null 值，基本上是在给自己增加工作量，也是在给调用者添乱。只要有一处没检查 null 值，应用程序就会失控。在方法中返回 null 值是糟糕的做法，但将 null 值传递给其他方法就更糟糕了。边界学习性测试（learning tests）：不要在生产代码中试验新东西，而是编写测试来遍览和理解第三方代码使用尚不存在的代码，将尚未开发完毕的 API 从中隔离出来。自己通过使用符合应用程序的接口，一旦 API 被定义出来，再将二者对接。通过代码中少数几处引用第三方边界接口的位置来管理第三方边界。单元测试TDD 三定律：在编写不能通过的单元测试前，不可编写生产代码。只可编写刚好无法通过的单元测试，不能编译也不算通过。只可编写刚好足以通过当前失败测试的生产代码。脏测试等同于——如果不是坏于的话——没测试。测试代码和生产代码一样重要。它可不是二等公民。它需要被思考、被设计和被照料。它该像生产代码一般保持整洁。整洁的测试有什么要素？有三个要素：可读性、可读性和可读性。整洁的测试遵循以下 5 条规则：快速（Fast）：测试应该够快。独立（Independent）：测试应该相互独立。可重复（Repeatable）：测试应当可在任何环境中重复通过。自足验证（Self-Validating）：测试应该有布尔值输出。及时（Timely）：测试应及时编写。类类的第一条规则是类应该短小。第二条规则是还要更短小。单一权责原则（SRP）认为，类或模块应有且只有一条加以修改的理由。系统应该由许多短小的类而不是少量巨大的类组成。每个小类封装一个权责，只有一个修改的原因，并与少数其他类一起协同达成期望的系统行为。通常而言，方法操作的变量越多，就越黏聚到类上。如果一个类中的每个变量都被每个方法所使用，则该类具有最大的内聚性。开放-闭合原则（OCP）：类应当对扩展开放，对修改封闭。依赖倒置原则（DIP）：类应当依赖于抽象而不是依赖于具体细节。系统软件系统应将启始过程和启始过程之后的运行时逻辑分离开，在启始过程中构建应用对象，也会存在相互缠结的以来关系。可以使用抽象工厂模式让应用自行控制何时创建对象，但构造的细节却隔离于应用程序代码之外。依赖注入（Dependency Injection）：对象不应负责实体化对自身的依赖。反之，它应当将这份权移交给其他「有权力」的机制，从而实现控制的反转。我们应该只去实现今天的用户故事，然后重构，明天再扩展系统、实现新的用户故事。这就是迭代和增量敏捷的精髓所在。面向方面编程（aspect-oriented）：被称为方面的模块构造指明了系统中哪些点的行为会以某种一致的方式被修改，从而支持某种特定的场景。迭进简单设计规则 1：运行所有测试：遵循有关编写测试并持续运行测试的简单、明确的规则，系统就会更贴近 OO 低耦合度、高内聚度的目标。简单设计规则 2：重构：在重构过程中，可以应用有关优秀软件设计的一切知识。提升内聚性，降低耦合度，切分关注面，模块化系统性关注面，缩小函数和类的尺寸，选用更好的名称等。不可重复：「小规模复用」可大量降低系统复杂性。表达力：做到有表达力的最重要方式却是尝试。尽可能少的类和方法。并发编程| 名词     | 基础定义                                                     ||  | -|| 限定资源 | 并发环境中有着固定尺寸或数量的资源。例如数据库连接和固定尺寸读/写缓存等 || 互斥     | 每一时刻仅有一个线程能访问共享数据或共享资源                 || 线程饥饿 | 一个或一组线程互相等待执行结束。                             || 死锁     | 两个或多个线程互相等待执行结束。                             || 活锁     | 执行次序一致的线程，每个都想要起步，但发现其他线程已经「在路上」。 |对象是过程的抽象。线程是调度的抽象。并发是一种解耦策略。它帮助我们把做什么（目的）和何时（时机）做分解开。并发软件的中肯说法：并发会在性能和编写额外代码上增加一些开销；正确的并发是复杂的，即便对于简单的问题也是如此；并发缺陷并非总能重现，所以常被看做偶发事件而忽略，未被当做真的缺陷看待；并发常常需要对设计策略的根本性修改。生产者-消费者模型：一个或多个生产者线程创建某些工作，并置于缓存或者队列中。一个或者多个消费者线程从队列中获取并完成这些工作。生产者和消费者之间的队列是一种限定资源。读者-作者模型：当存在一个主要为读者线程提供信息源，但只是偶尔被作者线程更新的共享资源，吞吐量就会是个问题。增加吞吐量，会导致线程饥饿和过时信息的积累。协调读者线程不去读取正在更新的信息，而作者线程倾向于长期锁定读者线程。宴席哲学家：许多企业级应用中会存在进程竞争资源的情形，如果没有用心设计，这种竞争会遭遇死锁，活锁，吞吐量和效率低等问题。本书后几章主要侧重于讲解 Java 代码的一些例子，对其它语言帮助不大，在这里就不做整理了。正如我在上一篇读书笔记中所说的：每一本中都会充斥着许多作者的自己的观点、看法，而唯有价值观相符合或相接近的人才会觉得本书写得很不错，上一本《黑客与画家》是，这本《代码整洁之道》也是，你可能很难认为变量的命名需要有那么考究，函数的长短有那么重要，心里想着程序能运行就没事，甚至连 WARNING 都忽视掉，这类人想必并不是本书的目标群体。而本书的目标群体在开头已经注明了：你想成为一个更好的程序员。其实我觉得目标群体还可以加上一小撮人：有强迫症的程序员——比如我。我曾经看自己四个月前的代码能羞愧得钻进地里，心想着怎么能写出这么烂的代码。这四个月固然有我对该门语言较高层级的数据结构更加熟悉，能更熟练的操作它们，但更多的是编程观念的改变：需要用心来写代码，不要简单敷衍了事，不要认为程序只要能运行就算成功。程序毕竟还是写给人看的，就算不是为了别人，看着意义明确的变量，缩进优美的段落，结构分明的函数，想必自己心里也会很舒畅的。",
    "url": "/posts/65e48179/"
  },
  {
    "title": "写给 21 岁的自己",
    "date": 1535472000,
    "tags": "21 成长 感想",
    "category": "碎碎念",
    "content": "{% netease musicid=31861287 %}人类似乎总是对自己无法掌控的事物有些畏惧，比如时间。我就有些害怕时间的流逝，总觉得去年那篇写给 20 岁的自己的文章还历历在目，如今又到了该写这系列文章的时候了。我很早就开始构思这篇文章该写什么，却直到最近才了有些明确的思路。去年，我曾对自己说，希望可以「不在意别人的眼光，不为了生存而活，为了自己的热爱」那样真实的活着。所幸我应当是在大部分时候都做到了，因此这一年过得很自在。但怎么说呢，近来关于这个问题我却有些困惑了。前几天一朋友在群里说他辞职了。问：为啥啊？这工作不好吗？答：工作挺好的，划水都能拿 12k。更奇怪了，又问：划水都能拿这么高，还有啥不满意的？答：感觉生活没有目的，突然想辞职冷静一下。当时还不太能理解他的想法，因为在我看来这简直是梦寐以求的工作啊：划水意味着我就有更多的时间投入到我所喜爱的事情上，但我没有说出口，只是默默听着。他继续说辞职亲戚朋友都反对，但他还是辞了——「迷茫了，每天这么混，不知道该干什么」，他说。听他说完这句话时我就有点理解了，是啊，没有以自我认可为目的的生活，又有什么可以阻止它慢慢滑向悬崖的另一侧呢。说来有些不好意思，我的自我认可很大一部分来自两部电影——《搏击俱乐部》和《三傻大闹宝莱坞》：做自己想做的事，不要做自己应该做的事情。具体解释就是我不想也没有必要活成别人眼中的自己。像别人一样告诉自己先买车、后买房、再结婚？这都是自己作，一辈子忙忙碌碌都不知道为什么而活，生命只有一次，为什么就不能为自己而活呢？做自己想做的事，不是很开心吗？而现在我的想法好像有了些许的改变：在社会福利好的发达国家，也许公民是真的可以做到我梦想的这样：看起来不求上进，赚到钱就花，遇到热爱的事情就去做，一辈子都过得很开心、很舒服。但是在中国不行。想成为自己、为自己而活当然没错。这也是电影想告诉我们的，但电影没有告诉我们的是，今天的自己是自己，明天的也是。十年后，三五十年后的都是自己。对于「自己」来说目前所有的选择都是自由的，可以选择自己所热爱的事，也可以按部就班地选择自己应该做的事。仅需记住目前做出的选择所造成的千差万别也是未来的自己所必须接受的。在中国如果按照我之前的那种想法去选择，可能并不会让三十年后的自己开心。当然，这种选择不能说是错的，更不应该被批判，只是说我们在自己没想清楚的时候可能会选择了以后的自己不想要的未来。写到这忽然有点明白卢梭的那句「人生而自由，却又无往不在枷锁之中」中的意味了。关于我 21 岁的谈人生~瞎扯淡~就在这里告一段落了。确实，我没有像去年那样在全文中都很明确的表达出一个观点并以此作为我接下来一年生活的座右铭。反而是给了一个模棱两可的答案。但我想，相比去年，这个答案确实更好了——因为得出这个答案我思考得更全面了。或许我需要像阿甘一样，连续奔跑三年才知道自己为什么要奔跑。谁知道呢，也许我明天就想明白了，Life was like a box of chocolates. You never know what you're gonna get（译文：人呐，就都不知道（命运），自己就不可以预料）。用杨绛答复别人回信作为结尾吧：你们这些年轻人啊！ too young too simple, sometimes naive！你们啊，还是要提高自己的知识水平。啊不好意思，皮了一下，是下面这句：「你的问题主要在于读书不多而想得太多」——杨绛。最后，二十一岁快乐。送给自己。",
    "url": "/posts/d9253d8c/"
  },
  {
    "title": "没有希望的事儿，还有坚持的必要吗",
    "date": 1521600465,
    "tags": "感想 成长",
    "category": "碎碎念",
    "content": "「你说，没有希望的事，还有坚持的必要吗？」确实是没想到，看国产青春剧也能看出了共鸣。忘记很早之前在哪看到过一句话：人会长大三次。第一次是在发现自己不是世界中心的时候；第二次是在发现即使再怎么努力，终究还是有些事令人无能为力的时候；第三次是在明知道有些事可能会无能为力，但还是会尽力争取的时候。最初看这句话还没什么感觉，最近看了「最好的我们」后，突然就触动了。那种触动，想来就是怎么也绕不开的「成长」了：自己做了想做的事，而生活却没有给自己想要的结果。于是乎，以后再遇见了想做的事，开始犹豫了，开始畏缩了，开始计较得失了，因为有了之前的经历，担心自己做了，却也得不到自己想要的结果。你当然可以说是因为自己长大了，会计较得失了、不会像小时候一样：想干什么就去干什么。是啊，第二次成长的你知道了有些事情即使再怎么努力，也不会得到满意的结果，于是干脆就不去做了。可目前处于不明成长阶段的我啊，又觉得凡事要是都仔细衡量得失后再去想做还是不做的话，那人生想必会少掉许多乐趣、会错过许多事情。我果然还是不适合看电视剧，花了一个月时间才把《最好的我们》看完（小时候那种看电视剧甚至广告时间都不愿意转台生怕错过衔接部分的劲儿都不知道哪去了，以后有时间还是多看看电影和书），听说还有几部青春剧也挺不错（《你好，旧时光》、《一起同过窗》等），就不看了，虽说确实能勾起高中时的那些或苦涩或美好的回忆，可那些回忆却再也不可得了。也不想总是陷在回忆里，毕竟我，到底是已经长大了。",
    "url": "/posts/18b98ea6/"
  },
  {
    "title": "博客访问统计报告（2017.6.20-2018.7.4）",
    "date": 1530759154,
    "tags": "博客 Google-Analytics 访问统计",
    "category": "博客栈",
    "content": "我的博客建站至今也一年有余了，本想着在一周年（今年 5 月初）之际写一篇文章纪念一下，顺便公布一下本博客在这一年的访问情况，可当时发现统计记录还没有满一年（我是在 2017 年 6 月底才开始使用的 Google 分析），于是就想干脆等到 6 月底再写。而前段时间又忙于准备期末考试，直到昨天放假回家，似乎才有时间写这一篇文章。前言首先我并不确定 Google 分析的准确性有多高，因为当我查看 Cloudflare 自带的分析功能时，得到的数据与 Google 分析的有很大很大的差别。以近一周的数据做对比：虽说 Cloudflare 统计了所有的 HTTP 请求，但我博客实则只有 html 页面才会走 Cloudflare 的线路，其它的静态资源我都放在 CDN 了。而 Cloudflare 对于近一周访问 html 页面给出的数据是占总请求数的 48%——约 3411 次，这应该是与 Google 的页面浏览量（540）作为对比（加上其余两个子网站的浏览量分别为 121、4），可以看到仍然有将近 7 倍的差距，用户数也有近 5 倍差距——我确实想不出一个合理的解释（根据 Cloudflare 给出的解释，可能是由于某些网络爬虫，故与基于 Javascript 的统计工具来说有较大出入）。但 Cloudflare 无法给出像 Google 分析那样包括平均会话、每次会话浏览数、跳出率等等指标，故本篇博客还是选取 Google 分析的数据进行分析。受众群体在过去的一年零两周内，本博客的基本访问情况如下图：这期间，本博客一共迎来了 5,446 位用户，他们一共产生了 10,508 次会话以及 19,989 次浏览。平均每天 14 位用户、28 次会话、53 次浏览。图表中有一个较为凸出的高峰（5 月 29 日），原因是我在 V2EX 发了帖介绍自己写的一个表情包生成工具，这个工具中算是间接性的把用户引导至本博客了。流量获取其中流量获取的来源主要是三部分：Referral（引荐）、Organic Search（搜索引擎）、Direct（直连）。其中 Google 的流量占了大多数：36.80%，其次是本博客自身的引荐；本博客并没有添加百度站长的信息，并且主动屏蔽了百度蜘蛛的爬取，故并没有来自百度的流量。现在的 Google 分析为了保护用户隐私，已经无法显示用户查询的关键词了。地理位置毫无疑问，本博客的主要流量都来自于中国大陆，不过令我感到奇怪的是第二名是美国。在操作系统语言中：简体中文（zh-CN + zh-cn）占了 72.27%，较地理为中国大陆的 68.93% 多出了 3.34 个百分点；英语（en-US + en-us）占了 16.91%，较地理为美国的 11.06% 也多出了 5.85 个百分点；也就是说，并非只有美国地区的人才会使用英文，也并非中国地区的人才会使用中文。设备信息首先看看浏览器的占用，由于本博客的类型更偏技术一些，故 Chrome、Safari、Firefox 的使用占据前三甲，其中 IE 的份额不足 0.4%，这意味着我并不需要照顾 IE 的用户，可以尽情使用各种新技术。第四的 Android Webview 应该是指 App（QQ、微信） 内置的浏览器。操作系统毫无疑问是以 Windows 独占鳌头，其次是 Linux，我一直使用 Manjaro Linux 作为日常开发，比 Windows 方便许多，也没有 Windows 那么多 Bug，由于娱乐方式的缺乏，在 Linux 下开发也会更加专注。浏览页面在本站可访问页面中（仅统计文章页面），浏览量的前六名分别是：Linux 与 Windows 10 用 GRUB 引导教程解除百度云下载限速Spacemacs 生存指北Nextcloud 搭建私人云服务教程QQ 音乐外链解析Sorry，会写代码真的能为所欲为（唉，最满意的几篇文章浏览量反倒是挺低的，心情复杂.jpg。）后记自本博客运营至今共发布了 53 篇文章，其中自 17 年 9 月以来，发文的频率明显降低：首 4 个月发了 33 篇文章，17 年 9 月至今却只发了 20 篇。一方面是刚建站的时候事比较多；另一方面是相较于博客数量来说，更开始注重博客质量了。最初我选择运营独立博客，并非想从中得到什么实质性的好处，只是作为一种兴趣。而如今在快餐时代坚持写独立文章的人越来越少，这也无可厚非，毕竟短期内看不到结果的话，有些人就无法坚持了。我周围的人似乎对此（我写博客这件事）也表示不太理解，但我还是会一直做下去。我一直认为，只要能长期的投入一件事中，最终一定能从中获取到乐趣和满足感。我就是如此。",
    "url": "/posts/790223d2/"
  },
  {
    "title": "累加器引发的一点思考",
    "date": 1580352129,
    "tags": "编程 杂谈",
    "category": "分享境",
    "content": "趁着最近肺炎，在家修养生息：看看剧，看看电影，偶尔也会学习一下。最近在学习 Elixir 这门语言，由于其实在太小众，只能抱着一本英文书啃（第一次看英文书籍，也没想象中那么难，就是看得比较慢），在看到 Elixir 实现累加器（就是《黑客与画家》里介绍的累加器）的时候，突发兴趣研究了一下，便有了本文。累加器是什么Paul Graham 在《黑客与画家》中是这么描述累加器（函数）的：我们需要写一个函数，它能够生成累加器，即这个函数接受一个参数 n，然后返回另一个函数，后者接受参数 i，然后返回 n 增加（increment）了 i 之后的值。「这里说的是增加，而不是 n 和 i 的相加（plus）。累加器就是应该完成 n 的累加。」比如说，这个函数是 foo，那么它应该具备以下行为： 想了一下，如果某语言可以比较舒服的实现这个函数，则该语言需要具备两个特性：对词法变量的完全支持；函数是一等公民（即函数可以作为返回值）。图灵等价Common Lisp 的实现： 虽然根据图灵等价来说，所有的语言在功能上都是相同的，但这没有意义：因为题目要求的并不只是实现一个（累加器）功能，还对具体的实现有额外的要求（必须使用函数来实现），因此你没有办法使用 Java 来实现（因为 Java 无法把函数作为另一个函数的返回值）。举一个更一般的例子，比如有个问题：要求计算 167564386575724718662 的平方，但不得自行编写处理整数溢出的函数。在这个问题中：计算一个数的平方是功能，而不得自行编写处理整数溢出函数则是额外的要求。如果只是针对功能来说，确实所有图灵完备的语言都可以实现，只需要处理一下溢出的整数就好，但这类问题狡猾在对具体的实现还有额外的要求，因此，整数会溢出的语言便无法解决这个问题。Python 的实现在书中，Paul Graham 给出了 Python 的一种（累加器）实现： 之所以需要这么写，而不能直接使用 lambda 返回的原因有两点：Python 中的 lambda 无法使用赋值（=）符号；Python 中对词法变量并非完全支持。有关第一点，《流畅的 Python》一书中提到，因为 Guido 不想让 Python 变得太函数化，因此极大地限制了 lambda 的使用。而第二点，则是因为 Python 不支持对词法变量「重新赋值」的缘故： 在 foo 内部的 bar 函数中，  语句会在当前词法作用域新建一个变量 n（当前作用域不存在 n 而且有「=」符号），因此这个写法是错误的，运行会得到 UnboundLocalError 的错误，除非在 bar 函数中显式声明： ，表示 n 使用上一层词法作用域的值。那么为什么书中的实现没有声明   也可以呢？注意我刚刚提到的，Python 虽然不支持对词法变量的「重新赋值」，但是支持对已存在的词法变量「修改」：对于 s 来说，  这个操作，并没有把 s 重新赋值，而只是把 s 的其中一个元素修改了，换句话说 s 本身的地址是没有变的： 同理，其他可变的数据类型（class、dict）也都可以实现这个功能：以下是使用 dict + lambda 实现的： 看起来虽然简洁了不少，但我觉得这远不如使用   来得优雅，而且这种方式也降低了可读性。Elixir 的实现数据不可变我学习 Elixir 也有二十来天了（从这一次提交开始），虽然早就预见数据不可变会给我的编程习惯带来一定影响，但是没想到影响会这么大。还是拿累加器举例子。更近一步地说，要实现这个累加器（函数），只需要保证闭包内部的词法作用域能修改外部作用域的变量就可以了。 但由于 Elixir 的数据是不可变的，定义 lambda 时，内部词法作用域保存的 outside_var 的引用地址的值是 5，定义完毕后，lambda 内部引用地址的值便无法被修改了。这里虽然对 outside_var 绑定了两次值（5 和 6），但第二次绑定并不是修改内存地址的值，而是重新申请一块内存赋值为 6，再将其绑定给 outside_var。也就是说，虽然 Elixir 对词法变量完全支持（不会像 Python 一样报错）： 但这种写法得到了不符合我们预期的行为，它同样会在内部匿名函数的词法作用域中添加 n 变量（由于 n 没有使用，所以解释器报 warning 了），并不会对外部作用域的 n 变量进行修改。且 Elixir 并没有 Python 那样的 trick（使用 list、dict 等可变类型），毕竟 Elixir 里的数据是不可变的（无论是什么数据类型）。那么问题来了，Elixir 该怎么修改并保存变量呢，更一般地说，Elixir 如何保存进程的状态呢？消息传递由于 Elixir 里的进程（这里的进程，有别于操作系统的进程，更类似于 Go 或者 Python 里的「协程」）都是完全孤立的，进程间无法通过共享内存来通信，因此 Elixir 采用消息传递（message passing）的方式进行进程之间的通信，也是通过它，我们可以构建出保存状态的进程。比如这里的累加器函数，在每次调用累加器时，需要做两件事：从消息信箱中获取上一次累加的结果；更新这个结果，并将结果发送给消息信箱。 值得注意的是，虽然 receive 语句是阻塞的，但是能保证每次开始调用累加器时，消息信箱中总是有数据的（来自于上一次累加发送的消息），因此进程并不会阻塞住。 不过，由于这种方法涉及进程之间的通信，因此耗费的时间远比原生支持修改外部作用域变量的语言要多（大约是 Python 的实现方式的 10 倍左右）。结尾其实有些纠结是否应该发这类文章，主要是纠结其内容是否有价值，后来想了想，当然是有价值的，价值的名字叫做「独立思考」。参考：黑客与画家Elixir in Action 2nd",
    "url": "/posts/286f4007/"
  },
  {
    "title": "Elasticsearch 集群备份指南",
    "date": 1540648512,
    "tags": "Elasticsearch 备份 恢复 backup",
    "category": "分享境",
    "content": "Elasticsearch 官方对其的定义是一种搜索引擎，但我更喜欢把它当作一种非关系型数据库来看待，而作为数据库来看待的话，保障其中数据的安全性和可靠性自然是重中之重了。首先声明，本文对 Elasticsearch 数据的备份是基于官方提供的 API，其它的诸如 elasticsearch-dump 等第三方工具暂且不谈。官方的提供的备份方式是一种 Snapshot，其中备份路径可以选择云端或本地，本文想就备份集群数据到本地写一份指南，并对遇到的问题做一些解答。 搭建集群文件系统为了创建一个 Elasticsearch 集群的 Snapshot，首先必须先搭建一个集群文件系统，用以确保集群的所有节点对同一个目录具有操作权限——这里推荐使用 NFS（Network File System）。NAS 需要指定集群的某一个节点的文件夹作为服务器来提供硬盘存储，也是 NAS 存储文件的实际位置，集群的其他节点作为客户端挂载服务端的共享文件夹。安装 创建共享文件夹这里是我踩的第一个坑。服务端的共享文件夹所有者必须也是运行 Elasticsearch 程序的用户，不然 Elasticsearch 是无法将数据备份到该文件夹的，比如运行 Elasticsearch 的用户是 els 的话，可以用如下命令来创建共享文件夹： 修改配置文件在服务端的   中添加以下内容： 其中   就是服务器本机的 IP。括号内的是配置参数，稍稍解释一下： ：允许客户端从大于 1024 的端口号连接。 ：所有连接者都具有读写权限。 ：将更改都提交到稳定存储之后再回复请求。 ：禁用子树检查。 ：关闭 root 压缩。 ：不要向客户端显示 ACLs。更多的参数可以参考这里。生效配置 这时你可以使用   来查看本机的挂载情况： 客户端注意，客户端也一定要使用运行 Elasticsearch 的用户的权限来创建相同的文件夹，这一点非常重要。然后把服务端的文件夹挂在到各个节点： 没有报错的话，就挂载成功了。Elasticsearch 配置需在每一个节点的   中加上一行： 然后重启 Elasticsearch。这时就可以尝试创建一个 Snapshot 的仓库了： 如果没有报了权限错误的话，就 OK 了。如果报了权限错误，请检查 Elasticsearch 对该文件夹是否具有写权限。如果确认具有写权限，那么就需要把集群各节点运行 Elasticsearch 的用户的 UID 和 GID 统一起来，具体做法见附录。这里是我踩的第二个坑。创建一个备份你可以以如下命令来创建一个备份： 其中   参数并不会马上返回结果，而是等备份完成之后再返回结果，如果备份的索引很多的话，可能会花费很多时间才返回，所以并不建议加上这个参数。可以为   加上请求体，指定索引，如上指定  、  两个索引备份，如果不加请求体的话会默认备份全部索引。当 Snapshot 正在生成中的时候，可以使用如下命令来获取备份的进度： 其返回的   项的值即是备份进度条。Elasticsearch 是采取增量备份的形式，但需注意，Snapshot 不可重复创建，也就是说 Snapshot 的名字不能相同。从备份中恢复可采取如下命令从 Snapshot 中恢复： 默认所有的索引都会恢复，当然你也可以指定索引： 而有关恢复的进度，Elasticsearch 并不提供查询像备份进度那样的 API，所以只能使用 indices recovery 和 cat recovery 来查询恢复进度。与备份和恢复更详细的讲解请参照官方文档。附：更改 UID 和 GID 的方法首先假设各节点运行 Elasticsearch 的用户名为  。先假设：他的旧 UID 为 1005，旧 GID 为 2000，要把他改成 UID 为 2005，GID 为 3000 的新用户。首先为   更改新的 UID 和 GID： 这就算完成了，可以用   命令来查看用户的 UID 和 GID 是否被成功更改。当然，这只是把用户名的 UID 和 GID 做了简单的更改，还需要把原用户的所有文件、目录的所有者都改成新的，不然是无法成功运行 Elasticsearch 的，会报权限错误。以下命令来更改： 其中   参数对每个文件执行   和   命令。  参数是对符号链接起作用，而不是应用文件。参考：Snapshot API not workingelasticsearch backup and restoreHow to Change a USER and GROUP ID on Linux For All Owned Files",
    "url": "/posts/92d76830/"
  },
  {
    "title": "QQ 音乐外链解析",
    "date": 1520396586,
    "tags": "音乐解析 Javascript 网易云",
    "category": "实验室",
    "content": "起因大概在五天前，忽然发现一直在用的网易云解析不能用了，去作者的项目查看才知道原来是网易云更换了新的接口，旧接口的请求现在统一返回 403。于是乎，便萌生了自己写一个接口的想法。其实网易云的外链获取目前还是有几种可用方案，比如：云音乐直链生成器手动替换： ，将中括号改为歌曲 id，即为外链这两种方法其实大同小异，都会 302 至歌曲的缓存地址，但也存在一个身为强迫症的我无法忍受的缺点——~~缓存地址的协议是  （从云音乐官网现在还有大量的 Mixed Content 就可以看出网易对这方面并不上心），而且自己将协议修改成   后访问部分歌曲又会有机率出现 403，这可真是逼死我了~~现在第二个方法已经会直接 302 至  HTTPS 协议了。于是决定暂时放弃掉网易云，换其他家的顶着。我又用回了网易云接口，并编写了一个 API 文档，欢迎使用。QQ 音乐考虑了一圈，还是决定选 QQ 音乐。在网上也找到了 QQ 音乐所提供的接口：请求地址： 参数，有三个：songmid：歌曲页 Url 的   括号部分filename：歌曲名  guid：随机生成的数字串  综上，歌曲的请求地址为： 向这个地址请求后，会得到一个 JSON 格式的数据文件，包含了我们需要的信息：vkey 得到了最重要的   字段后，就可以解析出歌曲的「真实链接」了： 你可能注意到返回的信息中还包含了   字段。是的，  只有在该时间段内才有效，当然这个问题很好解决，可以把该程序部署至服务器，而从服务器发起请求获取链接后 302 至歌曲链接。而当我满心欢喜的把这个脚本向服务端部署的时候，却失败了：原因是接口的请求地址只支持国内的（想来是因为 QQ 音乐只拿到了在大陆地区的版权），而我的服务器在美国，这个问题就有些难解决了（我没有国内的服务器）。于是我想另辟蹊径。纯 JS 解析既然服务端无法解析，那就用 JS 在用户端解析。但又带来了另一个问题——跨域。目前跨域请求比较好的解决方案有两种：CORS 和 JSONP，其中 CORS 需要服务器端设置  ，所以也就只有使用 JSONP 了。注意：跨域请求失败原因浏览器端阻止显示，并非服务器端无法返回数据使用 JSONP 时要求服务端返回的是满足 JSONP 模式的文件，不能是纯 JSON 文件，举个例子： 其中   返回的是纯 JS 文件，  返回的是满足模式的 JS 文件。可以运行上面代码看看结果。本想直接用现成的  ，考虑到并非所有的网站都引入了 jQuery，而为   就引入一个那么庞大的库又有些没必要。于是就自己封装了一个   接口来搭配   使用。项目已开源，具体的代码见这里，有很详细的注释。使用为了使接口更干净，没有使用 callback 函数，而是使用了 ES7 的新特性 async、await。尝试过使用 Babel 等工具转换成兼容更好的 ES5 代码，但是并没有成功，故而浏览器的兼容可能存在问题。引入这个 JS 文件：接口： ，如下图：注意：在调用 getMusic() 的时候一定要加上 await 关键字，否则返回的就是一个 Promise 对象了配合 Aplayer由于使用了 ES7 的新特性：async 和 await，故而 Aplayer 的配置文件也需要稍加改动：需要将原配置信息放至包含   关键字的函数内，随后调用这个函数，如下： 结语越来越认同保罗 · 格雷厄姆那句「黑客就像画家，工作起来是有心理周期的有时候，你有了一个令人兴奋的新项目，你会愿意为它一天工作 16 个小时。等过了这一阵，你又会觉得百无聊赖，对所有事情都提不起兴趣。」话了，简直就是我的写照：这四天大约花费了 30 小时（当然有很大一部分缘由是之前没怎么学过 JavaScript，修改一下别人的代码还行，自己写就有点「捉襟见肘」了），而估计后几天又会陷入「空窗期」了。而 JavaScript 又是一门有很多~坑爹~特性的语言，也让我把初学者的坑基本上都踩完了（还是写 Python 爽）。同时也感觉学习新东西的最好、最快的方法就是实战，换句话说，抱着解决问题的目的去学习所学到的知识远比你抱着单纯学习目的所学的知识要更快、更牢靠。",
    "url": "/posts/72171293/"
  },
  {
    "title": "Kindle Papwerwhite 开箱 & 简评",
    "date": 1507178026,
    "tags": "开箱 Kindle 简评 电子书",
    "category": "碎碎念",
    "content": "If you don't let go old things, new ones wouldn't come.                   —— Nicolas Wincer前言时间是在 9 月 27 日晚，我用了一年零 8 个月的 Kindle 正式宣布坏掉，原因是充不进电，我的第一反应是想着去修，后来还是打消了这个念头。主要是这个 Kindle 实在算是家族里的「老古董」了，我对 kpw3 的 300 ppi 也是种草许久，正好本着“旧的不去，新的不来”的观念，就入了一部 kpw3，其实在我想着要买  kpw3 的时候，是有点纠结 Voyage 的，因为用了快两年的 Kindle3 我已经习惯了实体翻页键，奈何囊中羞涩，只是为了这一个功能就要多花 600 +，有些不值当，想着等工作了之后直接上 Oasis。其实我最近是比较少看书了，现在看的这本《雪中悍刀行》看了半年多才看了一半，上本《将夜》看了一年，一方面是看的书越多，品味自然也高了起来，现在写的好的小说是越来越少，之前一直很喜欢的几个作者要么更新是越来越慢（比方说：烽火戏诸侯，愤怒的香蕉）、要么是书的质量不如之前（比方说：烟雨江南、猫腻），有点担心自己看完了就书荒了。我买 Kindle 不是为了亚马逊庞大的图书资源（我看书只自己在网上找），而是因为那块 E-ink 屏幕，而且因为 Kindle 那可怜兮兮的娱乐功能，用 Kindle 时可以更专注于看书。而国庆前几天一直忙于跑亲戚，所以直到今天才有空闲时间开箱。开箱这就是全部的配件（裸机 + 数据线）了：右边是卖家附赠的| 参数   | 描述                 ||  | :- || 阅读灯  | 4 颗                || 解析度  | 300 ppi            || 重量   | 205 g              || 尺寸   | 169 × 117 × 9.1 mm || 屏幕   | 6 吋                || 容量   | 4 GB               || 连接   | Wi-Fi              || 运存   | 512 mb             |简评开完箱经过简单的设置之后，迫不及待的从电脑传了几本书（谁都阻止不了我想读书的心情！）。吐槽一下，这里是无法像多看一样做成文件浏览的形式，也就是说，即使你把一些书放进新建的文件夹里（便于归类管理），它也是直接在首页显示。这就是阅读界面的选项了，选项少的可怜，而且页边距太大！我这已经设置页边距最小了。得益于 Kindle 这块 4:3 的屏幕，看漫画可以说是比手机更具优势。清晰度是够了，要是屏幕再大一些就好了：如果想要购买正版书，就在上方的搜索按钮输入书名：设置界面确实寒酸，不过想想要的只是纯粹的阅读体验，也就释然了：使用了~半个多小时~两天多了，简单总结一下感受：300 ppi 看起书来真的是太 ™ 爽了在翻页的速度上，相比前几代快了不少，当然和手机还是没法比阅读灯对我来说没啥用，我晚上看书也会开台灯页边距实在太大，我都已经调整成了最小边距了，可还是留白太多系统功能相比多看来说还是少了一些，比如无法设置全刷页数后记买 kpw3 之前其实还有一个顾虑，就是刷不了「多看」，我的电子书资源多是 「epub」格式的，而 Kindle 的原生系统是不支持「epub」格式的（我一直搞不懂为什么亚马逊不支持）现在我每一本书都要转成 「mobi」 才能在 Kindle 上看。还有就是实体翻页键了，等我经济独立之后，一定要买 Oasis！",
    "url": "/posts/6619f85a/"
  },
  {
    "title": "Hello World",
    "date": 1493962690,
    "tags": "随笔 Hexo NexT",
    "category": "碎碎念",
    "content": "在朋友的推荐下，这个简易的博客搭建起来了。折腾了一天多，第一天结束的时候在 Github Pages 上看到自己的博客加载出来的时候，突然有种错综复杂的恍惚感。是的，它不是自己的 QQ 空间，不是新浪博客，不是豆瓣小站，也不是百度贴吧。它更像是属于自己的一块小小的领地，因而我满足这种归属感。我愿意、更乐于在上面安静劳作。一个之前为地主打工的农民，现在通过自身努力终于分到了一块地，不再需要帮地主的土地创造价值时，于是，这个农民重生了，他可以自豪的宣告：Hello World。当然，这个农民确切的来说是个码农。主题采用的是 Next，很好看的主题，使用文档见这里。",
    "url": "/posts/4a17b156/"
  },
  {
    "title": "再见 LiveRe，拥抱 Disqus",
    "date": 1501294112,
    "tags": "Disqus 博客 评论",
    "category": "博客栈",
    "content": "没错，我又双叒叕换评论系统了，从最初的网易云跟帖，到后来的 LiveRe，再到现在的 Disqus，两个多月就换了好了三四次（中间从 LiveRe 切换过一次 Disqus，后来又换回来了）了，仿佛我在折腾这些非博客主体的路上越走越远，也幸好我的博客才建成，没啥人留言，不然就得不偿失了。LiveRe其实 LiveRe 真的做的挺棒的，中国的本地化做的更是没话说，支持国内的社交媒体：微信、QQ、百度、人人、豆瓣、新浪，国外的支持的就更多了，上次我因为评论框颜色的问题发送了邮件，结果不到 12 个小时 LiveRe 中国区的负责人亲自发邮件解答了这个疑问，就这点来说简直太良心了。但是美中不足的是：不支持游客评论（其实这点倒无关紧要）不支持导出评论在我博客的加载速度问题我最不能忍受的就是第三点了，由于我博客是采用了 CloudFlare 的 Keyless SSL 技术，流量都会走 CloudFlare 的 CDN 节点，但是由于节点在国外，国内访问速度实在是太慢了，每次点开网页都会看到圈圈不停的转，这简直不能忍啊，于是我就想做一个延时加载的，后来想想，既然都要做延时加载的了，那我为什么不干脆换成 Disqus 呢？Disqus那么说到 Disqus，之前为什么会不用 Disqus 呢，主要还是担心国内不会翻墙用户无法评论的问题，后来想想其实这点不重要，因为：我的博客只是在 Google Search Console 添加了信息，没有在百度站长平台添加，~所以百度是搜索不到我的网站~现在貌似已经可以搜到了；既然是从谷歌搜索进入的话，那自然也就不存在不会翻墙的问题了；不是所有的用户都需要看评论，于是我就把评论功能隐藏了起来，需要的话点击下方按钮加载评论，如果网络比较好的话，会自动显示，否则需要手动点击；这样优化过后，总算好多了。延迟加载原理嘛，先用 ajax 异步发送一个 get 请求至 Disqus 服务器，接收成功则屏蔽按钮，加载评论；超时则自动断开，并显示加载按钮： 最后，列一下我对博客的优化：使用 glup 插件压缩 html、css、js、img 等；CloudFlare 的 CDN 加速访问资源；ServiceWorker 提供离线访问技术；延时加载 Disqus 评论；每一点优化我都有写文章，文章链接可以通过搜索关键字获取。",
    "url": "/posts/e5d13eb/"
  },
  {
    "title": "Manjaro 大法好",
    "date": 1496927912,
    "tags": "KDE Linux",
    "category": "碎碎念",
    "content": "前言从去年 8 月到现在，终于无法忍受 Ubuntu 了，原因有以下几点：依赖太过混乱，自带 Python 默认版本居然是 2.7，而且更改默认版本后安装软件会各种报错时不时报一个内部错误软件版本更新太慢考虑到以上三点，我选择了  Arch 系的 Manjaro Linxu，选择 Arch 是因为去年有装过，是滚动更新模式，提供最新版本的软件，而不直接用的原因是安装步骤太过繁琐，没有必要，故而选择了基于 Arch 的 Manjaro 发行版。制作启动盘建议采用「rufus」烧制到 u 盘，制作的时候选择 dd 模式，不要选择 iso 模式，否则会无法从 u 盘启动，随后一路点点点。安装后的配置安装完成后，界面挺丑的，首先：更换中国的源，建议 USTC，这是教程换一张壁纸将面板从底部删除，在顶部新建一个，添加一些部件工作空间主题中更换观感和桌面主题应用风格中更换窗口样式更换图标包fcitx 输入法安装 docky美化终端，安装 zsh、Oh my zsh、powerline配置 conky（之前 Ubuntu 上的不知道为什么不能用了）使用感想Arch 的包管理 pacman 比 Ubuntu 的不知道高到哪里去了，还有 Octopi 图形界面客户端特效比 Ubuntu 华丽多了可随意切换工作区，效率确实高了一些KDE 设置确实较多，需要花时间KDE Connect 简直方便到爆炸！效果图",
    "url": "/posts/7e325dad/"
  },
  {
    "title": "从 GnuPG 的使用谈谈密码学",
    "date": 1512955576,
    "tags": "GPG 密码学 安全",
    "category": "分享境",
    "content": "前言我是一个很注重隐私的人，所以对密码学也就很感兴趣，这学期本着想进一步了解密码学的念头选了一门应用密码学的选修课（其实是为了混学分），虽说也没去过几次，但总想着这门课都快结束了总不能像没上过一样。这次借着 GnuPG（以下简称 GPG） 软件的使用也聊聊目前现代密码学中以密钥性质进行区分的两大加密方式。对称密钥加密大概半年前，写过一个暴力破解加密压缩文件的程序，说白了就是跑字典，不断的试密码，这只能破解常用密码，一旦用户采用随机生成的密码就无从下手。我们平时所用到的压缩加密大多都是对称性加密，即我们用同一字符串对文件进行加密，又用同一字符串进行解密（此时为了保证安全，密码需越复杂越好）。明文 <> 密钥 <> 密文对称加密很方便也很快速，但是也带来了一个很大的缺点，由于加密和解密用的都是同一密钥，在传输的过程中，要求双方取得相同的密钥，这会大大降低加密的安全性（注意：这里所说的不安全不是说对称加密算法不安全，而是从密钥的获取程度来说的，即密钥知道的人越少越安全）。在如今的互联网时代，通信双方分隔异地且素为谋面，则对称加密要求事先交换共同密钥的安全性也无法得到保障。公开密钥加密那么为了解决对称加密的安全隐患，非对称加密诞生了。与对称加密不同的是，非对称加密的加密和解密所需要的密钥是不同的，而且知道了其中一方，想推导出另一方（需要解决一个数学难题），在量子计算机时代来临之前，基本是不可能完成的。因此公开其中一个密钥，并不会对密钥对的安全性有影响。我们常说，公钥可以公开，私钥需要保密，但其实公钥和私钥在生成过程上，并无什么不同。并不是因为公钥公开后，解密出私钥困难，如果公开的是私钥，解密出公钥也同样困难。也就是说我们将一对密钥公开的那部分叫公钥，另一部分叫做私钥。并不是因为公钥，才能公开，私钥，就必须保密。明文 <> 公钥 <> 密文 <> 私钥 <> 明文前一段时间很火的勒索病毒就是采用的非对称加密中的 RSA-4096 加密算法。想具体了解 RSA 加密原理的话，点击这里。由于公钥加密在计算上相当复杂，导致其加密速度相对于对称加密来说慢。数字签名其中对称加密还有一个用处：数字签名。对称加密的公钥和私钥在使用顺序上并没有什么要求，你可以用公钥加密，私钥解密，这就是非对称加密算法，同样可以用私钥加密，公钥解密，而这就成为数字签名。由于私钥是发送者保存的，发送者用私钥加密后的信息，任何拥有该发送者的公钥的人都可以解密该信息。如果接收用发送者公开的公钥解开了，那么说明这个信息是确实是发送者发送的（没有被篡改，也不是伪造的）。公众也可以信赖这条信息确实来自与该用户，用户无法否认。一般来说，不直接对消息进行签名，而是对消息的哈希值进行签名，并将签名附赠在消息一起发送。总结一下二者的优点与缺点：对称密钥加密（使用最广泛的 AES）：加解密速度很快，强度也足够，但问题在于寻找一个安全通道让通信双方交换密钥很困难公开密钥加密（使用最广泛的 RSA）：加解密速度很慢，但可以解决通信双方安全通道的问题故现在多将二者结合使用：需要加密的主体内容使用对称加密，对称加密的密钥使用非对称加密。GPG 教程下面说说如何使用 GPG 软件加密文件。GPG 支持的算法有很多：公钥：RSA, ELG, DSA, ECDH, ECDSA, EDDSA对称加密：IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256,​     TWOFISH, CAMELLIA128, CAMELLIA192, CAMELLIA256散列：SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224压缩：不压缩，ZIP，ZLIB，BZIP2对称加密使用对称加密很简单，只需要一行就可以： 随后会让你输入两次密码，就会生成一个 FILENAME.gpg 的文件在同目录下。解密： 更多参数请输入   自行查阅。非对称加密生成密钥（这里如果输入的是   的话，会省去一些步骤：自动设置密钥尺寸为 2048 位、有效期限为 2 年、注释留空）： 回车后，出现以下文字： 选择 1： 选择 4096： 如果想设置 5 年过期，输入 5y，我这里是自己私人用，选择 0，随后会让你确认以上信息正确与否，输入 y，系统会要求你提供一下个人信息： 注释这一栏可以留空。随后： 输入 o，会弹框提示设置一个密码，用于保护私钥。与此同时，系统也会提示： 几秒后，系统就会提示密钥已经生成。导出密钥显示系统的私钥： 显示系统的公钥： 删除密钥： 其中 uid 可以使用邮箱代替，下同。导出公钥： 导出私钥： 这样导出的 key 文件是二进制，不可读，加上 armor 参数可以保存为 ASCII 码形式。导入密钥： 加密 -r 指定用户的公钥，如自己使用改为自己邮箱即可，-o 指定加密后输出文件名称。解密 会让你输入密码，即用于保护私钥的密码。参考：公开密钥加密GPG 入门教程",
    "url": "/posts/4aa5d46d/"
  },
  {
    "title": "Python 字典的原理及高级用法",
    "date": 1526088182,
    "tags": "Python 字典",
    "category": "分享境",
    "content": "算算时间有段时间没写技术类的文章了，部分原因是最近过得确实比较忙。当然，也并没有忙到完全抽不出时间写博客，根本原因还是没有找到啥好的写作素材，随随便便糊弄一篇我又有点不好意思发上来，于是乎，就一直搁置到现在。对于字典这一基础的数据结构来说，其对 Python 的程序重要性是无可替代的，在《代码之美》一书中，作者是这么描述的：字典这个数据结构活跃在所有 Python 程序的背后，即便你的源码里并没有直接用到它。——A.M.Kuchling在 Python 程序里，无论是模块、函数、还是对象，均有自己的「命名空间」，而这命名空间即为一个字典（dict），key 就是变量名，value 就是变量值，除去「命名空间外」，对象的函数（方法）关键字也是存放在字典中，此时的 key 就是函数（方法）名，value 就是该函数（方法）的引用。可以采用 __builtins__.__dict__ 来查看这些函数（方法）。字典的原理Python 的字典是依据散列表（也叫哈希表）来实现的，首先简单介绍一下散列表的原理。散列表中的每一个单元称为表元。在 dict 的实现里，每个 key-value 均占用一个表元，其中 key 为键的引用（这里是键的引用，而不是键本身，因为 key 可以为任意可散列对象），value 为值的引用。因为是引用：表元大小均一致，所以可通过偏移量来读取某个表元。在 Python 中，散列函数由 hash() 方法出任，当我们查询 my_dict[search_key] 时，Python 会调用 hash(search_key) 来计算 search_key 的散列值，并将这个值的低几位数字当作偏移量，在散列表中查找表元，具体是几位，需要根据散列表的大小来决定。若表元为空，则说明 search_key 不存在，抛出 KeyError 异常。若非空，则表元会有一对 found_key:found_value，这时若 search_key == found_key 为真，那么就返回 found_value。如果 search_key 和 found_key 不相等，这种情况成为散列冲突，发生这种情况是因为散列表只把该元素映射到了只有几位数字上。为了解决散列冲突，算法会在散列值中另外取几位，用新得到的数字做偏移量再次寻找。创建字典创建一个字典有许多方式： 在刚刚的原理中说到，由于字典的索引是根据 hash() 函数来获得的，所以 dict 其实是无序的，这也解释了为什么上面代码中的等式会成立。字典推导没错，在 Python3+ 里，推导式不再是列表的特性了。 键查询最简单的方法是采用下标方式来查询。即：my_dict[key]，这也是推荐的方法，但这是 key 存在的情况，而现实中，一定会遇到 key 不存在的时候，这时就会 raise 一个 KeyError。以下有几种解决办法：用 get 来获取 若 key 存在，则返回对应的 value，若 key 不存在，且传入第二个参数，那么返回该参数，若无第二个参数，则返回 None。用 defaultdict 预先设置缺省（推荐） defaultdict 需要指定一个 factory，当查询 key 不存在时，会创建一个空的 factory 返回。推荐使用这种方式来处理 key 不存在的情况，因为该方法不仅可用于读取 value 值，还可随时用 append 来更新 value。同时需注意：defaultdict 中的参数只会在 __getitem__ 中被调用。如 dd 是一个 defaultdict，k 是一个不存在的键，dd[k] 用 factory 来创造一个默认值，但 dd.get(k) 却仍会返回 None。使用 __missing__ 方法当我们调用 my_dict[key] 时，如果 key 是一个字符串，我们会需要用 my_dict['name'] 来获取，如果你觉得比较麻烦，想直接用 my_dict[name] 的话，可以采用如下方法： 使用 __getattr__ 方法（不推荐）有时我们可能更懒，想要用类属性类似的 my_dict.name 方法来获取 value，这时，可以使用 __getattr__ 方法： 并不推荐这样做，因为在 dict 实现中，并没有要求 key 一定为合法标识符，只需要是可散列对象即可，而上面的写法一旦 key 不为合法标识符，会 raise 一个 SyntaxError： 如果非常想使用 . 来获取 value 的话，建议使用 namedtuple当然这也就意味着必须使用合法标识符了： 实现 switch ... case 结构同样借助键查询，可以实现 Python 中没有的 switch ... case 结构： 所以说 Python 不设计 switch ... case 语句是有原因的，看上面的实现，比 switch ... case 不知道高到哪里去了。dict 和它的小伙伴们OrderedDict在添加键的时候会按顺序添加，同时 .popitem 是会删除并返回字典的最后一个元素而不是像 dict 里面一样可能会删除任意元素。Counter这个映射会给键一个计数器，每次更新键时都会增加这个计时器，所以这个类型可以用以给可迭代类型计数： UserDict用法见键查询。不可变映射在 Python 3.3 后的版本，types 模块引入一个名为 MappingProxyType 的类。如果给这个类一个映射，它会返回一个只读的映射视图。但它是动态的，如果原映射改动，那么它也会相应改动。 ",
    "url": "/posts/4f2b4bfb/"
  },
  {
    "title": "《黑客与画家》读书笔记",
    "date": 1516957889,
    "tags": "笔记 黑客与画家",
    "category": "文字阁",
    "content": "去年年底那会，花了大概一周多时间，阅读完了《黑客与画家》这本书，收获颇丰。可惜当时确实没多少时间整理出读书笔记，期末考试结束后，回到家中，本想着有时间能好好补一下博客，结果回家之后也没有想象中的空闲，看着「搬瓦工」把每年 20$ 的套餐补货了，于是就购置了一台服务器，将博客源码从 GitHub 上转移到了自己的服务器上，还拿 Golang 重写了一下「一言」的 API（扯远了，服务器的事等以后再开一篇博客说说），还补了一部早已加入想看列表却一直没看的番——「反叛的鲁路修」（嘻嘻 😌）。直到今天，才终于有时间能把这篇读书笔记给整理出来了，笔记是直接在 Kindle 上标注的，然后用「Clippings.io」这个工具导出（为什么 Kindle 不能开发一个好用一点的笔记管理系统呢！？）。好在 azw3 版本在 Kindle 上的体验还不错，即使有代码段排版也没有垮掉，所以决定原谅你。（👇以下为文摘）在一个人产生良知之前，折磨就是一种娱乐。程序写出来是给人看的，附带能在机器上运行。（这句话的出处是在《SICP》这本书的卷首语，作者引用了）如果有必要的话，大多数物理学家有能力拿到法国文学的博士学位，但是反过来就不行，很少存在法国文学的教授有能力拿到物理学的博士学位。人们喜欢讨论的许多问题实际上都是很复杂的，马上说出你的想法对你并没有什么好处。小时候，每个人都会鼓励你不断成长，变成一个心智成熟、不再耍小孩子脾气的人。但是，很少有人鼓励你继续成长，变成一个怀疑和抵制社会错误潮流的人。   如果自己就是潮水的一部分，怎么能看见潮流的方向呢？你只能永远保持质疑。不服从管教，其实是黑客之所以成为优秀程序员的原因之一。公民自由并不仅仅是社会制度的装饰品，或者一种很古老的传统。公民自由使得国家富强。经济学里有一条拉弗曲线（Laffer curve），认为随着税率的上升，税收收入会先增加后减少。我认为政府的力量也是如此，随着对公民自由的限制不断上升，政府的力量会先增加后减小。极权主义制度只要形成了，就很难废除。（咳咳）一定数量的盗版对软件公司是有好处的。不管你的软件定价多少，有些用户永远都不会购买。如果这样的用户使用盗版，你并没有任何损失。事实上，你反而赚到了，因为你的软件现在多了一个用户，市场影响力就更大了一些，而这个用户可能毕业以后就会出钱购买你的软件。首先，管理企业其实很简单，只要记住两点就可以了：做出用户喜欢的产品，保证开支小于收入。一个大学毕业生总是想「我需要一份工作」，别人也是这么对他说的，好像变成某个组织的成员是一件多么重要的事情。更直接的表达方式应该是「你需要去做一些人们需要的东西」。即使不加入公司，你也能做到。公司不过是一群人在一起工作，共同做出某种人们需要的东西。真正重要的是做出人们需要的东西，而不是加入某个公司。要鼓励大家去创业。只要懂得藏富于民，国家就会变得强大。让书呆子保住他们的血汗钱，你就会无敌于天下。财富是用工作成果衡量的，而不是用它花费的成本衡量的。如果我用牙刷油漆房屋，屋主也不会付给我额外工资的。好设计是艰苦的设计。如果观察那些做出伟大作品的人，你会发现他们的共同点就是工作得非常艰苦。如果你工作得不艰苦，你可能正在浪费时间。并非所有的痛苦都是有益的。世界上有有益的痛苦，也有无益的痛苦。你需要的是咬牙向前沖刺的痛苦，而不是脚被钉子扎破的痛苦。解决难题的痛苦对设计师有好处，但是对付挑剔的客户的痛苦或者对付质量低劣的建材的痛苦就是另外一回事了。等到你逐渐对一件事产生热情的时候，就不会满足于模仿了。「你用什么语言并不重要，重要的是你对问题是否有正确的理解。代码以外的东西才是关键。」这当然是一派胡言。各种语言简直是天差地别。语言设计者之间的最大分歧也许就在于，有些人认为编程语言应该防止程序员干蠢事，另一些人则认为程序员应该可以用编程语言干一切他们想干的事。允许你做某事的语言肯定不差于强迫你做某事的语言。它们（指某些语言）的内核设计得并非很好，但是却有着无数强大的函数库，可以用来解决特定的问题。（你可以想象一辆本身性能很差的小汽车，车顶却绑着一个飞机发动机。）有一些很琐碎、很普遍的问题，程序员本来要花大量时间来解决，但是有了这些函数库以后，解决起来就变得很容易，所以这些库本身可能比核心的语言还要重要。所以，这些奇特组合的语言还是蛮有用的，一时间变得相当流行。车顶上绑着飞机发动机的小车也许真能开，只要你不尝试拐弯，可能就不会出问题。（内心 OS：我可没有针对 C++ 😏）当我说 Java 不会成功时，我的意思是它和 Cobol 一样，进化之路已经走到了尽头。如果摩尔定律依然成立，一百年后计算机的运行速度将是现在的 74 乘以 10 的 18 次方倍（准确地说是 73 786 976 294 838 206 464 倍）。即使最后只是略微快了 100 万倍，也将实质性地改变编程的基本规则。如果其他条件不变，现在被认为运行速度慢的语言（即运行的效率不高）将来会有更大的发展空间。效率低下的软件并不等于很烂的软件。一种让程序员做无用功的语言才真正称得上很烂。自下而上的编程方法意味着要把软件分成好几层，每一层都可以充当它上面那一层的开发语言。这种方法往往会产生更小、更灵活的程序。它也是通往软件圣杯——可重用性（reusability）——的最佳路线。罗伯特·莫里斯和我都很了解 Lisp 语言，我们相信自己的直觉，找不出任何不使用它的理由。我们知道其他人都用 C++ 或 Perl 开发软件，但是我们不觉得这说明了什么问题。如果别人用什么技术，你也用什么技术，那么你大概只能使用 Windows 了（日常黑 Windows）。编程语言的特点之一就是它会使得大多数使用它的人满足于现状，不想改用其他语言。如果从图灵等价（Turing-equivalent）的角度来看，所有语言都是一样强大的，但是这对程序员没有意义。最不用担心的竞争对手就是那些要求应聘者具有 Oracle 数据库经验的公司，你永远不必担心他们。如果是招聘 C++ 或 Java 程序员的公司，对你也不会构成威胁。如果他们招聘 Perl 或 Python 程序员，就稍微有点威胁了。至少这听起来像一家技术公司，并且由黑客控制。如果我有幸见到一家招聘 Lisp 黑客的公司，就会真的感到如临大敌。你的经理其实不关心公司是否真的能获得成功，他真正关心的是不承担决策失败的责任。黑客欣赏的一个特点就是简洁。黑客都是懒人，他们同数学家和现代主义建筑师一样，痛恨任何冗余的东西或事情。简洁性是静态类型语言的力所不及之处。只要计算机可以自己推断出来的事情，都应该让计算机自己去推断。举例来说，hello-world 本应该是一个很简单的程序，但是在 Java 语言中却要写上一大堆东西，这本身就差不多可以说明 Java 语言设计得有问题了。 如果你从来没没有接触过编程，看到上面的代码可能会很奇怪，让计算机显示一句话为什么要搞得这么复杂？有意思的是，资深程序员的反应与你一样。语言设计者应该假定他们的目标用户是一个天才，会做出各种他们无法预知的举动，而不是假定目标用户是一个笨手笨脚的傻瓜，需要别人的保护才不会伤到自己。如果用户真的是傻瓜，不管你怎么保护他，他还是会搬起石头砸自己的脚。对黑客来说，选择编程语言的时候，还有一个因素比简洁更重要，那就是这种语言必须能够帮助自己做到想做的事。（👇以下为简评）这本书算是我从去年 7 月以来看完的第一本书了（《计算机程序的构造和解释》这本书太难了，看了前两章就没时间看，到还书的日期了），主要也在于作者 Paul Graham 的行文十分流畅，阮一峰的翻译也很到位，没有什么阅读障碍，还有「读至好几处都有一拍大腿，哎呀妈呀我也是这么想的啊」的想法，读完之后，思想也似乎豁然开朗了些。关于第六章——「如何创造财富」，财富的获得是看你最终的结果，不是看你的付出（过程）。你做出了别人需要的产品，没人在乎你是做了三天还是三十天，他并不会因为你只做了三天就完成而少付给你报酬，更不会因为你是三十天完成而多给你报酬。还有关于「财富并不是固定不变的」这个理论，他给出了一个例子：你拥有一辆老爷车，你可以不去管它，也可以自己动手把它修葺一新这样的话，你就创造了财富：世界上因此多了一辆新的车，财富就变得多了一点，如果你把车卖掉，你得到的卖车款就会比以前更多，与此同时，你并没有使任何人变得更贫穷。正因为这个理由，他也建议我们多多创业，但也给我们泼了一盆「凉水」：创业的付出与回报总体上是成比例的，但是在个体上是不成比例的，不要把创业过于神话，但创业的确给了我们更多的可能。还有就是关于编程语言的争论，作者似乎和我一样很喜欢黑 Java，认为 Java 是「进化之路已经走到了尽头」，因为编程语言并不应该限制程序员去做某些事情，即使这些事情是有害的。同时也抛出了另一个很新颖的说法：关于一百年以后，我们该使用什么样的编程语言？按照摩尔定律：预计 18 个月会将芯片的性能提高一倍，那时候电脑的运行速度将是现在的 73 786 976 294 838 206 464 倍，所以他认为现在某些因为运行速度略慢但编程起来更舒服的语言在未来反而是主流，即有更大的发展空间，同时作者似乎很推崇动态类型语言，因为写起来比静态类型语言方便、看起来也比较简洁。作者也不止一次的推崇了 Lisp，甚至不惜黑 Oracle 数据库、C++、Java（见上面第 30 条）。最后，这本书算是 Paul Graham 的一本随笔文集，其中自然充斥着许多作者的价值观，如果这些价值观与你的价值观符合，那么你就会像「捡到宝」一样的对待这本书，反之，你会认为这本书的观点完全是和「邪教信条」一般，很庆幸，我是前者。处于马上步入社会的我啊，在迷茫的时候，不妨也多阅读几本好书。",
    "url": "/posts/a6c2a51d/"
  },
  {
    "title": "再见，2017",
    "date": 1514515566,
    "tags": "2017 随笔",
    "category": "碎碎念",
    "content": "{% netease musicid=4010884 %}关于 2017 年，其实还真的有挺多想说的，也早就有想写一篇博客的想法了，差不多到今天才抽得出时间写。前几天和朋友聊天时谈到关于今年最有成就感的一件事，我想了一会，应该是搭建了这样一个博客。当初搭建博客的初衷其实很单纯：就是为了好玩，谁知从此就沉迷于此了。在之后的写博客的过程中甚至产生了一种当一个作家也还不错的想法（当然前提是我的文章还有人看😋），现在想想，与高中时期相比，我的想法是发生了一些转变（在高中时期的我是绝不可能产生这种想法的）。正如开始所说的，现在遇到点什么事就想写下来，在往年，我一直没有写年末总结的习惯。这种「创作欲」，类似作家：将自己内心的想法写成作品，实则是把自己的内心剖析给别人看。也渐渐有些明白卡尔·雅斯贝尔斯的那句「文学和科学相比，的确没什么用处，但文学最大的用处，也许就是它没有用处」的意思了。买了 kpw3 后，我很乐意培养自己的阅读习惯。大学时间其实还是比较宽松的，但我反而不能每天抽出一小时阅读时间。有时候看书没看两分钟，随便手机一个通知消息就能让我转移注意力——这也是我的缺点：当自己没有全神贯注的时候，很容易被其它的事情所吸引注意力（这也算我很迫切想改掉的一个坏习惯），也导致看了近两周才把《黑客与画家》这本书看完（书推过两天会补上）。是太浮躁了，也太焦虑了，或许是因为到了大三，面临找工作的压力，这压力不仅体现在看书上，有时我就莫名想快些完成正在做的事情，后来多次发现快速完成的事情必然是敷衍的，而事后一旦想起这件「敷衍」的事情，会更加浮躁。其实这样并不好，道理古人都说给我们听了：「欲速则不达」，以后我会尽量放慢自己做事情的速度，投入自己的内心，问问自己真正想要的是什么。今年有过一段恋情，对我产生了一些影响，有好，也有坏，让我成长了许多，也意识到了自己的不足。是的，一段感情之后一定会让你成长的。我在这个过程中有开心、难过、有挂念一个人，甚至有些「病态」的想法——不论好坏，这些特殊的情感都是之前没有体会过的。恋爱的时候，双方的关系一定需要去协商、磨合，这也会让你学会更好的与人沟通，同时你会发现有些问题如果脱离恋爱范围的话根本就不是问题。在一段恋情过后，我们获得的不仅仅是恋情，还有更好的、获得了成长的自己。你会更了解自己，也更了解你需要找一个什么样的人。要有自己的生活，要坚持做自己。要学会去爱，但要先学会爱自己。接下来说说工作。其实我很反感工作——即学校安排给你作为学生所必须学习的课程，所以这学期的课我基本没怎么去，因为去了我也不会听：我无法强迫自己去听那些完全没有兴趣的课程，那有点像是别人强迫要你去做的事情，我天生是一个「猫型人格」（即：你让我向左转，我会不由自主的向右转，同时心里还有一点歉疚），所以有些不由自主地抗拒。在之前写的那篇文章中就说到，我想更加追随自己内心的意愿去活着。具体到工作的说法就是：我想开始「不以找到工作为目的的学习」，学习自然指的是编程。编程这么有趣的事，竟然还有钱赚      ——by c++ 之父我喜欢编程，我愿意将自己的时间花费在上面做一些有趣的小程序，即使这在旁人看来对以后的工作没有什么帮助，我不想抱着太强的目的性、太多的功利心去学习，因为这样，会让学习变味。同时我也乐于看着指尖下的一串串字符到显示器上显示出成果，会有一种小小的满足感。最后，小小说一下对 2018 年的展望（这绝对不是 FLAG！）希望继续读书的习惯希望做事情的时候更专注希望能多吃水果、生活作息规律希望学会使用 To-Do list（如果能有效治愈我的拖延症的话）",
    "url": "/posts/5873b0c0/"
  },
  {
    "title": "记一次反向代理的搭建",
    "date": 1562212063,
    "tags": "反向代理 Startpage 搜索引擎",
    "category": "实验室",
    "content": "最近和朋友聊天时，他说发现了一个云计算服务商：「ZEIT」，可以为程序免费提供托管，想问问我有没有什么好的想法。我查看了一下发现这货在全球提供的线路还真不少（亚洲大部分地区都有），用作代理软件想必体验会比较不错。于是我首先想到搭建 ShadowSocks、V2Ray 这类代理软件，不过很可惜 ZEIT 在部署上有限制：不支持 WebSocket（当然更不支持 SOCKS5 了），且虽然线路的延迟比较低，但在带宽上却有限制，于是我暂时放弃了正向代理，把注意打到了反向代理的头上。反向代理相比正向代理的限制不少，最大限制的在于一次只能代理一个网站。想了想还是决定代理一个搜索引擎——Startpage，用于手机等不那么方便翻墙的设备搜索。至于为什么选择它嘛，有两点原因：它是一个非常「干净」的搜索引擎，隐私性做得非常好，甚至没有登录功能，用户偏好也只是用 Cookie 实现；它匿名地向 Google 提交查询，再将结果返回给用户（某种意义上来说，它也算 Google 的反向代理），所以搜索质量约等于 Google。至于为什么不选择 Google，答案也很简单，Google 会检测计算机的异常流量，一旦检测到异常，则必须通过「reCAPTCHA」检测才能继续使用。尤其是在使用反代的时候，出现检测的机率非常高，这对想迅速得到搜索引擎反馈的用户来说，无疑是一种灾难。时隔一年，我真香了，在把本站的代理切换成 Google 一段时间之后访问时也并没有出现「reCAPTCHA」检测，因此本站会继续保持代理 Google。⚠️：目前，我的 ZEIT 账户因为搭建的代理被太多人次访问（每个月差不多使用了 100g 的流量），已经遭到官方永久性冻结账户了。所以大家还是尽量自己搭建自己使用吧。思路反向代理的核心思路或者说原理其实很简单：中转服务器把来自客户端的请求发送给服务端，再将服务端的应答返还给客户端。单纯地实现这一功能也非常简单，使用 Golang，你甚至不需要借助第三方库便可搭建一个很简单的反向代理。 这几行代码就足以搞定 Google 的反向代理了，也能让你愉快地使用 DuckDuckGo 了，然而却无法使用 Startpage。是的，可能因为「Startpage」本身就相当于对 Google 的反代，所以它对反向代理极其不友好，具体见下。薛定谔的 Bug 们绝对路径当我运行刚刚的程序，打开浏览器并输入地址满心欢喜地看着 Startpage 的首页一点点出现时，我几乎以为已经成功了，可是当我输入关键字搜索时，打开 Firefox 的调试工具却发现它的请求资源都是从「Startpage」域名返回的。是的，Startpage 很「聪明地」将静态文件的引用使用了绝对路径，而不是大多数网站都使用的相对路径，这意味着我还需要修改 Response Body，将原域名都替换成自己的域名，这一点倒是没什么难度（当时我是这么想的），正好 Golang 也提供了 ModifyResponse 用于 Response 的修改。可当我代码写好了然后发现运行结果仍和原来一样时，我开始觉得有点难办了。传输编码造成这个问题的原因其实很明显，但我却花了半天的时间才找到：Startpage 在网页传输时启用了 GZIP 的压缩编码，因此直接替换   是行不通的，需要将 Response Body 解码之后再替换。完成解码替换之后，终于如愿看到请求资源都是从本域名返回的，我又一次以为自己要成功了。可是当我点击搜索结果的下一页时，网页却久久处于加载之中，我开始觉得或许不应该选择代理「Startpage」了。域名改变打开 Firefox 的调试工具之后，发现它居然把第二页的域名给换成了与首页完全不同的二级域名——「www」会变成类似「s2-us8」、「s3-us6」这的前缀，而具体变成什么样是由首次搜索的时候随机返回的。这个问题其实应该是无解的——除非你把所有出现的二级域名都进行代理（类似 YouTube 其实也是把每个视频的源文件放在不同域名的服务器上），不过很可惜，Startpage 只是单纯把域名换了，实测之后直接输入域名前缀也是可以正常使用的，因此只需要把代理的 URL 从   换成   就可以加载后几页的内容了。处理 Header在修复了以上三个 Bug 之后，搜索功能已经很完善了，不过还有一个小问题，就是用户的偏好设置无法保存，比如自定义背景、偏好语言等，点击保存按钮会 301 重定向至   页面，是的，这又是「Startpage」为反向代理设置的一道关卡。（没办法，自己选的路，哭着也要走完 : ）在修改完 301 的重定向地址后，点击保存发现虽然不会跳转到「Startpage」域名了，但是设置依然没有保存下来，一番 Debug 后发现是 Cookie 的问题，Cookie 设置的 Domain 不是同样使用的是绝对路径，「Startpage」为了不让别人反代真是煞费苦心呐！在直接把 Cookie 的 Domian 字段干掉之后，使用起来终于和原网站无异了。总结虽然一开始只想着反代一个搜索引擎，但中途想着还是把普适性做得更广一些，让它能代理任意的网站，因此考虑的方面也比较多，但最终的成就感还是挺爽的，自己也对 HTTP 各字段的理解更深刻了。目前这个反向代理工具支持文本替换、重定向替换、Cookie 替换等，源码已开源在 GitHub，部署在 ZEIT 上，如果你想部署在自己的服务器上，建议使用 master 分支。参考：Reading gzipped HTTP response in GoGolang Example: multi-route, multi-lambda with dependenciesHow to dump a response of an HTTP GET request and write it in http.ResponseWriter",
    "url": "/posts/1352252a/"
  },
  {
    "title": "解除百度云下载限速",
    "date": 1497508320,
    "tags": "教程 百度云加速 百度云 限速",
    "category": "分享境",
    "content": "目前关于破解百度云限速的方法网上提供了许多种，实则是殊途同归，即：高速链接 + 多线程下载工具。而目前获取的链接的方法并非完美且存在一些限制，但聊胜于无。我将目前网上能搜集到的方法一一列举，同时也会针对每个方法的适用性与方便性做出评价。TL; DRWindows 用 PanDownload。其它平台用 PanDownload 网页版。获取下载直链这一类方法都是以插件获取下载直链，再辅以多线程下载工具来达到不限速的目的，以下为各个插件的具体说明：（有关多线程下载工具 Axel 见文章末端）下载助手下载油猴脚本管理器安装下载助手修改版脚本打开百度云，勾选需要下载的文件上方会出现「下载助手」的按钮，依次点击：压缩按钮 -> 获取压缩按钮：此方法适用性应当比较高。以下是 Axel 开启 128 线程的示例：缺点就是有些麻烦：需复制 Header 信息才可掉调用下载工具（如 Axel 等）下载，获得 Header 的方法就是打开调试窗口，粘贴该链接在 Chrome 地址栏，在 Network 选项卡中查看该链接的 Request Headers，至少需要将 Cookie、User-Agent 两项传入给下载工具。注意：这里的 Cookie 并不是当前域名（pan.baidu.com）的 Cookie，是   的 Cookie，其实所需要的仅仅是 Cookie 的   和   值Pandownload在提供 Windows 客户端的同时，PanDownload 还于最近提供了网页版，可直接将分享的文件提取出直链 ：打开PanDownload 网页版，输入分享链接和提取码会生成一个包含你想要下载文件的页面，点击会进入这样的界面：直接点击即可通过浏览器下载（如果你想用其它的工具下载，记得传递 Cookie），当然你也可以使用 Aria2 RPC 下载。这是我使用 Aria2 下载的速度，配置文件见这里：此方法的优点在于不用安装额外的浏览器插件，也不用下载客户端，比较方便手机和 Linux 用户。缺点在于 Aari2 的线程仍然有限，所以速度不会特别快，但也算比较理想了。BaiduExporter~~自本文最近一次更新起，该方法获取的链接已无法在 Axel 中使用，原因是 URL 参数中的 app_id 失效，但这失效的 app_id 的 URL 却仍然可以用 aria2c 下载。~~可以使用我 Fork 后修改的版本作为代替。我的小号在使用这个方法的时候被封了，直接 403，更换帐号后可正常下载。被封之后大概两天内会解封。建议线程数不要开太多，被封之后可以更换速盘下载。clone 该仓库Chrome -> 更多工具 -> 扩展程序 -> 加载已解压的扩展程序（需勾选开发者模式） -> chrome/release（文件夹）进入想要下载文件的界面勾选，点击 导出下载 -> 文本导出 -> 拷贝下载链接：复制链接后，是一串格式类似以下内容的命令： 其中包含两个 HTTP 首部信息：分别是 UA、Cookie，这两个信息在上一步骤的框里均会显示，不要直接复制我的，Cookie 会过期。其中最后一个参数   是需要你手动输入的线程数量，即为采取 233 个线程下载。该项目算是目前比较完美的解决方案了，以下是使用 Axel 开启 256 个线程后的速度（不要在意中间的乱码）：原项目是将链接导出至 ariac2 下载，但是 ariac2 却只能最多开启 16 个线程，这对一般下载任务也够了，但是对于百度这种老流氓来说（每个连接限速至 10Kb/s ），还是不够用的，所以我 Fork 后采用 Axel 代替 ariac2，Axel 可以设置任意连接数）。此方法也是我目前一直在使用的方法。ADM + ES这个方法是酷安上流传已久的方法，但我一直都无法满速，还是在这里提一下吧，造福一下手机党：安装 ES 文件浏览器安装 ADM（酷安手机客户端下载）ADM 线程数调至最高修改 User-Agent：ADM -> 设置 -> 下载 -> 用户代理 -> \\，将以下内容复制进去： ES 文件浏览器 -> 网络 -> 新建 -> 百度网盘，随后登录就会进入网盘界面，进入文件夹找到需要下载的文件后 长按 -> 更多 -> 打开为 -> 视频 -> ADM，这样就会调用 ADM 下载了同样该方法并非完美，用「ES 文件浏览器」获取的百度云链接只能在该手机端使用，因为该链接是通过本地端口远程链接所生成的，故还是有一些限制，速度不稳定（会有一些不稳定的波动）：第三方客户端这一类方法使用的是别人已经封装好了的第三方客户端，其实就相当于把 获取链接的插件 + 多线程下载工具 打包好成为一个客户端。比上一类方法方便性会强一些，但适用性会弱一些。PanDownload该软件只有 Windows 版。该软件不仅支持加速下载，并支持在线解压缩，并且文档很详细。并且个人认为比速盘好，我有时候使用速盘下载提示限速，但此软件却能达到满速，推荐使用。速盘该软件同样是由爱吾一位大神创作，同样只有 Windows 版。与其它软件的不同之处在于它还支持网盘资源搜索的功能。据说是支持直接通过分享链接下载的，但我试了一下通过分享链接下载总是报错。但登录后下载还是可以的。BaiduPCS-Go（全平台）该项目是使用 Go 语言编写的命令行客户端，支持下载、分享、上传、离线下载等功能。我没有使用过该项目，但该项目在 GitHub 上收获 6.5k 的 star，应当是获得了许多人的认可。附 Axel 使用方法我为什么提倡使用 Axel 来代替 aria2c 作为多线程下载工具呢，原因是 aria2c 最多只能设置 16 线程下载，虽说网上有修改成 512 线程的版本，但我试了之后发现速度并没有提升。而 Axel 对此则没有限制。安装该软件已经附在各发行版的源仓库中了，直接安装就行。对于 Windows 来说可以自行从源码编译，这是教程。使用终端输入  ： 本文持续更新中。",
    "url": "/posts/cfd78fa9/"
  },
  {
    "title": "基于 ETS 的漏斗限流",
    "date": 1594204594,
    "tags": "ETS Elixir 限流",
    "category": "实验室",
    "content": "ETS（Erlang Term Storage），是一种运行在 Erlang 虚拟机上基于内存的项式存储系统，在功能上类似于「简化版」的 Redis，但由于集成在 OTP 内部，相比 Redis 来说有两个优点：不用像 Redis 必须通过网络端口访问，所以在理论上的存取性能会比 Redis 要高几个数量级；存取的数据结构比较灵活，可以是任何的 Erlang/Elixir 项式。在稍稍查阅了 ETS 的相关文档之后，我便决定将目前 API 项目中的漏斗限流模块使用 Elixir + ETS 重写（稍后会介绍一下我为什么这么做），当然只重写限流部分并不能替换现有的基于 Redis 的限流，在日后我会将整个的 API 系统都用 Elixir 重写一遍。漏斗限流漏斗限流是我之前在阅读《Redis 深度历险》了解到的一种限流方法，相比于传统的 Nginx 请求限制（ngx_http_limit_req_module）会更加的灵活。比如：漏斗限流可以接受短期内的多次访问，只需要不超过漏斗的总容量即可，在暂停访问则会一点一点恢复容量——这才应该是比较符合常理的限流方式，毕竟某接口的访问间隔不可能总是恒定的。漏斗限流的初始化参数包含如下四个：漏斗的总容量；漏斗的流水速率；漏洞当前的剩余容量；上一次请求的时间。其中前两项参数相同类型的漏斗都会保持一致，后两项则是每一个独立的漏斗都不一样。因此我在设计目前的限流模块时，只使用了剩余容量、上一次时间这两个参数，总容量与速率设置成了恒定不变的。使用 ETS继使用 Elixir 重写完豆瓣的爬虫之后，总感觉有写不舒服：Elixir 擅长领域不应该是在爬虫，而应该是在服务端应用上。因此我决定继续深入研究 Elixir。只是手中暂时也没有什么新坑，于是就想着使用 Elixir 把 API 系统重构一下，虽然重构完成后我也不一定会将现有的 Golang 版本的 API 替换（毕竟 Golang 的部署实在太香了），但重构应该是会加深我的 Elixir 的理解。那么为什么我会选择使用 ETS 呢，其实有一个很重要的原因就是 Elixir 的数据是不可变的，因此当使用另外的数据结构（比如：Map）修改或新增键值对的时候，会涉及到比较大的内存和时间开销（复制旧的 Map 数据到新的 Map 上），于是我便把目光转向了 ETS。其实我最早的打算是使用 Heap 这个数据结构，只是虽然 Heap 在新增键值对的性能很高（O(1)），删除的时候也不错（O（lgn）），但是在更新的操作很麻烦，需要查找出旧的删除，再插入新的。更关键的是 Elixir Heap 的实现方式是配对堆，与二插堆提供的上浮下沉操作不一样，自己实现配对堆的更新操作的话不知道会踩多少坑。。简单写了一段代码来测试 ETS 的存取性能： 简直出乎我的意料，一千万次的插入和查找操作均在 1 秒内完成（硬件水平：i7-9700K，16G 3000MHZ）。惰性删除在设计好了插入和更新（更新同样可以使用   函数完成）后，还有一个非常重要的功能：「删除」。如果不定期将存储在 ETS 的键值对删除的话，内存的占用就会越来越多，所以得需要实现一个定期删除的策略。我考虑的策略是如果某 IP 五分钟之内没有请求，那么就将 Key 为 IP 的键值对从内存中删除。为此需要记录每一个 IP 访问的最后时间，且最好按照时间来严格排序（从功能上来说 Redis 的 sorted set 其实是完美契合的，只是这样一来的话又得用 Redis 了，那目前为止的工作就没有意义了），如果不能严格排序的话，用 Heap 也是一个不错的选择。只是同样会因为 Elixir 数据不可变的原因，成为性能的瓶颈。在 Google 了好一段时间之后，终于在 Stack Overflow 上找到了我想要的方案：使用另一个类型为 ordered-set（类似于 Redis 的 sorted set）的 ETS Process 来存储 IP 访问时间顺序的数据，为了避免数据的冗余，只需要保存 Key（即 IP）和时间即可，在需要删除的时候，先获得 ordered-set 的第一个元素，然后取出时间判断这个时间是不是已经过去五分钟了，如果是的话，就把这个数据删除，同时也需要将另一个 ETS Process 里对应的键值对删除。对于这个「在需要删除的时候」的检测，我将其设置为每一次访问都会触发。提高可用性完成了删除的功能开发之后，限流系统已经可以正常使用，但是为了提高系统的可用性，还需要将当前系统的主要进程使用 Supervisor 监管。目前功能实现分为三个模块：Ral.Cell：这个模块是对外提供的接口，只有 choke 函数被定义为公开，其余辅助函数均对外隐藏。choke 接受一个参数 Key，不限制类型，但最好为 Atom，返回值是 true 或者 false，代表本次请求通过或者不通过；Ral.CMD：这个模块是接受 choke 函数被调用时产生的对数据库的操作，将其与 Ral.Cell 拆分是为了让消息能在两个进程之间异步地传输，提升性能；Ral.ETS：这个模块是专门控制 ETS 的相关进程的，如果和 Ral.CMD 合并成一个模块的话，需要将 ETS 的参数设置为   或将整个 Ral.CMD 注册成 GenServer，但前者有些危险：任何进程都可以写入 ETS 的数据，理想情况应该是最多允许其他进程读取数据而不允许写入；后者与用 Message Queue 传递消息相比将显著的降低（大约 50% 的）性能。三个模块中，需要被 Supervisor 监管的有 Ral.CMD：需要保证 Message Queue 消息接收方始终可用和 Ral.ETS：需要保证 ETS 的服务始终可用——至于 Ral.Cell，只包含对 ETS 的查询操作和对 Ral.CMD 的调用操作，因此无需对其使用高可用。功能完善后，简单跑了一下 benchmark，每秒处理数可以达到 27w，而之前使用 Redis 的限流模块QPS 只有 2w，这就将系统的性能瓶颈从限流模块转向了 Web Server，算是一个比较成功的轮子吧～",
    "url": "/posts/16c559c7/"
  },
  {
    "title": "Poker 机械键盘开箱与简评",
    "date": 1509602200,
    "tags": "开箱 键盘 评测",
    "category": "碎碎念",
    "content": "一入外设深似海，从此钱财是路人。初识第一次知道外设这个概念，是在高中的时候，在网上偶然逛到机械键盘贴吧，只是当时忙于准备高考，而外设又价格不菲，于是念头便搁置了。后来上了大学，买了笔记本，敲着笔记本自带的键盘「 shit 」一般的手感，才想到我应该买一把机械键盘了。于是就在网上找，看到一个段子说：年轻人千万别碰哪些东西？毒品游戏显卡Hi-Fi 耳机固态硬盘机械键盘Steam Origin Uplay. . .当时大一，看到这个段子就笑了一笑，面对从一百多到一千多价位不等的机械键盘，还是比较理智的，听人说凯华轴的手感也是最接近 Cherry 轴的，于是就买了贼鸥 87，用了快两年，这期间：鼠标换了两个，耳机也买了两个，键盘却一直在用这一个，最近有几个键不灵了，正好趁着双十一，想着干脆换一把新的。心中对 Poker 那独特的键位种草已久，可惜京东没有 Poker II 的红轴版本，于是便入手了一代。外观不愧是「二手东」，这饱经沧桑的包装盒：关于包装盒，去拿快递的时候还发生了一个小插曲：当时京东的人问我手机尾号，我告诉了她，然后又问我是什么东西，我说是一把键盘，然后他就去找，找了半天，没找到，然后就问另一个人，说：“尾号是 6 的快件都在这里了吧，怎么没有键盘啊？”，然后转头问我：“键盘应该是挺大的吧？”，我说：“不，不大，挺短的”，然后她又去找小一点的包裹，结果一找就找到了。回到寝室，迫不及待的拆开了包装：这便是全家福了，包含：键盘本体、USB 连接线、RGB 的大键键帽、说明书、拔键器。其中连接线带有屏蔽磁环，做工也算精良。60%Poker 这一系列，最大的特点应当就是 60% 尺寸的设计了，准确来说是 61 键。相对于普通 87 键的键盘，尺寸更加玲珑小巧，省去了方向键和功能键，改为用   的组合键来实现相应功能。方向键是用   + WASD 来实现，不过，对于用 Spacemacs 的我来说，没啥影响，哈哈。真正拆开的时候才发现 60% 尺寸带来的冲击有多么大。说到组合键，  与组合键的功能在侧刻上都已标注：  与数字键组合就是 F1~F12。  + N、M、< 分别是音量 -、+、静音等。轴和键帽说道机械键盘的核心，应当就是轴体和键帽了。轴体轴体方面，采用的是 Cherry 原厂轴体，大键也是卫星轴设计。手感嘛，自然是没话说了。我这里购买的是红轴的版本，毕竟用了两年，还是红轴最为顺手。键帽键帽采用的是 PBT 材质，对于 ABS 来说，PBT 的好处就是绝不会打油。而且这款 PBT 键帽比我之前在网上购入的 PBT 键帽手感要更胜一筹，对着光看起来还闪着微弱的光，挺有意思。在上图键 F、G、H 的侧面，可以看到有三个数字，分别是 15ms、0.1s、0.5s，这是允许用户调整按下键帽时的响应速度。这一点也是比较新奇。背部相对与小巧玲珑的正面来说，背部就没有那么精致了：四周是四个黑色的防滑垫，没有撑脚，可能是为了缩减体积来作出的取舍（当然键盘也设计成了前高后低的人体工学形状），防滑垫对我来说用处不大，因为我是把键盘放在鼠标垫上使用的。中间那块金属铭牌上刻着一句英文：「The keyboard to cheer you up」（用这把键盘让你高兴起来！）可能会注意到在底部的右侧有四个很小的指拨开关，作用分别是：开关 1：CAP = 左 WIN；CAP 灯 = 左 WIN 灯开关 2：右 CTRL = `~开关 3：左 WIN = 左 FN开关 4：写保护键盘编程功能这一功能也算是 Poker 的特色了，目前还不是很了解，先放一放，过几天等了解了再补上。总结换上附赠的 RGB 键帽后，白色素雅的 Poker 顿时骚了起来，哈哈。由于是 mini 键盘，我的手托也就不那么合适（长了一截，无关紧要）。一把 60% 键盘，精简了多余的按键和尺寸，为便携带来了许多好处（要是再赠送一个保护套就更完美了）。做工上乘，手感尚佳，不过大键的手感稍肉，Cherry 原厂轴加上 PBT 键帽，算的是 IKBC 的良心之作，值得入手。（怎么感觉写成了软文 23333",
    "url": "/posts/72474942/"
  },
  {
    "title": "杭州见闻",
    "date": 1537535493,
    "tags": "杭州 生活 旅游",
    "category": "碎碎念",
    "content": "似乎很难说出为什么我对杭州这座城市如此「情有独钟」，以至于暑假就和同学计划着来杭州实习，虽然还是拖到了开学。出发之前也没有准备许多东西，只是简单收拾了一下衣服。所幸到达杭州后遇到的问题（比如租房、工作等）都比较顺利的解决了：遇到了很棒的宾馆老板、主动给我指路的老奶奶、很 Nice 的面试官（随后顺利入职）……这一切都让我对杭州这座城市更有好感，也让如今的我庆幸没有来错杭州。  面试来杭州前，我和同学都约了面试，不同的是，他约了 5 场，我只约了 1 场。 在学校临走前的几天他都挺慌的，说 5 场万一都不合适怎么办，非要约 10 场差不多心里才有底，我就安慰他说没事，我才 1 场，我都不慌，你慌什么。他反而对我说，对啊，我要是你估计都慌得不敢去了，不知道你怎么这么有信心。当时的我也不知道为什么这么有信心，似乎根本没有想过万一在杭州找不到工作怎么办。就这样，我抱着三分紧张，两分忐忑，五分兴奋的心情，进行了我人生中第一次面试。面试中技术问题主要针对的是之前做的笔试题，而笔试题中大部分都是算法的，所幸虽然我虽好久没接触算法了，但也没有完全忘记。不过让我感到奇怪的是我简历中的项目反而问的不是很仔细，似乎公司更看重的是学习能力和思考方式，而说到学习能力我自然是不会虚谁了，毕竟现在掌握的技能大部分都是自学来的 :）技术问题过后就是较为老套的提问流程了，比如你为什么要来杭州啊，你对我们公司想要了解什么啊，你对自己未来的职业规划是怎么样的啊等等。与面试官的沟通交流较为顺畅，面试官也说我是来面试中很优秀的了，两天后，顺利的拿到了 Offer。公司名字就不透露了，在和瑞科技园。蟹黄汤包随后在等面试结果的一天里，让朋友领着逛了逛杭州。那天早上朋友说带我去吃蟹黄汤包（青芝坞那家），当时已经早上十点了，朋友准备早午饭一起在那里吃，而我当时已经吃过早饭了，就准备到美院的食堂去吃午饭（我十分庆幸没有去美院的食堂吃，走了一圈愣是没找到食堂在哪），但禁不住朋友一直说这里的蟹黄汤包多么好吃多么好吃，于是我也点了一份。等了差不多十几分钟，它才姗姗来迟。外表乍一看和普通的汤包没什么区别，细看还是可以看出馅儿是偏黄一些的。我马上夹起一个就塞到了嘴里，差点没烫哭出来。朋友笑了，然后告诉我说汤包要先从褶子里把汤吸掉，要不然会很烫的。想我以前在学校的时候，哪吃过现蒸的汤包啊，食堂大妈早就蒸好了，然后拿布盖着保温，虽然算不上冷，但也绝对算不上烫。味道嘛，还算好吃。中国美院话说其实一开始我不是很想去美院的（但没办法，谁让相机在我朋友手上呢），因为我觉得学校嘛，再好看还能比旅游景点好看？直到我见到美院的大门那一刻我才知道我错了。前方多图预警（这个预警并没有什么卵用，因为当你点进这个页面的时候图片已经加载完毕了 :）（不知是因为杭州的美女多还是因为学艺术的女生都比较有气质，真的不愧是~中国美女学院~中国美术学院。）这次好像只逛了一半的校园，因为校园里面的建筑真的和迷宫一样，从一个建筑进去绕了一圈就不知道原先从哪出来的了，导致进校园和出校园都在同一侧，下次有机会还要去逛逛。工作我目前所在的公司是早上九点上班，下午六点下班，中午午休一小时，一周五天。除了中午休息时间有一点短之外，几乎完美了，而我除了第一、第二天在下午会稍稍犯困之外，后面几天都挺精神的（当然，代价是晚上十点半就要睡觉，这对我反而是好事，正好能调整到健康的作息时间 :)公司的同事都很年轻，办公氛围也比较轻松，不会像部分其它的公司那么压抑。那个 Nice 的面试官也成为了我目前所在项目组的 Leader。我现在的日常生活就是每天早上睡到八点起，洗漱一下，买个早饭走十几分钟去公司，中午和同事一起去食堂吃午饭，晚上回来之后就写写博客或者看部电影。呐，惬意的生活啊。今天也是第一周的最后一天班，早上去公司的时候发现桌上摆着一盒「蛋黄酥」，应该是中秋的礼物了。说到中秋，这应该是我第一个不在家过的中秋了吧，有些伤感。最后，还是祝大家中秋节快乐。",
    "url": "/posts/2848ddef/"
  },
  {
    "title": "Kubernetes 初探",
    "date": 1584332852,
    "tags": "Kubernetes PostgreSQL Erlang",
    "category": "实验室",
    "content": "之前对 Kubernetes（K8s）一直抱有一种很「暧昧」的态度：我想了解它的特性，并且也尝试根据别人总结的经验去接触它，但尝试接触后却总像雾里看花，好像懂了一些又好像什么都不懂。我对新技术技术又总是充满渴望的，渴望来自于对旧技术的不满，这种不满在最近辞职后达到了顶峰：我不想通过别人总结的「二手知识」来接触 K8s 了，而是希望全面地了解 K8s 如何解决了现有软件架构的缺点从而火起来的。正好借着本文，写一下我近期关于架构方面的一些思考（第一篇架构相关的文章，可能会有些稚嫩）。软件架构的改进几年前，软件的架构都是单体式（Monolithic）的：即使一个 Web 系统的大多数模块在业务上并不是紧密相连的，它们仍然会运行在一个操作系统级别的进程当中（如今大把的软件仍然是这样的架构），这也就意味着单独改动某一个模块，在部署时必须重新将整个系统都打包一遍。并且由于大部分单体式的软件在架构层面缺少优化，在打包部署时简直就像是一场灾难，而作为开发人员最难受的是明明有办法阻止灾难发生但却无能为力。比如我的前公司：先把 Web 应用打一个包（包含各种 pip 的库），再把底层依赖打一个包（Elasticsearch、PostrgeSQL、Nginx，以及各种 rpm 包），这两步下来，包的大小已经直逼 3 个 G 了，每次打包部署的流程差不多都要花费两三个小时，而且有时候还安装失败。近几年，随着 Docker 的问世，微服务架构（Microservices）火了起来。它将单体式的软件拆分了微小且可独立运行的组件，这些组件之间是相互解耦的，因此它们可以独立地开发、部署、升级。而在微服务架构中修改了某模块之后，因为模块组件之间的运行环境是相互隔离的，也不用将系统整体打包了，只需要单独重新部署这个模块就可以了。而随着系统的复杂性逐渐提升，微服务架构中的组件必然会越来越多，配置、管理并让组件们一直保持顺畅地运行（即使是系统在升级中）也成为了一个问题。由人工来保证组件自动化配置、监督组件的运行、故障时进行处理，显然是一件吃力不讨好的事，于是 K8s 这类容器编排工具出现了。非 K8s 不可么高可用的系统设计至少需要满足以下几点；容灾性（Fault-tolerance）、扩展性（Scalability）、分布式（Distribution）、快反应（Responsiveness）、热升级（Live Update）。K8s 的确是满足了这几点，但这些并非是 K8s 的「专利」 ，实际上，在二十多年前爱立信所创造的 Erlang 编程语言便已经满足了这几点要求：即使 Erlang 诞生的时候并没有微服务这个概念（没错，我就是 Erlang 吹）。甚至可以说，K8s 在相当程度上借鉴了 Erlang 的思想：Erlang 虚拟机（BEAM）上运行的所有进程（这里的进程类似 Golang 的协程，并非是操作系统级别的进程）都是相互孤立的，进程之间的通信只能通过 message box 来传递，甚至没有共享内存，这简直就是天然的 Docker 啊！同样是因为进程孤立，跨虚拟机进程通信和虚拟机内的进程通信就只是网络开销不同，也因此 Erlang 天生就支持分布式。至于容灾性，Erlang 同样自带了进程级别的 Supervisor，当进程崩溃的时候，会自动重启。那么，既然 Erlang 设计的这么厉害，为啥现在火起来的是「借鉴」 Erlang 思想的 K8s 而不是 Erlang 本身呢？因为 Erlang 的运行模型实在太特殊了，比如：Erlang 的数据是绝对不可变的，进程之间传递数据只能复制不能传引用，才导致进程可以完全相互独立，进而保证进程崩溃的时候不会影响到其他进程。而 K8s，则是将这一系列的思想从特定的平台抽离了出来，不必再拘泥于 Erlang 这么特殊的模型了，让其他任何语言编写的程序均可以做到高可用。而对于如今的公司来说，将服务拆分然后用 K8s 进行部署的难度显然远远低于将现有代码改成用 Erlang 或者 Elixir 实现。K8s 的实践在前公司，我曾尝试在架构需要调整的项目里推过 K8s，但架构评审的时候，被领导以同事都不会 K8s 为理由给驳回了，这一点倒是在我意料之中，毕竟领导担心承担决策失败的风险，以及他大概认为给开发一两周的时间熟悉 K8s 给他带来的收益比写一两周代码要少吧 :)既然目前在工作中用不到，我就只能在自己的项目中用了。于是决定将 DIEM-API 项目改为使用 K8s 部署，并将整个项目解耦为三个部分：基于 Golang + Gin 框架的服务层（Stateless），这里本应该根据功能再划分为不同的服务，但是因为目前只提供了一个 API，已无法更细分了；基于 PostgreSQL 的数据持久层（Stateful）；基于 Redis 的缓冲层，提供限流服务（Stateless）。单独说明一下第三点：虽然使用了 Redis 作为缓冲，但是其中存的数据仅是 IP 的访问频次，而访问频次对于功能来说并不重要，故这里还是将缓冲层的组件定义为无状态型服务。无状态型服务（服务层、缓冲层）包含两方面的设置：设置 kind 为 Deployment 方便进行 Live Update，同时会自动创建 ReplicationSet 管理 Pods：崩溃时自动创建、可随意扩展服务；设置 kind 为 Service，提供静态 IP 以供外部访问，因为 Pods 是不稳定的，可能随时被销毁并重建，同时 Service 也可提供负载均衡服务；至于有状态服务（数据持久层）要复杂一些，除了包含无状态型服务需要的两方面设置外，还需要配置 PersistentVolume 用来生成存储的资源，以及 PersistentVolumeClaim 用来请求 PersistentVolume 的资源。有关具体的配置文件信息，请查阅项目内的几个 Yaml 文件。后记我在读完《Kubernetes in action》的前十章之后才对 K8s 有了一个比较清晰的认识，也总算明白了之前对着别人的教程创建了 Pods，然后怎么删都删不掉的原因：因为创建的是 ReplicationController，就算删除关联的 Pods 也会被重新创建。也知道了容器是基于 Linux Kernel 提供的 namespace 和 cgroups 技术来实现的，因此在容器内运行程序几乎没有额外的开销。本文并没有解释 Pods、ReplicationSet、Services、Deployment 等 K8s 的基础概念，一方面是我担心因为了解不够深入而难以解释清楚（毕竟我也就接触了两三周时间），更重要的是，希望读者能通过阅读书籍和官方文档来获取一手的知识。",
    "url": "/posts/e0246a27/"
  }
]